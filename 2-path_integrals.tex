\chapter{Path Integrals and Feynman-Kac formulae}


    The path integral was originally developed by Richard Feynman as an alternative formulation of quantum mechanics
    ~\cite{Feynman1948,Feynman1965}.  
    In the path integral, the amplitude for a particle to propagate from one position to another,
    is given by the sum over \emph{all} possible paths between the points.  
    Each path is weighted with a phase $e^{iS[x(t)]/\hbar}$ where $S[x(t)]$ is the classical action for the path,
    and $\hbar$ is the reduced Planck constant.  
    
    %put later with reference to Feynman-Kac formulae.  
    Mark Kac put the path integral on firmer mathematical footing, who worked with similar
    functional integrals~\cite{Kac1949}.  Instead of attributing a phase to each path, one weights each path
    by $e^{-S_E[x]}$, where $S_E$ is the so-called Euclidean action.  This passage from imaginary, oscillatory
    exponents to real, decaying exponents makes the convergence of the results integrals much clearer.

    
    


\begin{itemize}
  % \item Path integral method is alternate formulation of quantum mechanics developed by 
  %   Feynman.  
  % \item Mathematical footing.  Kac
  % \item Relates transition amplitude for quantum particle to sum over all paths connecting
  %   end points, weighted by phase given by classical action for path.  
  \item Put on firmer mathematical ground by Kac\comment{Citation!}.  
    Wick-rotate Schr\"odinger equation to imaginary time, to get diffusion equation.
    Replaces oscillating Gaussian integrals for real, decaying ones.
  \item Path integral have broad applications in theoretical physics as a grounding for field theories
    \cite{Brown1994}, finance~\cite{Glasserman2004} and statistics~\cite{Durrett1996, Karatzas1991}.
    \comment{Should also cite Cecile Morette-deWitt, Kleinert and Grosche}.
    In field theory offer simple way to quantize Gauge theory, and in statistical and financial 
    applications provide a natural way to connect the sample paths, 
  \item This fact (path integrals are solutions to diffusion equations) is referred to as the 
    Feynman-Kac formula.  
    In addition, the same term is used to refer to particular solutions for given situation.
    We will typically employ the term in this second sense to refer to particular
    solutions corresponding to path integrals.  
\end{itemize}

\section{Derivation of Feynman-Kac formula }
\begin{itemize}
  \item Follow spirit of Feynman~\cite{Feynman1948}, and derivation in Sakurai\cite{Sakurai1994}.  
    Related material in Steck Sec 17.9~\cite{SteckNotes} 
    Formal derivations in Karatzas and Shreve~\cite{Karatzas1991}, and Durrett~\cite{Durrett1996}
    \comment{Cite Morette-de Witt}
  \item Key idea is to always work to order $\Delta T$ or $1/N$.  
  \item {Quote form of general PDE, and form of solution.}
    We can evaluate these functions using the insight that all of the path integrals are also the solution to Fokker-Planck equation.  
    For example,
    \begin{equation}
      \partial_t f = \frac{1}{2}\partial_x^2 f  - [V(x,t)+\lambda]f +g(x,t) ,
    \end{equation}
    has the solution
    \begin{equation}
      f(x,t) = \dlangle  f[x_0+x(t)] e^{-\lambda t - \int_0^t dt'\,V[x(t')]} + 
      \int_0^t ds\,g(x,t-s) e^{-\lambda s-\int_0^s du V(x,t-u)} \drangle 
    \end{equation}
    with initial condition $f(x,t=0)= f_0(x)$, and $\dlangle \cdots\drangle$ denotes the ensemble average over Brownian walks.
  \item Introduce double angle bracket notation, and relate to typically path integral notation.
  \item Also introduce path-average notation as time integral.
  \item Comment on subscripts denoting types of loops $\dlangle\cdots\drangle_{\vect{x}_0}$
\end{itemize}

\subsection{Path Integral without Source}
\begin{itemize}
  \item {Fokker-Planck Equation on Hilbert space.  }
    So let's do the quantum mechanical approach to this.  We start from 
    \begin{equation}
      \partial_t f = \frac{1}{2}\partial_x^2 f - V f + g, 
    \end{equation}
    this can be turned into an operator equation: 
    \begin{equation}
      \partial_t\langle x |f\rangle = -\langle x|\left[\frac{\op{p}^2}{2}+V(\op{x})\right]|f\rangle
    \end{equation}
  \item Solution is exponential operator.  
  \item {Split operators into $N$ steps.  Baker-Campbell-Hausdorff}
    Then, do the usual path integral tricks:
    \begin{align}
      \langle x_N|f(t)\rangle =& \langle x_N|\exp\left[-t\frac{\op{p}^2}{2}-tV(\op{x})\right]|f\rangle \\
      =& \langle x_N|\prod_{k=1}^N\exp[- t/N(\frac{\op{p}^2}{2}+V(\op{x})]|f\rangle \\
      =& \langle x_N|\exp[- t/N(\frac{\op{p}^2}{2}+V(\op{x})] \ldots \exp[- t/N(\frac{\op{p}^2}{2}+V(\op{x})]|f\rangle \\
      =& \int \prod_{k=0}^{N-1}dx_k \langle x_N|\exp[- \Delta t(\frac{\op{p}^2}{2}+V(\op{x})]|x_{N-1}\rangle\langle x_{N-1}| \ldots \langle x_1|\exp[- \Delta t(\frac{\op{p}^2}{2}+V(\op{x})]|x_0\rangle\langle x_0|f\rangle \\
      =& \int \prod_{k=1}^N\frac{dx_{k-1}dp_k}{(2\pi)}\prod_{j=1}^N e^{-\frac{\Delta T}{2}p_j^2 +ip_j(x_j-x_{j-1}) - V(x_j)\Delta T}\langle x_0|f\rangle \\
      =& \int \prod_{k=0}^{N-1}\frac{dx_k}{\sqrt{2\pi \Delta t}}e^{-\frac{(x_{k+1}-x_k)^2}{2\Delta t} - \Delta t V(x_k)}f(x_0)
    \end{align}
    Now somehow transform this to something like $f(x_n + \sum_{j}dW_j)$ to get the same form as Dan?
    Transform to integrating over the increments $dW_j = x_{j+1}-x_j$.
    Then $\sum_{j=0}^{N-1} dW_j = x_N - x_0$.
    Well, just quickly solve, and you see that $x_0 = x_N - \sum_{j=0}^{N-1}dW_j$.
    Similarly, $x_k = x_N - \sum_{j=k}^{N-1}dW_j$.  

  \item {Continuum limit.  Note source of walks}
    \begin{align}
      f(x_N,t)=& \int \prod_{k=0}^{N-1}\frac{dx_k}{\sqrt{2\pi \Delta t}} e^{-\frac{(x_{k+1}-x_k)^2}{2\Delta t} - \Delta t V(x_k)}f(x_0)\\
      =& \int \prod_{k=0}^{N-1}\frac{d(dW_k)}{\sqrt{2\pi \Delta t}} e^{-\sum_k\frac{dW_{k+1}^2}{2\Delta t} - \sum_k\Delta t V(x_N-\sum_{j=k}^{N-1}dW_j)}f(x_N-\sum_{j=0}^{N-1}dW_j)\\
      =& \int \prod_{k=0}^{N-1}\frac{d(dW_k)}{\sqrt{2\pi \Delta t}} e^{-\sum_k\frac{dW_{k+1}^2}{2\Delta t} - \sum_k \Delta t V(x_N+\sum_{j=0}^{k}dW_j)}f(x_N+\sum_{j=0}^{N-1}dW_j),
    \end{align}
    or in continuous language:
    \begin{equation}
      f(x,t)= \dlangle e^{-\int_0^t dt'  V[x+W(t')]}f_0[x+W(t)]\drangle
    \end{equation}
  \item Note time-ordered product.
    Note that in the case of $V(x,t)$ the exponential is really the time ordered product of these things.
  \item $\delta$-pinning at $x=0$.  
    Then if we take $g(x) = \delta(x)$, then the Brownian walks will be restricted to return to the origin.
    Note that I think this definition also assumes that the brownian walks are starting from the origin.  
  \item Discuss notions of Brownian motion, Brownian bridges.  Specify in terms of increments,
    final positions.  Introduce measures like correlation?
\end{itemize}

\subsection{Path Integral without Source}

\begin{itemize}
  \item {Integrating factor method for ODE.  (Interaction picture?)}
    Consider how to solve: 
    \begin{equation}
      \partial_t f = -\alpha(t) f + g(t)
    \end{equation}
    This can be solved via an integrating factor.  Let's introduce $h = e^{\int_0^t dt' \alpha(t')} f$.  then 
    \begin{equation}
      \partial_t h = e^{\int_0^t dt'\alpha(t')} [\partial_t f +\alpha(t)f(t) ] = e^{\int_0^t dt'\alpha(t')} g(t),
    \end{equation}
    where we used the differential equation for $f$.  This differential equation in $h$ has a solution
    \begin{equation}
      h(t) = h_0 + \int_0^t ds\, g(s) e^{\int_0^{s} du \alpha(u)}.  
    \end{equation}
    Then reverting the transformation to $h$ back to $f$, and using $f(t=0)=f_0=h_0$,  we have: 
    \begin{align}
      f(t) &= e^{-\int_0^t dt' \alpha(t')}h(t)  \\
      &= f_0e^{-\int_0^t dt' \alpha(t')} + \int_0^t ds\, g(s) e^{\int_0^{s} du \alpha(u)}e^{-\int_0^t dt' \alpha(t')}  \\
      f(t)&= f_0e^{-\int_0^t dt' \alpha(t')} + \int_0^t ds\, g(s) e^{-\int_s^t du \alpha(u)}.
    \end{align}
    Now take $s \rightarrow t-v$, and $u \rightarrow t-u$.    
    \begin{align}
      f(t)&= f_0e^{-\int_0^t dt' \alpha(t')} + \int_0^t dv\, g(t-v) e^{-\int_{0}^v du \alpha(t-u)},
    \end{align}
    which is pretty much what Dan has, albeit with more sophisticated machinery in play.  

  \item Integrating factor for PDE

    Now imagine applying the same path integral procedure, but you're just careful to keep the operator ordering clear.  

    So let's do the quantum mechanical approach to this.  We start from 
    \begin{equation}
      \partial_t f = \frac{1}{2}\partial_x^2 f - V f + g, 
    \end{equation}
    this can be turned into an operator equation: 
    \begin{equation}
      \partial_t\langle x |f\rangle = -\langle x|\left[\frac{\op{p}^2}{2}+V(\op{x})\right]|f\rangle + \langle x|g\rangle,
    \end{equation}
    Then let us introduce
    \begin{equation}
      U(t) =  T \exp\left[-\int_0^t dt'\frac{\op{p}^2}{2} +V(\op{x})\right]
      = \prod_{k=1}^N \exp\left[ -\Delta t\frac{p^2}{2}-\Delta tV(x_k)\right]
    \end{equation}
    (literally a path integral)?



  \item Need careful time ordering.  
\end{itemize}


\subsection{Solution method}

\begin{itemize}
  \item For actual solutions work in steady-state limit.  
  \item {Work with Laplace transform.  }
    Now let us consider steady state, for potentials $V(x,t) = V(x)$.
    In this case, we can drop the initial condition, and take $f(x,t=0)=0$, as the steady state is insensitive to the initial condition.
    In addition, we take $g(x,t)=g(x)$.   then as $t\rightarrow \infty$ we have 
    \begin{equation}
      f(x) = \dlangle \int_0^\infty ds\,g(x) e^{-\lambda s-\int_0^s du V[x(s)]} \drangle,\label{eq:path_int_solution}
    \end{equation}
    which satisfies 
    \begin{equation}
      0 = \frac{1}{2}\partial_x^2f(x) - (V+\lambda)f + g(x).  
    \end{equation}
  \item Take $g(x)=\delta(x)$.
  \item Solve associated diffusion equation.  (So works for separable geometries.  But foundational
    for approximations suited step-wise basis.)
  \item Identify value of $f(x=0)$ as path integral.  Different location choices will yield different
    functions.  
  \item Particularly interested in methods that could serve as approximations beyond PFA.  
    Interested in results that can serve as \emph{local} approximations exploiting planes.  
  \item From here on, this is mostly a collection of solutions to Fokker Plank equations with various potentials,
    notably steps, and sundry gradients of steps.
    The overall procedure is the same, just the potential changes.
    Later we will have need of these results in our analytical calculations.  The planar open
    path results are essential for numerical techniques.      
\end{itemize}

\section{Sojourn Time and One Step Potential }

\begin{itemize}
  \item {Take $V=\chi\Theta[x-d]$.}
  \item Quote FPE, with potential.  Note source term for closed loops.  
    We start with a single step, $V = \chi\Theta[x-d]$.  We need to solve the following Fokker-Planck equation 
    \begin{equation}
      \partial_t f = \frac{1}{2}\partial_x^2 f - (\chi\Theta(x-d)+\lambda)f + \delta(x).
    \end{equation}
    where $g$ will act as the source which pins the solutions to a particular point, $x_0$.
  \item Note using explicit delta function, rather than unified Fourier representation.  
    While it is possible to solve this using the Fourier representation of the delta function, 
    I found it more transparent to use an explicit delta function and explicitly handle the cases where the pole is in different places.  
    Cite Steck, and Hooghiemstra
  \item Quote Laplace-transformed solution, and appropriate PDE. 
    Now from Eq.~(\ref{eq:path_int_solution}) we have 
    \begin{equation}
      f(x) = \dlangle  \int_0^\infty ds\,\delta(x) e^{-\lambda s-\int_0^s du\,\chi\Theta[x(u)-d]} \drangle,
    \end{equation}
    is the solution to 
    \begin{equation}
      \partial_x^2 f = 2(\chi\Theta(x-d)+\lambda)f - 2\delta(x).  
    \end{equation}
  \item Quote general form of solution, note choosing bounded solution
    In general the solutions are of the form, 
    \begin{equation}
      f(x) = A e^{\kappa x} + B e^{-\kappa x},
    \end{equation}
    where we will fix $\kappa$ appropriately, and choose the bounded solution.
  \item Quote boundary conditions.  
    We also have to take care with the boundary conditions at surfaces.
    At the jump discontinuity at $x=d$ we have 
    \begin{equation}
      \partial_xf(d+\epsilon) - \partial_x f(d-\epsilon) = 0, \qquad f(d+\epsilon)-f(d-\epsilon) = 0.  
    \end{equation}
    For the boundary conditions at the delta function we have 
    \begin{equation}
      \partial_xf(\epsilon) -\partial_x f(-\epsilon) = -2 , \qquad f(d+\epsilon)-f(d-\epsilon) = 0,
    \end{equation}
    where both of these relations follow from integrating the PDE across the discontinuity.  
    
    \item Quote general form of solution for $d>0$.  
    Then for $d>0$ have 
    \begin{equation}
      f(x) =\left\{ 
        \begin{array}{lcr}  A e^{\sqrt{2\lambda} x} & \hspace{2cm} & x<0\\
          B e^{\sqrt{2\lambda}x} + Ce^{-\sqrt{2\lambda}x} & \hspace{2cm} & 0<x<d\\
          D e^{-\sqrt{2(\lambda+\chi)}x} & \hspace{2cm} & x>d
        \end{array}
      \right.
    \end{equation}
    where the coefficients are fixed by matching the boundary conditions together.
    This was done using Mathematica to speed up the tedious algebraic work.  
    \item{Note for $d>0$ need $A$}
    We are ultimately only interested in $f(x=0)$, which in this case means we just need to know $A$.  
    It turns out that 
    \begin{equation}
      A = \frac{1}{\sqrt{2\lambda}} - u\,e^{-2\sqrt{2\lambda}d},\end{equation}
    where
    \begin{equation}
      u = \frac{\sqrt{\lambda} -\sqrt{\lambda+\chi}}{\sqrt{\lambda} + \sqrt{\lambda+\chi}},
    \end{equation}
  \item Note reflection coefficient similarity.  
    plays a similar role to the $TE$ reflection coefficient.
    Considering we are solving a nearly identical differential equation this is not much of a surprise.  
  \item For $d<0$, can get similar result from $D$, if $\lambda \leftrightarrow \lambda+\chi$.
  \item Final result for all cases.  
    Ultimately, we find that 
    \begin{equation}
      \int_0^\infty dt e^{-\lambda t} \dlangle \frac{e^{-s \theta[x(t)-d]}}{\sqrt{2\pi t}}\drangle  
      = \frac{1}{\sqrt{2[\lambda+\chi\theta(d)]}}\left[1 - \sgn(d) u e^{-2\sqrt{2[\lambda+\chi\theta(d)]}|d|}\right],
      \label{eq:Feynman-Kac TE one step}
    \end{equation}
    where the ensemble average is over brownian bridges that satisfy $x(0)=x(T)=0$.
  \item Note normalization factor
    The factor of $\sqrt{2\pi T}$ is normalization for the use of the bridges.  
  \item For $d<0$, note we can use symmetry and substitutions. 
    \subsection{$d<0$}
    We can go through the same procedure for $d<0$.
    This extra effort will be necessary for the Casimir energy where we will have to apply these formulae over all space.    
    Then for $d>0$ have 
    \begin{equation}
      f(x) =\left\{ 
        \begin{array}{lcr}  A e^{\sqrt{2\lambda} x} & \hspace{2cm} & x<d\\
          B e^{\sqrt{2(\lambda+\chi)}x} + Ce^{-\sqrt{2(\lambda+\chi)}x} & \hspace{2cm} & d<x<0\\
          D e^{-\sqrt{2(\lambda+\chi)}x} & \hspace{2cm} & x>0
        \end{array}
      \right.
    \end{equation}
    where the coefficients are fixed by matching the boundary conditions together.
    This was done using Mathematica to speed up the tedious algebraic work.  

    We are ultimately only interested in $f(x=0)$, which in this case means we just need to know $D$ for this case.
    It turns out that 
    \begin{equation}
      D = \frac{1}{\sqrt{2\lambda}} + u e^{2\sqrt{2\lambda}d}.
    \end{equation}
    \item Final results.
    We can pull these results together to write
    \begin{equation}
      f_{TE,1}(x) = \left\{\begin{array}{lcr} 
          \dfrac{1}{\sqrt{2\lambda}}\left[1+ u e^{-2\sqrt{2\lambda}d}\right]  & \hspace{2cm} & d<0\\
          \dfrac{1}{\sqrt{2(\lambda+\chi)}}\left[1 - u e^{-2\sqrt{2(\lambda+\chi)}d}\right] & \hspace{2cm} & d>0\\
        \end{array} \right. 
    \end{equation}

  \item Identify similarity to reflection coefficients
  \item {Quote result for integration over surface.}

    We now need to evaluate $\int dx_0 \dlangle e^{-\int_0^T dt V[x_0 + B(t)-h]}\drangle$ for use with Casimir energies.   Now we have to take $h\rightarrow h-x_0$, and integrate over $x_0$.
    The integrals over position is 
    \begin{align}
      I_{TE,1} &= \int_{-\infty}^h dx_0 \frac{1}{\sqrt{2(\lambda+\chi_1)}}\left(1 - u_1e^{-2\sqrt{2(\lambda+\chi_1)}(h-x_0)} \right) 
      + \int_h^\infty dx_0 \frac{1}{\sqrt{2\lambda}}\left(1 + u_1 e^{2\sqrt{2\lambda}(h-x_0)}\right) \\
      % &= \int_h^\infty dx_0[(2\lambda)^{-1/2}+(2\kappa)^{-1/2}]  -  \int_{-\infty}^0  dx_0 \frac{1}{\sqrt{2\kappa_1}}u_1e^{2\sqrt{2\kappa_1}x_0} + \int_0^\infty dx_0 \frac{1}{\sqrt{2\lambda}}u_1 e^{-2\sqrt{2\lambda}x_0}\\
      &= I^{(1)}_{div}  +   \left(\frac{1}{4\lambda}- \frac{1}{4(\lambda+\chi_1)}\right)u_1,
    \end{align}
    where $I^{(1)}_{div} = \int_h^\infty(2\lambda)^{-1/2}+\int_{-\infty}^h[2(\lambda+\chi_1)]^{-1/2}$.  This renormalization is only necessary for the energy.  

\end{itemize}

\subsection{Planar Dirichlet Conditions}

\begin{itemize}
  \item (Comment- important to get this correct and simple as this is the template?)
  \item Note connection to Gies work (they don't use this).    Note we will discuss this in
    accelerated convergence techniques.  
  \item Take delta function potential a distance $d$ away.  Use open loops.  
  \item Quote potential
\end{itemize}

\section{Two Step Potentials}

\begin{itemize}
  \item {Take $V=\chi_1\Theta[d_1-x]+\chi_2\Theta[x-d_2]$.}
    When we do the Casimir energy between two bodies we will need to find the Feynman-Kac formula assuming two step discontinuities.
    We will use exactly the same procedure as above, but with an extra step. 

    Here we are solving this with $V = \chi_1\Theta(-d_1-x) + \chi_2\Theta(d_2-x)$.
    We have solutions, 
    \begin{equation}
      f(x) = \left\{ \begin{array}{lcr}
          A e^{\sqrt{2(\lambda+\chi_1)}x}   & \hspace{1cm} & x<0\\
          B e^{\sqrt{2(\lambda+\chi_1)}x} + C e^{-\sqrt{2(\lambda+\chi_1)}x}  & \hspace{1cm} & 0<x<h\\
          D e^{\sqrt{2\lambda}x} + F e^{-\sqrt{2\lambda}x}  & \hspace{1cm} & h<x<h+d\\
          G e^{-\sqrt{2(\lambda+\chi_2)}x} & \hspace{1cm} & x>d_2
        \end{array}
      \right.
    \end{equation}
    We will take $d_1 = h, d_2 = d+h$.
    We can then check that our final solutions are independent of $h$ once we have integrated over position.
    We would expect the Casimir energy to only depend on $d$ in this case.   
  \item {Solve in each region, (quote results)}
    We then need 
    \begin{equation}
      f_{TE,12}[x-(h-x_0)] = \left\{ \begin{array}{ccr}
          \dfrac{1}{\sqrt{2(\lambda+\chi_1)}} + e^{-2\sqrt{2(\lambda+\chi_1)}(h-x_0)}\dfrac{u_2 e^{-2\sqrt{2\lambda}d} - u_1}{\sqrt{2(\lambda+\chi_1)}(1-u_1u_2 e^{-2\sqrt{2\lambda}d})} & \hspace{1cm} & h>x_0\\
          \frac{1}{\sqrt{2\lambda}} + \dfrac{2u_1u_2 e^{-2\sqrt{2\lambda}d} + u_1 e^{2\sqrt{2\lambda}(h-x_0)} +u_2 e^{-2\sqrt{2\lambda}(d+h-x_0)}}{\sqrt{2\lambda}(1-u_1u_2 e^{-2\sqrt{2\lambda}d})} & \hspace{1cm} & h<x_0<h+d\\
          \dfrac{1}{\sqrt{2(\lambda+\chi_2)}} + e^{2\sqrt{2(\lambda+\chi_2)}(d+(h-x_0))}\dfrac{(u_1 e^{-2\sqrt{2\lambda}d}-u_2)}{\sqrt{2(\lambda+\chi_2)}(1-u_1u_2 e^{-2\sqrt{2\lambda}d})} & \hspace{1cm} & h+d<x_0
        \end{array}
      \right.
    \end{equation}
    with 
    \begin{equation}
      u_i = \frac{\sqrt{\lambda} -\sqrt{\lambda+\chi_i}}{\sqrt{\lambda} + \sqrt{\lambda+\chi_i}},
    \end{equation}
  \item Identify similarity to reflection coefficients/ Fabry-Perot resonance condition.
  \item Leave in Laplace transformed version for analytical comparisons.    
  \item {Carry out integral over position. Note divergent terms, these are cancelled out by 
    suitable renormalization.}
    We now need to evaluate $\int dx_0 \dlangle e^{-\int_0^T dt V[x_0 + B(t)-h]}\drangle$ for use with Casimir energies.   Now we have to take $h\rightarrow h-x_0$, and integrate over $x_0$. 
    First up we need $I_{12}=\int dx_0 f_{12}[x-(h-x_0)]$
    \begin{align}
      I_{TE,12} %=& \int_{-\infty}^h  dx_0  f_{x_0<h} + \int_{h}^{h+d}  dx_0  f_{h<x_0<h+d} + \int_{h+d}^\infty dx_0 f_{x_0>h+d}\\
      =&\int_{-\infty}^h dx_0 \left[\dfrac{1}{\sqrt{2(\lambda+\chi_1)}} + e^{-2\sqrt{2(\lambda+\chi_1)}(h-x_0)}\dfrac{u_2 e^{-2\sqrt{2\lambda}d} - u_1}{\sqrt{2(\lambda+\chi_1)}(1-u_1u_2 e^{-2\sqrt{2\lambda}d})}\right] \nonumber\\
      & +\int_{h}^{h+d}dx_0\left[\frac{1}{\sqrt{2\lambda}} + \frac{2u_1u_2 e^{-2\sqrt{2\lambda}d} + u_1 e^{2\sqrt{2\lambda}(h-x_0)} +u_2 e^{-2\sqrt{2\lambda}(d+h-x_0)}}{\sqrt{2\lambda}(1-u_1u_2 e^{-2\sqrt{2\lambda}d})} \right]\nonumber\\
      &+ \int_{h+d}^\infty dx_0 \left[\dfrac{1}{\sqrt{2(\lambda+\chi_2)}} + e^{2\sqrt{2(\lambda+\chi_2)}(d+(h-x_0))}\dfrac{u_1 e^{-2\sqrt{2\lambda}d}-u_2}{\sqrt{2(\lambda+\chi_2)}(1-u_1u_2 e^{-2\sqrt{2\lambda}d})}\right]
    \end{align}

     We need 
    \begin{gather}
      \int_{-\infty}^h dx_0 e^{-2\sqrt{2(\lambda+\chi_1)}(h-x_0)} = \int_{-\infty}^0 dx_0 e^{2\sqrt{2(\lambda+\chi_1)}(x_0)} = \frac{1}{2\sqrt{2(\lambda+\chi_1)}}\\
      \int_{h+d}^\infty dx_0 e^{2\sqrt{2(\lambda+\chi_2)}(d+(h-x_0))} = \int_0^\infty e^{-2\sqrt{2(\lambda+\chi_2)}x_0} = \frac{1}{2\sqrt{2(\lambda+\chi_2)}}\\
      \int_{h}^{h+d} dx_0 e^{-2\sqrt{2\lambda}(x_0-h)} = \int_0^d  dx_0 e^{-2\sqrt{2\lambda}x_0} = \frac{1 - e^{-2\sqrt{2\lambda}d}}{2\sqrt{2\lambda}}\\
      \int_{h}^{h+d} dx_0 e^{2\sqrt{2\lambda}(x_0-d-h)} = \int_{-d}^0  dx_0 e^{2\sqrt{2\lambda}x_0} = \frac{1 - e^{-2\sqrt{2\lambda}d}}{2\sqrt{2\lambda}}
    \end{gather}
   \item Final integrated value
    So that we get:
    \begin{align}
      I_{TE,12} =& -I_{div} + \dfrac{u_2 e^{-2\sqrt{2\lambda}d}-u_1}{4(\lambda+\chi_1)(1-u_1u_2 e^{-2\sqrt{2\lambda}d})} +\frac{2u_1u_2 e^{-\sqrt{2\lambda}d}d}{\sqrt{2\lambda}(1-u_1u_2 e^{-2\sqrt{2\lambda}d})} + (u_1+u_2)\frac{(1-e^{-2\sqrt{2\lambda}d})}{4\lambda(1-u_1u_2e^{-2\sqrt{2\lambda}d})}\nonumber\\
      & +\frac{u_1 e^{-2\sqrt{2\lambda}d} - u_2}{4(\lambda+\chi_2)(1-u_1u_2 e^{-2\sqrt{2\lambda}d})},
    \end{align}
    where $I_{div} = [2(\lambda+\chi_1)]^{-1/2}\int_{-\infty}^h dx_0  +  [2(\lambda+\chi_2)]^{-1/2}\int_{h+d}^\infty dx_0  + (2\lambda)^{-1/2}d$.
\end{itemize}

\section{Feynman-Kac formula for TM Potentials}

\begin{itemize}
  \item {Note that TM potential has highly singular potential.  Must be regularized.}
  \item Smooth out contribution by analytically averaging over subpaths.
    In handling the TM case we will first have need to handle that singular potential.
  \item We shall do this first on it's own, since we will have to use those results in any numerical method.
    In addition, it vastly simplifies down.
    We will find that the potential enforces a boundary condition.  

  \item Quote PDE, and exact form of the potential
    We will find the solution to 
    \begin{equation}
      \partial_t f = \frac{1}{2}\partial_x^2f -V_{TM} f - \lambda f + \delta(x-c)
    \end{equation}
    where 
    \begin{equation}
      V_{TM}(x) = \frac{\Xi^2}{2}[\delta(x)]^2 - \frac{\Xi}{2}\delta'(x).
    \end{equation}
  \item Introduce regularized version.  
    Since that is highly singular, we will instead deal with 
    \begin{equation}
      \mathfrak{M}(x) = \lim_{a\rightarrow 0} \frac{\Xi^2}{2a^2}\Theta(a/2-|x|) - \frac{\Xi}{2a}[\delta(x)-\delta(x-a)],
    \end{equation}
    which corresponds to the gradients of a suitably regularized version of $\epsilon_r = 1+\chi\Theta(x)$.  
  \item Outline of next few sections.  Derive boundary conditions for regularized potential.  
  \item Derive Feynman-Kac formula between fixed end points.  Absolutely essential for numerical
    work.
\end{itemize}

\subsection{Transfer Layer Boundary conditions for TM Potential}

\begin{itemize}
  \item {Quote regularized potential.  Note that it corresponds to exponential interpolation.}
    Here we will be trying to solve
    \begin{equation}
      \partial_x^2f =\frac{\Xi^2}{a^2}\Theta(a/2-|x-d|) - \frac{\Xi}{a}[\delta(x-d)-\delta(x-d-a)]f
    \end{equation}
    which arises as the TM potential for crossing the surface associated with $\epsilon_r = 1+\chi\Theta(x-d)$.  We will try to solve this in the limit $a\rightarrow 0$, so we have dropped the other terms.  
    As usual, the solutions will be of the form $f = \alpha_+ e^{\kappa x}+\alpha_- e^{-\kappa x}$, where $\kappa$ is chosen to satisy the differential equation, and $\alpha_\pm$ are fixed by the boundary conditions.  Note that we have three delta functions to handle here.  At each delta function $\gamma \delta(x-s)$ we have the following boundary conditions:
    \begin{equation}
      f'(s+\epsilon)-f'(s-\epsilon) = \gamma f(s),\qquad f(s+\epsilon)-f(s-\epsilon) = 0.
    \end{equation}

  \item {Can find BC's due to this regularized surface.}
  \item Eliminate middle region using continuity conditions.  
  \item Write out form of solutions
    Let us see if we can solve this by eliminating all reference to the middle region.  
    \begin{align}
      f_{\text{mid}} =& Be^{\sqrt{2\lambda + \Xi^2/a^2}x} + C e^{-\sqrt{2\lambda + \Xi^2/a^2}x}\\
      =& Be^{\Xi x/a} + C e^{-\Xi x/a}
    \end{align}
  \item Write out continuity conditions
    and boundary conditions, 
    \begin{subequations}
      \begin{align}
        f(d + \epsilon)-f(d -\epsilon) =& 0\\
        f(d+a+\epsilon)- f(d+a-\epsilon)=& 0\\
        f'(d + \epsilon) -f'(d -\epsilon)=& -2\sigma f(d)\\
        f'(d+a+\epsilon) -f'(d+a-\epsilon)=& +2\sigma f(d+a)
      \end{align}
    \end{subequations}
  \item Find relations between $f(d\pm \epsilon)$ and $f'(d\pm \epsilon)$.
    We will solve for $f(d+a+\epsilon)$, and $f'(d+a+\epsilon)$, trying to eliminate $B$ and $C$, which we will fix in terms of $f(d-\epsilon),f'(d-\epsilon)$.  We will thus have derived the relation between $f$ and its derivatives on both sides of the potential.      
    Our first conditions are
    \begin{align}
      f(d+\epsilon) - f(d-\epsilon) =& 0\\
      \rightarrow f(d-\epsilon) = Be^{\Xi d/a} + C e^{-\Xi d/a}\label{eq:M c1}
    \end{align}
    Similarly, at the second edge  we find that 
    \begin{align}
      f(d+a+\epsilon) - f(d+a-\epsilon) =& 0\\
      \rightarrow f(d+a-\epsilon) = Be^{\Xi d/a+\Xi} + C e^{-\Xi d/a-\Xi}\label{eq:M c2}
    \end{align}
    Now the derivative conditions at $d$
    \begin{align}
      f'(d +\epsilon)-f'(d-\epsilon) =& -\frac{\Xi}{a}f(d)\\
      \rightarrow f'(d-\epsilon)=& \frac{\Xi}{a}\left(Be^{\Xi d/a} + C e^{-\Xi d/a}\right) + \frac{\Xi}{a}\left(Be^{\Xi d/a} - C e^{-\Xi d/a}\right)\\
      =& 2\frac{\Xi}{a}Be^{\Xi d/a} \label{eq:M d1}
    \end{align}
    And the derivative conditions at $d+a$ yield 
    \begin{align}
      f'(d+a+\epsilon) -f'(d+a-\epsilon)=& \frac{\Xi}{a}f(d+a)\\
      \rightarrow f'(d+a+\epsilon)=&\frac{\Xi}{a}\left(Be^{\Xi (d+a)/a} + C e^{-\Xi (d+a)/a} \right)+ \frac{\Xi}{a}\left(Be^{\Xi (d+a)/a} - C e^{-\Xi (d+a)/a} \right)\\
      =&2\frac{\Xi}{a}Be^{\Xi d/a}e^{\Xi}\label{eq:M d2}
    \end{align}
  \item Solve for B/C.
    Eq.~(\ref{eq:M d1}) fixes $B$, which we can use in to Eq.~(\ref{eq:M d2}), so that 
    \begin{equation}
      f'(d+a+\epsilon) = e^{\Xi}f'(d-\epsilon).
    \end{equation}
    So far so good.  Next up the normal continuity condition.  
    \begin{align}
      f(d-\epsilon) =& B e^{\Xi d/a} + C e^{-\Xi d/a}\\
      =& \frac{a}{2\Xi} f' + C e^{-\Xi d/a} = C e^{-\Xi d/a},
    \end{align}
    which says that $B\sim a$, so we will drop it from this part of the calculation.  
    Now use this in Eq.~(\ref{eq:M d2}) to find
    \begin{equation}
      f(d+a+\epsilon) = C e^{-\Xi d/a} e^{-\Xi} =  e^{-\Xi} f(d-\epsilon).  
    \end{equation}
  \item Eliminate references to internal state.  Take limit of regularization going to zero.
  \item {Quote final boundary conditions.}
    We can now take $a\rightarrow 0 $ everywhere.  So we have the following boundary conditions due to an interface $\mathfrak{M}$:
    \begin{align}
      \Aboxed{
        f(d-\epsilon) =& e^{\Xi}f(d+\epsilon), \qquad
        f'(d -\epsilon)= e^{-\Xi}f'(d+\epsilon)
      }
    \end{align}
    \label{sec:TM boundary condition}

\end{itemize}

\subsection{Finding the Feynman-Kac formula}

\begin{itemize}
  \item {Using above effective BC solve for Feynman-Kac eqn for open bridge.}
    \item Quote form of solution, and PDE it solves.  
    \item Note how to recover various cases by flipping signs etc.  
    We are now in position to derive an expression the ensemble average of paths going from $0\rightarrow c$ through $V_{TM}$. 
    \begin{equation}
      f_{0\rightarrow c}=\int_0^\infty dt e^{-\lambda t}\frac{e^{-c^2/(2t)}}{\sqrt{2\pi t}} \dlangle e^{-s\int_0^T dt V_{TM}}\drangle.
    \end{equation}
    This is the solution to 
    \begin{equation}
      0 = \frac{1}{2} \partial_x^2 f - V_{TM}f - \lambda f + \delta(x-c)
    \end{equation}
    We will find the solutions for the case where $0<c<d$.  From this we can see how we need to change the signs to recover the other cases.  Note that the boundary conditions at $x=c$ are: ${f(c+\epsilon)=f(c-\epsilon)}, {f(c+\epsilon)-f(c-\epsilon)= -2}$.  As we found in Sec.~(\ref{sec:TM boundary condition}), at $x=d$ we need $f(d-\epsilon) = e^{\Xi}f(d+\epsilon),f'(d -\epsilon)= e^{-\Xi}f'(d+\epsilon)$.  
  \item Form of solutions in each region, and fixing values via BCs from previous section
    For example, with $c<d$ we have 
    \begin{equation}
      f  = \left\{\begin{array}{ccr} A e^{\sqrt{2\lambda} x} & \hspace{2cm} & x<c\\
          B e^{\sqrt{2\lambda} x} + C e^{-\sqrt{2\lambda} x}  & \hspace{2cm} & c<x<d\\
          D e^{-\sqrt{2\lambda} x}& \hspace{2cm} & c<x<d\\
        \end{array}
      \right. .
    \end{equation}
    In the case where $d>0$, we will need $f(0) = A$.  In the other case where $d<0$, we will need $f(0) = D$.  
    Mathematica when asked to solve the boundary conditions finds that 
    \begin{equation}
      f = \left\{ \begin{array}{ccr} 
          \dfrac{e^{-\sqrt{2\lambda}|c|}}{\sqrt{2\lambda}} + \dfrac{e^{-\sqrt{2\lambda}(2d-c)}}{\sqrt{2\lambda}}\dfrac{e^{2\Xi}-1}{e^{2\Xi} +1}  &   \hspace{2cm}  & d>c,  d>0\\
          \dfrac{ e^{-\sqrt{2\lambda}|c|}}{\sqrt{2\lambda}} \dfrac{2e^\Xi}{1 + e^{2\Xi}} & \hspace{2cm} & d>c,d<0 \\
          \dfrac{ e^{-\sqrt{2\lambda}|c|}}{\sqrt{2\lambda}} \dfrac{2e^\Xi}{1 + e^{2\Xi}} & \hspace{2cm} & c>d,d>0 \\
          \dfrac{ e^{-\sqrt{2\lambda}|c|}}{\sqrt{2\lambda}} - \dfrac{e^{\sqrt{2\lambda}(2d-c)}}{\sqrt{2\lambda}}\dfrac{e^{2\Xi}-1}{e^{2\Xi}+1} & \hspace{2cm} & c>d, d<0
          \\
        \end{array}
      \right.
    \end{equation}
    \item Simplify down to crossing/no-crossing cases.
    That seems complicated, but we can note that if there is a crossing ($|c|<|d|$) then we get 
    \begin{equation}
      f_{nc}=\dfrac{e^{-\sqrt{2\lambda}|c|}}{\sqrt{2\lambda}} + \sgn(d)\dfrac{e^{-\sqrt{2\lambda}|2d-c|}}{\sqrt{2\lambda}}\dfrac{e^{2\Xi}-1}{e^{2\Xi} +1}
    \end{equation}
    For the case of crossings ($d(d-c)<0$) we get
    \begin{equation}
      f_c = \dfrac{ e^{-\sqrt{2\lambda}|c|}}{\sqrt{2\lambda}} \dfrac{2e^\Xi}{1 + e^{2\Xi}}.
    \end{equation}
  \item {Invert Laplace transform to get real-time version.}

    Ultimately, we will want to isolate the potential term.  
    If we use 
    \begin{equation}
      \mathcal{L}^{-1}\left[ \frac{e^{-\sqrt{2\lambda}x}}{\sqrt{2\lambda}}   \right] = \frac{e^{-x^2/(2t)}}{\sqrt{2\pi t}},
    \end{equation}
    which is exactly the factor we isolated in front of $\mathcal{M}$.  
  \item {Final results.  Can now use as basis for numerical methods since depends on loop-time.}
    So we have:
    \begin{equation}
      \frac{e^{-c^2/(2T)}}{\sqrt{2\pi T}} \dlangle e^{-\int_0^T dt V_{TM}(x-d)}\drangle =  \left[\left( \frac{e^{-c^2/(2T)}}{\sqrt{2\pi T}}  + \sgn(d)\dfrac{e^{-(2d-c)^2/(2T)}}{\sqrt{2\pi T}}\dfrac{e^{2\Xi}-1}{e^{2\Xi} +1}\right)\theta(|d|-|c|) + \frac{e^{-c^2/(2T)}}{\sqrt{2\pi T}}\dfrac{2e^\Xi}{1 + e^{2\Xi}}\theta(|c|-|d|) \right]
    \end{equation} 

    Dan has:
    \begin{equation}
      \dlangle \exp\left[-\int_0^T dt V_{TM}(x-d)\right]\drangle = 1 + \frac{\sinh(\Xi/2)}{\cosh\Xi}[\sgn(d-c)e^{\sgn(d)\Xi/2} + \sgn(d)e^{-\sgn(d)\Xi/2}]e^{\left[c^2-(|d|+|c-d|)^2\right]/2t}.
    \end{equation}
    This agrees with my expressions for all cases.  This is useful for our numerical work.  
    Let us check out the $\Xi$ prefactor against my work.  
    \begin{align}
      F_{d>0,c<d} =&\frac{\sinh(\Xi/2)}{\cosh\Xi}[\sgn(d-c)e^{\sgn(d)\Xi/2} + \sgn(d)e^{-\sgn(d)\Xi/2}]\\
      =&\frac{\sinh(\Xi/2)}{\cosh\Xi}[e^{\Xi/2} + e^{-\Xi/2}] = \frac{e^{\Xi} - e^{-\Xi}}{e^\Xi+ e^\Xi}  
    \end{align}
    works.
    \begin{align}
      F_{d>0,d<c} =&\frac{\sinh(\Xi/2)}{\cosh\Xi}[-e^{\Xi/2} + e^{-\Xi/2}] = -\frac{ e^{-\Xi} + e^{\Xi} -2}{e^\Xi + e^{-\Xi}},
    \end{align}
    works, 
    \begin{align}
      F_{d<0,c<d} =\frac{\sinh(\Xi/2)}{\cosh\Xi}[e^{-\Xi/2} -e^{\Xi/2}]=\frac{[(e^{\Xi/2}- e^{-\Xi/2})(e^{-\Xi/2} -e^{\Xi/2})]}{e^\Xi + e^{-\Xi}}=-\frac{e^\Xi + e^{-\Xi} -2}{e^\Xi + e^{-\Xi}},
    \end{align}
    works, and 
    \begin{align}
      F_{d<0,d<c} =&\frac{\sinh(\Xi/2)}{\cosh\Xi}[-e^{\Xi/2} -e^{-\Xi/2}] = -\frac{e^\Xi - e^{-\Xi}}{e^\Xi + e^{-\Xi}}
    \end{align}
  \item Figure of TM potential.  Note connection to Neumann BC and reflection.  
\end{itemize}

\section{Single TM potential and Step}

\begin{itemize}
  \item {Solve FK for TM potential plus step. }
  \item Quote form of solution, and PDE it solves
    Let's now find: 
    \begin{equation}
      f = \int_0^\infty dT \frac{1}{\sqrt{2\pi T}}\langle e^{-\int_0^T dt V_{TM} + s\Theta}\rangle 
    \end{equation}
    This is the steady state solution to 
    \begin{equation}
      \partial_t f = \frac{1}{2}\partial_x^2f -(V_{TM} + s\Theta(x-d)+\lambda)f +\delta(x). 
    \end{equation}

  \item Quote boundary conditions at the boundary, and delta function.  
    For the boundary conditions at the delta function we have 
    \begin{equation}
      \partial_xf(\epsilon) -\partial_x f(-\epsilon) = -2 , \qquad f(d+\epsilon)-f(d-\epsilon) = 0,
    \end{equation}
    where both of these relations follow from integrating the PDE across the discontinuity.
    And the boundary conditions courtesy of $V_{TM}$ are
    \begin{align}
      f(d-\epsilon) = e^{\Xi}f(d+\epsilon)\\
      f'(d-\epsilon) = e^{-\Xi}f'(d+\epsilon).
    \end{align}

    This problem can be solved in exactly the same fashion as the equivalent TE problems.
    Perhaps unsurprisingly, you find that the two slab results can also be ported over, but with their TM reflection coefficients.  

  \item {Leave as Laplace-transform.  Note integral identities mean we can apply this for analytical
    result analytically.  }
    \item Quote solution.  
  \begin{equation}
      f_{TM,1}(x) = \left\{\begin{array}{lcr} 
          \dfrac{1}{\sqrt{2\lambda}}\left[1+ u' e^{-2\sqrt{2\lambda}d}\right]  & \hspace{2cm} & d<0\\
          \dfrac{1}{\sqrt{2(\lambda+\chi)}}\left[1 - u' e^{-2\sqrt{2(\lambda+\chi)}d}\right] & \hspace{2cm} & d>0\\
        \end{array} \right. 
    \end{equation}
    where
    \begin{equation}
      u' = \frac{\sqrt{\lambda}e^{2\Xi} -\sqrt{\lambda+\chi}}{\sqrt{\lambda}e^{2\Xi} + \sqrt{\lambda+\chi}},
    \end{equation}
    plays a similar role to the $TM$ reflection coefficient, since $e^{2\Xi} = (1+\chi)$.   
  \item Final result.  
    Ultimately, we find that 
    \begin{equation}
      \int_0^\infty dT e^{-\lambda T} \dlangle \frac{e^{-\int_0^T dt V_{TM}+s\theta[x(t)-d]}}{\sqrt{2\pi T}}\drangle  =
      \frac{1}{\sqrt{2[\lambda+\chi\theta(d)]}}\left[1 - \sgn(d) u' e^{-2\sqrt{2[\lambda+\chi\theta(d)]}|d|}\right],\label{eq:Feynman-Kac TM one step}
    \end{equation}
    where the ensemble average is over brownian bridges that satisfy $x(0)=x(T)=0$.
    The factor of $\sqrt{2\pi T}$ is normalization for the use of the bridges.  
\end{itemize}


\section{Two TM Step Potentials}

\begin{itemize}
  \item {Quote full potential, and note boundary conditions.}
  \item Quote full potential, and PDE.
  \item Comment on how to handle other surface.
    When we do the Casimir energy between two bodies we will need to find the Feynman-Kac formula assuming two step discontinuities.
    We will use exactly the same procedure as above, but with an extra step. 

    The potential is then 
    \begin{equation}
      V = \chi_1\Theta(h-x) + \chi_2\Theta(x-h-d) + \mathfrak{M}(-\Xi,h) + \mathfrak{M}(\Xi,h+d),
    \end{equation}
    where we took $\Xi \rightarrow -\Xi$ on one step since $\partial^2_x\theta(-x) = -\delta'$.  
  \item Exploit symmetry of effective boundary conditions.  
  \item {Quote results.  Note that $r\rightarrow r'$.}

    We then need to solve this for the various cases of $h,h+d $ on each side of $x=0$:
    \begin{equation}
      f_{TM,12}[x-(h-x_0)] = \left\{ \begin{array}{ccr}
          \dfrac{1}{\sqrt{2(\lambda+\chi_1)}} + e^{-2\sqrt{2(\lambda+\chi_1)}(h-x_0)}\dfrac{u'_2 e^{-2\sqrt{2\lambda}d} - u'_1}{\sqrt{2(\lambda+\chi_1)}(1-u'_1u'_2 e^{-2\sqrt{2\lambda}d})} & \hspace{1cm} & h>x_0\\
          \frac{1}{\sqrt{2\lambda}} + \dfrac{2u'_1u'_2 e^{-2\sqrt{2\lambda}d} + u'_1 e^{2\sqrt{2\lambda}(h-x_0)} +u'_2 e^{-2\sqrt{2\lambda}(d+h-x_0)}}{\sqrt{2\lambda}(1-u'_1u'_2 e^{-2\sqrt{2\lambda}d})} & \hspace{1cm} & h<x_0<h+d\\
          \dfrac{1}{\sqrt{2(\lambda+\chi_2)}} + e^{2\sqrt{2(\lambda+\chi_2)}(d+(h-x_0))}\dfrac{(u'_1 e^{-2\sqrt{2\lambda}d}-u'_2)}{\sqrt{2(\lambda+\chi_2)}(1-u'_1u'_2 e^{-2\sqrt{2\lambda}d})} & \hspace{1cm} & h+d<x_0
        \end{array}
      \right.
    \end{equation}
    \item {Quote various limits for $h,h+d$ on either side of 0}
    For have $h,h+d>0$
    \begin{align}
      f(x) =\frac{1}{\sqrt{2(\lambda+\chi_1)}} + e^{-2\sqrt{2(\lambda+\chi_1)}h}\frac{u'_2 e^{-2\sqrt{2\lambda}d}-u'_1 }{\sqrt{2(\lambda+\chi_1)}(1-u'_1u'_2 e^{-2\sqrt{2\lambda}d})}
    \end{align}

    For $h<0, h+d>0$ we need 
    \begin{equation}
      f(x) = \frac{1}{\sqrt{2\lambda}} + \frac{2u'_1u'_2 e^{-2\sqrt{2\lambda}d} + u'_1 e^{2\sqrt{2\lambda}h} +u'_2 e^{-2\sqrt{2\lambda}(d+h)}}{\sqrt{2\lambda}(1-u'_1u'_2 e^{-2\sqrt{2\lambda}d})}
    \end{equation}

    Finally, for $h,h+d<0$ we get 
    \begin{equation}
      f(x) =  \frac{1}{\sqrt{2(\lambda+\chi_2)}} + \frac{e^{2\sqrt{2(\lambda+\chi_2)}(d+h)}(u'_1 e^{-2\sqrt{2\lambda}d} - u'_2)}{\sqrt{2(\lambda+\chi_2)}(1-u'_1u'_2 e^{-2\sqrt{2\lambda}d})},
    \end{equation}
    with 
    \begin{equation}
      u'_i = \frac{e^{2\Xi}\sqrt{\lambda} -\sqrt{\lambda+\chi_i}}{e^{2\Xi}\sqrt{\lambda} + \sqrt{\lambda+\chi_i}},
    \end{equation}
  \item {Integrate over position}
    In exactly the same fashion, we can integrate over position.  
    \begin{align}
      I_{TM,12} =& -I_{div} + \dfrac{u'_2 e^{-2\sqrt{2\lambda}d}-u'_1}{4(\lambda+\chi_1)(1-u'_1u'_2 e^{-2\sqrt{2\lambda}d})} +\frac{2u'_1u'_2 e^{-\sqrt{2\lambda}d}d}{\sqrt{2\lambda}(1-u'_1u'_2 e^{-2\sqrt{2\lambda}d})} + (u'_1+u'_2)\frac{(1-e^{-2\sqrt{2\lambda}d})}{4\lambda(1-u'_1u'_2e^{-2\sqrt{2\lambda}d})}\nonumber\\
      & +\frac{u'_1 e^{-2\sqrt{2\lambda}d} - u'_2}{4(\lambda+\chi_2)(1-u'_1u'_2 e^{-2\sqrt{2\lambda}d})},
    \end{align}
    where $I_{div} = [2(\lambda+\chi_1)]^{-1/2}\int_{-\infty}^h dx_0  +  [2(\lambda+\chi_2)]^{-1/2}\int_{h+d}^\infty dx_0  + (2\lambda)^{-1/2}d$.
  \item Comment on divergent parts cancelling out. 
\end{itemize}

\section{Path Integral in Curved Space}

\begin{itemize}
  \item Path integral construction on metric-affine space is surprisingly complicated 
    and error-fraught.  
  \item Care is required in construction to get all terms.  
  \item Similar to multiplicative noise in SDE.
\end{itemize}

\begin{itemize}
  \item Given analogy of a medium to a curved space. Cite Leonhardt, Gordon  
  \item Note general requirement for $\mu=\epsilon$.  Hard to achieve, especially broadband.
  \item Application to TM path integral with rescaling $\epsilon$.
\end{itemize}

\subsection{Operators in Curved Space}

\begin{itemize}
  \item Quote Position Operator and inner product for spatial wavefunctions.
  \item Note only momentum operator consistent with that.
  \item Develop path integral
  \item Show it obeys the Schrodinger equation (Grosche's test)
\end{itemize}

\subsection{Transformation}

\begin{itemize}
  \item Start with flat-space path integral.\cite{Gervais1976, Kleinert2012}
  \item Introduce coordinate transformation
  \item Choose expansion point, expand consistently to $\order(\Delta T)$.
  \item Note connection to choice of stochastic calculus.
  \item Expand Jacobian factors
  \item Expand Gaussian factors
  \item Convert to terms involving curvature tensors.
  \item Simplify down to $1D$
  \item Note typically small value of quantum correction.  $\hbar^2$.
\end{itemize}


\section{Operator Quantization in Curved Space}

This follows from Bryce DeWitt's early papers \footnote{
DeWitt, B. S. \textit{Point Transformations in Quantum Mechanics}, 
{Phys. Rev.}, \textbf{85}, 653, 1952.\\
deWitt, B. S. \textit{Dynamical Theory in Curved Spaces I: A Review of the 
Classical and Quantum Action Principles}, {Rev. Mod. Phys.}, \textbf{29}, 377,(1957). } .
See also a review by Pauli\footnote{
Pauli, W., \textit{General Principles of Quantum Mechanics}, (1980), 
translated by P. Achuthan and K Venkatesan} 

There are two ways of deriving the path integral in curved space.  In the first 
formulation, we derive the relevant path integral in curved space
by starting with the curved space Hamiltonian and quantized appropriately.  
This requires changing the form of the momentum operators, which gain corrections.
This is in contrast to the second approach, which starts with a flat-space path
 integral, and transforms that path integral to curvilinear coordinates.
 We will use $x$ to denote the curvilinear coordinates, and $q_i$ to denote the flat-space coordinates.  

Consider the following particle Lagrangian,
\begin{equation}
L = \frac{1}{2}g_{ij}(x)\dot{x}^i\dot{x}^j
\end{equation}
with line element, $ds^2 = g_{ij} dx^i dx^j$, and volume element, 
$dV = \sqrt{|\det[g_{ij}]|}\prod_idx_i$.  

This has canonical momenta 
\begin{equation}
p_i := \frac{\partial L}{\partial \dot{x}^i} = g_{ij}\dot{x}^j.
\end{equation}

The equivalent Hamiltonian is 
\begin{align}
H & = p_i\dot{x}^i - L \\
& = \frac{1}{2} p_i g^{-1}_{ij}p_j = \frac{1}{2}p_i g^{ij}p_j,
\end{align}
where  ${g^{-1}}_{ij} = g^{ij}$ is the inverse metric.  

The choice of where to place the metric (which is a function of position)
 relative to the momentum operators is sometimes called the 
\textit{operator-ordering problem}.  We have no classical reason for picking
any one of the myriad quantum operator ordering choices.  
We will see that this operator ordering is related to our choice of stochastic calculus.  

\subsection{Quantization}

When we quantize this we require that the position and momentum obey the usual commutation relations
\begin{equation}
[x_i,p_j] = i\hbar\delta_{ij}.
\end{equation}
The other piece we need is representation of the identity for states.
 We will represent the spatial and momentum identity operators as 
\begin{gather}
\int d\vect{x} \sqrt{g} |\vect{x}\rangle \langle \vect{x}| = 1\\
\int \frac{d\vect{p}}{(2\pi\hbar)^d} |\vect{p}\rangle \langle \vect{p}| = 1
\end{gather}
This representation of the spatial identity implies the inner product between
is
\begin{equation}
\langle \phi |\psi\rangle = \int d\vect{x} \sqrt{g} \phi^*(x)\psi(x),
\end{equation}
where we have introduced the shorthand notation, $g = \det[g_{ij}]$.
The position space representation of the momentum operator can be de derived 
by seeking consistency with the commutation relations and ensuring that the 
momentum is a hermitian operator
\begin{equation}
\langle x| \op{p}_i|\psi\rangle = -i \frac{1}{g^{1/4}} \partial_i\left[ g^{1/4}\psi(x)\right] 
= -i\left(\partial_i +\frac{1}{4}\frac{\partial_i g}{g}\right)\psi(x).
\end{equation}
We can check the hermiticity by requiring 
$\langle\phi |\op{p}|\psi\rangle = \langle \psi |\op{p}\phi\rangle^{*}$.
  In position space this becomes 
\begin{align}
\langle \phi|\op{p}|\psi\rangle & = -i\int dx\,\sqrt{g}\phi^*(x) 
\frac{1}{g^{1/4}} \partial_x\left[ g^{1/4}\psi(x)\right]\\
& = i\int dx\,\partial_i\left[g^{1/4}\phi^*(x)\right] g^{1/4}\psi(x)\\
& = i\int dx\,\sqrt{g}\psi(x) \frac{1}{g^{1/4}}\partial_i\left[g^{1/4}\phi^*(x)\right]\\
& = \langle \psi |\op{p}|\phi\rangle^*
\end{align}
The spatial representation of the momentum operator can also be written
in terms of the Christoffel symbols,
\begin{equation}
 \frac{1}{g^{1/4}}\partial_i g^{1/4} f = \partial_i f + \frac{1}{4}\partial_i\ln(g)f.
\end{equation}
The Christoffel symbols are defined as
\begin{equation}
\Gamma_{ij}^k = \frac{1}{2}g^{kl}\left(\partial_ig_{jl}+\partial_jg_{li} 
  - \partial_lg_{ij}\right)
\end{equation}
We can trace over the Christoffel symbols, 
\begin{align}
\Gamma_{i} &= \Gamma_{ik}^k=\frac{1}{2}g^{kl}\left(\partial_ig_{kl}+\partial_kg_{li} 
  - \partial_lg_{ik}\right)\\
%&=\frac{1}{2}\left(g^{kl}\partial_ig_{kl}+\partial^lg_{li} 
%  - \partial_kg_{ik}\right)\\
&=\frac{1}{2}g^{kl}\partial_ig_{kl} = \frac{1}{2}{g^{-1}}_{kl}\partial_ig_{kl}
\end{align}
This can be rewritten using $\tr-\log(A) = \log\det(A)$.  Our expression
for the derivative involves,
\begin{equation}
\partial_i\log\det(g)=\partial_i\tr\log(A)=\tr\partial_i\log(A) = \tr[g^{-1}\partial_ig]
\end{equation}
We can then write the derivative operator as 
\begin{equation}
\langle \vect{q}|p_i|\psi\rangle 
= -i\hbar\left(\partial_i +\frac{1}{2}\Gamma_i\right)\psi(\vect{q})
\end{equation}

This is not quite the full covariant derivative one might anticipate,
\begin{equation}
\nabla_iV^j = \partial_iV^j + \Gamma_{ik}^jV^k
\end{equation}
However, the wavefunction is a scalar, rather than a vector, and thus
we are not tracking how the vector components are changed in a curved space. 
Perhaps this would emerge naturally for spinors (or spin-1 particles - say for
the photon?), where the wavefunction should be decomposed in terms of irreducible
represenations of whatever group we are working with?

We also need to specify the form of the matrix elements.  The matrix elements
are:
\begin{gather}
\langle \vect{q}|\vect{q'}\rangle = \frac{1}{\sqrt{g}}\delta(\vect{q}-\vect{q'})\\
\langle \vect{p}|\vect{p'}\rangle = \delta(\vect{p}-\vect{p'})\\
\langle \vect{q}|\vect{p}\rangle = \frac{e^{ip_iq^i/\hbar}}{\sqrt{2\pi\hbar }g^{1/4}}.
\end{gather}
The first two relations ensure that $I_x^2=I_x$, $I_p^2=I_p$ by returning delta-functions
with appropriate factors of the matrix.  
The third ensures the overlap integral is independent of the basis used.  


If we assume we have quantum Hamiltonian,
\begin{equation}
H = \frac{1}{2}\op{p}_ig^{ij}(\op{q})\op{p}_j
\end{equation}
then in position space, the Schrodinger equation is 
\begin{equation}
i\hbar \partial_t\psi = 
-\frac{\hbar^2}{2}\frac{1}{g^{1/4}}\partial_i g^{1/4}g^{ij}g^{1/4}\partial_j \frac{1}{g^{1/4}}\psi(q)
 = -\frac{\hbar^2}{2}\Delta_{\text{LB}}\psi
\end{equation}
This can be reordered into the form of the Laplace-Beltrami operator\footnote{
Kleinert, H. G. \textit{Path Integrals in Quantum Mechanics, Statistics, 
Polymer Physics and Financial Markets}, $5^{\text{th}}$ edition, Sec 1.13}
where the differential operator is the Laplace-Beltrami operator.  
The Laplace-Beltrami operator is the natural curved-space analogue of the 
flat-space Laplacian, $\Delta_{\text{LB}}f = \nabla^\mu \nabla_\mu f$.  
In curved space the divergence, and gradient are modified by the metric.
The Wikipedia article on the Laplace-Beltrami operator defines 
\begin{equation}
\Delta_{LB} = \frac{1}{g^{1/2}}\partial_i g^{1/2}g^{ij} \partial_j
\end{equation}
which differs by some ordering terms from the proposed quantum operator.  
The Laplace-Beltrami operator is given by 
\begin{align}
\nabla_i\nabla^i f &= \nabla_i(g^{in}\partial_n f)\\
&= [\partial_m+\Gamma_{im}^i](g^{mn}\partial_n f)\\
&= [\partial_m+(\partial_m\ln\sqrt{g})](g^{mn}\partial_n f)\\
&= \frac{1}{\sqrt{g}}\partial_m[\sqrt{g}(g^{mn}\partial_n f)]
\end{align}

\section{Point transformations as effective potentials}

I have found a paper by Gervais and Jevicki\footnote{Gervais, J.-L and  Jevicki,
 A. \textit{Point Canonical Transformations in the Path Integral},
 Nuclear Physics B, \textbf{110}, 93, (1976)} which covers similar ground 
to what we are treading.  
The following is my attempt to follow their work.
They also cite a relevant paper by McLaughlin and Schulman\footnote{
McLaughlin, D. W. and Schulman, L. S. \textit{Path Integrals in Curved Spaces}, 
J. Math. Phys. \textbf{12}, 2520, (1971)}.
The basic idea here is to shift a Cartesian path integral into curvilinear coordinates.
You then have to keep terms to fourth order when expanding the ``kinetic'' term
 in the path integral, and so second order in the Jacobian to find all terms 
that contribute to $\order(\Delta t)$.
Kleinert has a similar prescription.
This is very close to Bryce deWitt's work, although McLaughlin and Shulman carry it one further.
They then expand the higher order terms, and integrate against the Gaussian.
This leads to an effective potential.

\subsection{Definitions and variable transformation}
We start from the following Lagrangian,
\begin{equation}
L = \frac{1}{2}\dot{q}_a\dot{q}_a,
\end{equation}
where $a=1,\ldots D$, and we are employing the Einstein summation convention.  
We will suppress any potential terms, which can be added again at the end 
without modification.  

We start with the Euclidean space path-integral for the transition amplitude
from $q_0$ to $q_{N+1}$ in time $T$,
\begin{equation}
Z = \int \prod_{k=1}^Nd^Dq_i \frac{1}{\sqrt{2\pi\Delta T}}
\exp\left[ - \frac{\left(q_{a,k+1}-q_{a,k}\right)^2}{2\Delta T}\right].
\end{equation}

We now change variables to $q_i = F_i(Q_j)$.  This change of variables
effectively introduces curvature into the space.  
We will also introduce the metric tensor, 
\begin{equation}
g_{ij} = \partial_i F_a \partial_j F_a.
\end{equation}
This is closely related to the so-called \textit{vielbein} formalism 
(vielbien is German for many legs), 
which relates the local coordinates on the manifold to some Euclidean coordinates.
Carrol refers to this as a non-coordinate basis\footnote{Carrol, S., 
``Spacetime and Geometry'', Addison-Wesley, Appendix J}.  

\comment{This variable transformation depends only on the current time!
  Our version also requires a knowledge of the past.}
After the transformation the path integral is given by
\begin{equation}
Z = \int \prod_{i=1}^D\prod_{k=1}^NdQ_i(k) \left| \frac{\partial F_a}{\partial Q_{j}(k)}\right|
 \frac{1}{\sqrt{2\pi\Delta T}} \exp\left[ 
- \frac{\left[F_{a}(k+1)-F_a(k)\right]\left[F_{a}(k+1)-F_a(k)\right]}{2\Delta T}\right].
\end{equation}
where subscripts denote vector components, and parentheses are the ``time'' argument. 
 We can also relate the determinant of the Jacobian determinant to the determinant of the metric,
 $\left|\frac{\partial F_i}{\partial Q_j}\right| = \sqrt{|g_{ij}|}$.  The path-integral
can be written as
\begin{equation}
Z = g^{1/4}(Q_0)g^{1/4}(Q_N)\int \prod_{k=1}^N\frac{d^DQ(k)}{(2\pi\Delta T)^{D/2}} 
g^{1/4}(k)g^{1/4}(k+1) \exp\left[ - \frac{\left[F_{a}(k+1)-F_a(k)\right]^2}{2\Delta T}\right],
\end{equation}
where we have factoring the terms to be split across adjacent increments.  

\subsection{Expanding to $\order(\Delta T)$}

Our goal will be to develop the path integral by consistently expanding all terms
to first order in $\delta T$.  
We will use an Ito-like rule treating $\Delta q^2\sim\Delta T$. This 
reasoning follows from assuming the dominant contributions come when the 
argument of the exponential is of order one.  
In some terms we find we must expand up to to fourth order in $\Delta Q$. 

We will derive the path-integral in the so-called ``anypoint'' expansion, 
where we will Taylor expand the potentials from any point within $(Q(k),Q(k+1))$.

\subsubsection{Kinetic term}
We now want to expand the kinetic term to high enough order such that it is correct to $\order(\Delta T)$.
  We will Taylor expand each integral around
\begin{equation}
\bar{Q}(t) = \alpha Q(t+1)+(1-\alpha)Q(t),
\end{equation}
where $\alpha\in(0,1)$.  Some values of $\alpha$ correspond to particular 
choices of stochastic calculus:  Ito calculus emerges by expanding all functions
before the increment, so $\alpha=0$;  Stratonovich calculus comes from expanding
about the midpoint of the increment, $\alpha=1/2$; and anticipating calculus
by expanding about the end-point of the increment or $\alpha=1$.  This is mostly
done to make comparison with different results easier, rather than any inherent
superiority for this expansion.

We will use the increments $\Delta Q(t) =Q(t+1)-Q(t)$ as our integration
variables.  The basic trick will be to expand around $\bar{Q}$, and integrate
over $\Delta Q(t)$, treating each Gaussian integral independently.  

The positions can be rewritten in terms of these new variables,
\begin{align}
Q(t) &= \bar{Q}(t)-\alpha\Delta Q(t)\\
Q(t+1) &= \bar{Q}(t)+(1-\alpha)\Delta Q(t).
\end{align}
We drop the $(t)$ labels, since we will be focusing on one particular time in
what follows.  
The Taylor expansion for position, $q_a=F_a(Q)$ around $\bar{Q}$ is then 
\begin{align}
F_a(t) &= F_a\left[\bar{\vect{Q}} -\alpha\vect{\Delta Q}\right]\\
&\approx F_a(\bar{Q}) -\alpha \Delta Q_i \partial_i F_a 
+\frac{\alpha^2}{2!}\Delta Q_i\Delta Q_j\partial_i\partial_j F_a 
-\frac{\alpha^3}{3!}\Delta Q_i\Delta Q_j\Delta Q_k\partial_i\partial_j\partial_kF_a.
\end{align}
Similarly, we can expand $q_a(t+1)$
\begin{align}
F_a(t+1) &= F_a\left[\bar{\vect{Q}} +(1-\alpha)\vect{\Delta Q}\right]\\
&\approx F_a(\bar{Q}) +(1-\alpha) \Delta Q_i \partial_i F_a 
+\frac{(1-\alpha)^2}{2!}\Delta Q_i\Delta Q_j\partial_i\partial_j F_a \nonumber\\
&+\frac{(1-\alpha)^3}{3!}\Delta Q_i\Delta Q_j\Delta Q_k\partial_i\partial_j\partial_kF_a.
\end{align}
The increment $dq_a$ then follows from subtracting these results from each other:
\begin{align}
F_a(t+1)-F_a(t)%   &\approx (1-1)F_a(\bar{Q}) +[(1-\alpha)-(-\alpha)] \Delta Q_i \partial_i F_a \nonumber\\
% & +\frac{(1-\alpha)^2-\alpha^2}{2!}\Delta Q_i\Delta Q_j\partial_i\partial_j F_a \nonumber\\
% & +\frac{(1-\alpha)^3-(-\alpha^3)}{3!}\Delta Q_i\Delta Q_j\Delta Q_k\partial_i\partial_j\partial_kF_a\\
&\approx \Delta Q_i \partial_i F_a +\frac{(1-2\alpha)}{2}\Delta Q_i\Delta Q_j\partial_i\partial_j F_a \nonumber\\
&+\frac{(1-3\alpha+3\alpha^2)}{6}\Delta Q_i\Delta Q_j\Delta Q_k\partial_i\partial_j\partial_kF_a.
\end{align}
where all the functions are evaluated at $\bar{Q}(t)$.  
We will now substitute this increment into the kinetic energy term of the path integral.  
The leading order term predicts that $\Delta Q^2\sim\Delta T$.  
We will need to keep terms to $\order(\Delta Q^4)$ to get a result 
consistent to $\order(\Delta T)$.
The kinetic term of the path integral can then be rewritten as 
\begin{align}
\Delta T \dot{q}_a\dot{q}_a & = \frac{1}{\Delta T}\big[
\Delta Q_i \partial_i F_a 
+\frac{(1-2\alpha)}{2}\Delta Q_i\Delta Q_j\partial_i\partial_j F_a 
+\frac{(1-3\alpha+3\alpha^2)}{6}\Delta Q_i\Delta Q_j\Delta Q_k\partial_i\partial_j\partial_kF_a\big]^2\\
& = \frac{1}{\Delta T}\bigg[
\Delta Q_i \Delta Q_r\partial_i F_a \partial_r F_a \nonumber\\
&\hspace{1.5cm}+(1-2\alpha)\Delta Q_i \Delta Q_j\Delta Q_k\partial_i F_a\partial_j\partial_kF_a  \nonumber\\
&\hspace{1.5cm}+\left(\frac{1}{3}-\alpha+\alpha^2\right)\Delta Q_i \Delta Q_j\Delta Q_k\Delta Q_l\partial_i F_a 
\partial_j\partial_k\partial_lF_a\nonumber\\
&\hspace{1.5cm}+\left(\frac{1}{4}-\alpha+\alpha^2\right)\Delta Q_i\Delta Q_j\Delta Q_k\Delta Q_l
\partial_i\partial_j F_a\partial_k\partial_lF_a\bigg]
% &=\frac{1}{\Delta T}\left[\Delta Q_i \Delta Q_j\partial_j F_a\partial_i F_a 
% + \frac{1}{12}\Delta Q_i\Delta Q_j\Delta Q_k\Delta Q_l\partial_i\partial_j\partial_kF_a\partial_lF_a\right]\\
\end{align}
That strange fourth order term will lead to an extra potential of order $\Delta T$.    

%Can we combine some terms and perhaps re-express this in slightly simpler terms?
We can simplify this a little if we define the metric tensor as
\begin{equation}
  g_{ij} = \partial_iF_a\partial_jF_a,
\end{equation}
which is related to the non-coordinate basis (defined in terms of orthonormal
vectors - and the vierbein).
The corresponding inverse metric is 
\begin{equation}
  g^{ij} = \partial_aQ^i\partial_aQ^j,
\end{equation}
where $\partial_a$ denotes $\frac{\partial}{\partial F^a}$.
Some work rephrases this in terms of the Christoffel symbols and the Ricci
scalar (which is defined in terms of Christoffel symbols and their derivatives).
% The final potential we arrive at should be proportional to the Ricci scalar times 
% $\hbar^2$.  I will hold off on simplification until the end.    
For example the first derivative of the metric is, 
\begin{equation}
\partial_k(g_{ij})=\partial_k(\partial_iF_a\partial_jF_a) =
 \partial_i\partial_kF_a\partial_jF_a+\partial_iF_a\partial_j\partial_kF_a.
\end{equation}
The second derivative is more complicated, 
\begin{align}
\partial_{k}\partial_l(\partial_iF_a\partial_jF_a) 
% &=\partial_l( \partial_i\partial_kF_a\partial_jF_a+\partial_iF_a\partial_j\partial_kF_a)\nonumber\\
% &=\partial_i\partial_k\partial_lF_a\partial_jF_a+\partial_i\partial_kF_a\partial_j\partial_lF_a
% +\partial_i\partial_lF_a\partial_j\partial_kF_a +\partial_iF_a\partial_j\partial_k\partial_lF_a\nonumber\\
&=2(\partial_i\partial_k\partial_lF_a\partial_jF_a+\partial_i\partial_kF_a\partial_j\partial_lF_a),
\end{align}
where we simplified since we will multiply by a completely symmetric tensor.    

The Christoffel symbols are defined as
\begin{gather}
  [ij,l]=\frac{1}{2}(\partial_ig_{jl}+\partial_jg_{li}-\partial_lg_{ij})\\
  \Gamma_{ij}^k = g^{kl}[ij,l],
\end{gather}
and for our metric they are given by 
\begin{align}
  [ij,l]&=\frac{1}{2}[\partial_i(\partial_jF^a\partial_l F^a)
  +\partial_j(\partial_lF^a\partial_i F^a)
  -\partial_l(\partial_iF^a\partial_j F^a)]\\
  &= \partial_lF^a\partial_i\partial_j F^a
\end{align}
Their derivatives are
\begin{align}
 \partial_k[ij,l] &= \partial_k\partial_lF^a\partial_i\partial_j F^a 
+ \partial_lF^a\partial_i\partial_j\partial_k F^a
\end{align}

The kinetic term can be more compactly written as
\begin{align}
\Delta T \dot{q}_a\dot{q}_a & 
& = \frac{1}{\Delta T}\bigg[
\Delta Q_i \Delta Q_r\partial_i F_a \partial_r F_a \nonumber\\
&\hspace{1.5cm}+(1-2\alpha)\Delta Q_i \Delta Q_j\Delta Q_k[ij,k]  \nonumber\\
&\hspace{1.5cm}+\left(\frac{1}{3}-\alpha+\alpha^2\right)\Delta Q_i \Delta Q_j\Delta Q_k\Delta Q_l\partial_i F_a 
\partial_j\partial_k\partial_lF_a\nonumber\\
&\hspace{1.5cm}+\left(\frac{1}{4}-\alpha+\alpha^2\right)\Delta Q_i\Delta Q_j\Delta Q_k\Delta Q_l
\partial_i\partial_j F_a\partial_k\partial_lF_a\bigg]
% &=\frac{1}{\Delta T}\left[\Delta Q_i \Delta Q_j\partial_j F_a\partial_i F_a 
% + \frac{1}{12}\Delta Q_i\Delta Q_j\Delta Q_k\Delta Q_l\partial_i\partial_j\partial_kF_a\partial_lF_a\right]\\
\end{align}



The Riemann curvature tensor is in general refined as
\begin{align}
  {R^{r}}_{smn}=\partial_m\Gamma^{r}_{ns}-\partial_n \Gamma^{r}_{ms}
  +\Gamma^{r}_{ml}\Gamma^l_{ns} - +\Gamma^{r}_{nl}\Gamma^l_{ms}
\end{align}
The Ricci tensor is 
\begin{align}
  {R^{r}}_{srn}=\partial_r\Gamma^{r}_{ns}-\partial_n \Gamma^{r}_{rs}
  +\Gamma^{r}_{rl}\Gamma^l_{ns} - \Gamma^{r}_{nl}\Gamma^l_{rs},
\end{align}
and the Ricci scalar is 
\begin{align}
  g^{ns}{R^{r}}_{srn}=g^{ns}\partial_r\Gamma^{r}_{ns}-g^{ns}\partial_n \Gamma^{r}_{rs}
  +g^{ns}\Gamma^{r}_{rl}\Gamma^l_{ns} - g^{ns}\Gamma^{r}_{nl}\Gamma^l_{rs}.
\end{align}
DeWitt showed that the quantum corrections to the path integral we will derive
involve coupling to the Ricci scalar.  


The kinetic term can be rewritten in terms of the metric and its derivatives
as
\begin{align}
\Delta T^2 \dot{q}_a\dot{q}_a % &= \frac{1}{\Delta T}\big[
% \Delta Q_i \Delta Q_rg_{ir} \nonumber\\
% &+\frac{(1-2\alpha)}{2}\Delta Q_i \Delta Q_j\Delta Q_k\partial_kg_{ij}  \nonumber\\
% &+\frac{(2-6\alpha+6\alpha^2)}{6}\Delta Q_i \Delta Q_j\Delta Q_k\Delta Q_l\partial_i F_a 
% \partial_j\partial_k\partial_lF_a\nonumber\\
% &+\frac{1-4\alpha+4\alpha^2}{4}\Delta Q_i\Delta Q_j\Delta Q_k\Delta Q_l
% \partial_i\partial_j F_a\partial_k\partial_lF_a\big]\\
% &= \Delta Q_i \Delta Q_rg_{ir} \nonumber\\
% &+\frac{(1-2\alpha)}{2}\Delta Q_i \Delta Q_j\Delta Q_k\partial_kg_{ij}  \nonumber\\
% &+\left(\alpha-\frac{1}{2}\right)^2\Delta Q_i \Delta Q_j\Delta Q_k\Delta Q_l
% (\partial_i F_a \partial_j\partial_k\partial_lF_a
% +\partial_i\partial_j F_a\partial_k\partial_lF_a)\nonumber\\
% &+\Delta Q_i \Delta Q_j\Delta Q_k\Delta Q_l\left(\frac{1}{12}\partial_i F_a 
% \partial_j\partial_k\partial_lF_a\right)\nonumber\\
&= \Delta Q_i \Delta Q_rg_{ir} \nonumber\\
&+\frac{(1-2\alpha)}{2}\Delta Q_i \Delta Q_j\Delta Q_k\partial_kg_{ij}  \nonumber\\
&+\frac{1}{2}\left(\alpha-\frac{1}{2}\right)^2\Delta Q_i \Delta Q_j\Delta Q_k\Delta Q_l
\partial_j\partial_kg_{il}\nonumber\\
&+\Delta Q_i \Delta Q_j\Delta Q_k\Delta Q_l\left(\frac{1}{12}\partial_i F_a 
\partial_j\partial_k\partial_lF_a\right)\nonumber\\
\end{align}





\subsubsection{Jacobian determinant}
\comment{I think this is heavily influenced by Gr\"osche's work.}
Further to this, we must also expand the Jacobian factors
 in the measure of the path integral
\begin{equation}
J=g^{1/4}(t+1)g^{1/4}(t)\label{eq:jacobian}.
\end{equation}
We need to also expand this to quadratic order in $\Delta T$.  
We can do this by using the following form of the determinant
\begin{equation}
\det(A) = e^{\tr\ln A}.\label{eq:exp det}
\end{equation}

At the risk of being dopey, let's just expand directly in terms of $F_a(Q)$,
rather than in terms of the effective metric tensor.    

The Jacobian factor arises from changing variable, 
\begin{equation}
J(t)=\left|\frac{\partial F_a(t)}{\partial q_i}\right| 
= \left|\frac{\partial F_a(t)}{\partial q_i}\frac{\partial F_a(t)}{\partial q_j}\right|^{1/2}
\end{equation}
This can be justified by thinking of $\frac{\partial F_a(t)}{\partial q_i}$
as an orthogonal transformation~\footnote{Schutz, B., \textit{Geometrical Methods of Mathematical Physics},(1980),pg. 133}.
  In effect, we are demanding that $g_{ij} = (\Lambda)^TI\Lambda$, 
where we assumed that the $q_i$ where orthonormal, 
and thus their metric was the identity.   
The determinant of the metric tensor is then
\begin{equation}
\det[g] = \det[ \Lambda^T I\Lambda] = (\det\Lambda)^2 = \det\left(\frac{\partial F_a}{\partial q_j}\right).
\end{equation}

In order to proceed we will carry out the expansion to second order in $\Delta Q$.  
The expansion of the metric tensor to second order in $\Delta Q$,
\begin{align}
g_{ij}[Q(t+1)] &= g_{ij}[\bar{\vect{Q}}+(1-\alpha)\vect{\Delta Q}]\\
&= g_{ij}[\bar{\vect{Q}}] + (1-\alpha)\Delta Q_k \partial_kg_{ij}[\vect{\bar Q}]
+ \frac{(1-\alpha)^2}{2!}\Delta Q_k\Delta Q_l \partial_k\partial_lg_{ij}[\vect{\bar Q}]
\label{eq:expand g}
\end{align}
We will also need to expand the logarithm for matrices using
\begin{equation}
\log[\underbar{g} + \underbar{A}] = \log\underbar{g}+\log(\underbar{I}+\underbar{g}^{-1}\underbar{A}) 
= \log\underbar{g} + \underbar{g}^{-1}\underbar{A} -\frac{1}{2}\underbar{g}^{-1}{\underbar{A}}{\underbar{g}^{-1}}\underbar{A}
\label{eq:log g}
\end{equation}
where we use $\underbar{A}$ to denote a matrix.  
Combining relations~(\ref{eq:log g}) and (\ref{eq:expand g}), with the 
exponential representation of the determinant, we find 
\begin{align}
g^{1/4}(t+1) = & \exp\left\{\frac{1}{4}\tr\log[g_{ij}(t+1)]\right\}\\
= & \exp\left\{\frac{1}{4}\tr\log[\bar{g}_{ij}]
+\frac{1}{4}\tr\log\left[\delta^n_j+(1-\alpha)\Delta Q_k \bar{g}^{ni}\partial_k\bar{g}_{ij}
+ \frac{(1-\alpha)^2}{2!}\Delta Q_k\Delta Q_l \bar{g}^{nj}\partial_k\partial_l\bar{g}_{ij}
\right]\right\}\\
= & \bar{g}^{1/4}\exp\bigg\{
\frac{1}{4}\big[(1- \alpha)\Delta Q_k \bar{g}^{ji}\partial_k\bar{g}_{ij}\nonumber\\
&+ \frac{(1-\alpha)^2}{2}\Delta Q_k\Delta Q_l 
\big(\bar{g}^{ji}\partial_k\partial_l\bar{g}_{ij}
-\bar{g}^{js}\partial_k\bar{g}_{sm}\bar{g}^{mr}\partial_k\bar{g}_{rj}\big)
\big]\bigg\},
\end{align}
where in the first line we factored out Taylor expanded around $\bar{Q}$ inside
the logarithm, and then expanded the logarithm to second order and took the 
trace.
There is an analogous term from the pre-step, which we can recover by taking
$(1-\alpha)\rightarrow(-\alpha)$.  
\begin{align}
g^{1/4}(t) = & \exp\left\{\frac{1}{4}\tr\log[g_{ij}(t)]\right\}\\
= & \bar{g}^{1/4}\exp\bigg\{
\frac{1}{4}\big[-\alpha\Delta Q_k \bar{g}^{ji}\partial_k\bar{g}_{ij}\nonumber\\
&+\frac{\alpha^2}{2}\Delta Q_k\Delta Q_l 
\big(\bar{g}^{ji}\partial_k\partial_l\bar{g}_{ij}
-\bar{g}^{js}\partial_k\bar{g}_{sm}\bar{g}^{mr}\partial_k\bar{g}_{rj}\big)
\big]\bigg\}
\end{align}
These can be combined together to yield, 
\begin{align}
g^{1/4}(t+1)g^{1/4}(t) =& \bar{g}^{1/2}\exp\bigg\{
\frac{1}{4}\big[(1-2\alpha)\Delta Q_k \bar{g}^{ji}\partial_k\bar{g}_{ij}\nonumber\\
&+ \frac{1-2\alpha+2\alpha^2}{2}\Delta Q_k\Delta Q_l 
\big(\bar{g}^{ji}\partial_k\partial_l\bar{g}_{ij}
-\bar{g}^{js}\partial_k\bar{g}_{sm}\bar{g}^{mr}\partial_k\bar{g}_{rj}\big)
\big]\bigg\}
\end{align}


\subsection{Evaluating higher order moments}

We can now expand the exponential terms up to quartic order in $\Delta T$,
and then replace the increments with their ensemble averages.  
Each term in $\Delta Q$ can be treated as a Gaussian integral, 
and we can exploit the Gaussian moment theorem (or Wick's theorem).  
We will then be able to re-exponentiate these expressions to find 
the final effective potential. 

\subsubsection{Gaussian Integrals}

First up we need to compute 
\begin{equation}
I_2 = \int d^Dx\,\frac{g^{1/2}}{(2\pi\Delta T)^{D/2}}  e^{-\frac{x_ig_{ij}x_j}{2\Delta T}}x_a x_b
\end{equation}

Let uss change variables to $y$ where $g_{ij}y_j = \lambda_jy_i$, i.e. the principle basis of $g$.
We can write expand the old coordinates in terms of the new ones via a unitary transformation $x_i = O_{ij}y_j$.
We can also write the determinant as $g = \det[g_{ij}] = \prod_i \lambda_i$.
The matrix $g_{ij} = O_{ik}O_{jm}\delta_{km}\lambda_m.$  
The integral is then
\begin{equation}
I_2 = \int d^Dy\,\frac{\prod_i \lambda_i^{1/2}}{(2\pi\Delta T)^{D/2}} 
 e^{-\frac{-\lambda_i}{2\Delta T} y_i^2} O_{aj}O_{bk}y_jy_k.
\end{equation}
We can evaluate this from symmetry.
If $j\ne k$, the integrand is odd and the integral vanishes.
However for $j=k$, we are finding the integral for $D-1$ normalized Gaussians,
 and one variance.
So the answer is 
\begin{equation}
\boxed{  I_2 = O_{aj}O_{bk}\delta_{jk}\frac{\Delta T}{\lambda_j}
 = \Delta Tg^{-1}_{ab} = \Delta T g^{ab}.}
\end{equation}

Similarly, we need to evaluate 
\begin{equation}
I_4 = \int d^Dx\,\frac{g^{1/2}}{(2\pi\Delta T)^{D/2}}
  e^{-\frac{x_ig_{ij}x_j}{2\Delta T}}x_a x_b x_c x_d
\end{equation}
The same logic can be traced through for all pairs of contracted indices.    
In this case we get 
\begin{equation}
\boxed{I_4 = \Delta T^2(g^{ab}g^{cd} + g^{ac}g^{bd} + g^{ad}g^{bc}).}
\end{equation}
Note that this term shows up as $I_4/\Delta T$, so this is order $\Delta T$.  

We will set the integrals that have odd powers of $\Delta Q$ to zero.  

\subsubsection{Expanding Exponential}

The transformed path integral is 
\begin{align}
I=\,& \int \frac{d^Dq_i}{(2\pi \Delta T)^{D/2}} e^{-(q_iq_i)/(2\Delta T)}\\
=\,&\int \frac{d^DQ_i}{(2\pi \Delta T)^{D/2}}\bar{g}^{1/2}
\exp\bigg[-\frac{\Delta Q_i \Delta Q_rg_{ir}}{2\Delta T}\bigg] \nonumber\\
&\times\exp\bigg\{
\frac{1}{4}\big[(1-2\alpha)\Delta Q_k \bar{g}^{ji}\partial_k\bar{g}_{ij}\nonumber\\
&+ \frac{1-2\alpha+2\alpha^2}{2}\Delta Q_k\Delta Q_l 
\big(\bar{g}^{ji}\partial_k\partial_l\bar{g}_{ij}
-\bar{g}^{js}\partial_k\bar{g}_{sm}\bar{g}^{mr}\partial_k\bar{g}_{rj}\big)
\big]\bigg\}\nonumber\\
&\times\exp\bigg\{-\frac{1}{2\Delta T}\big[
\frac{(1-2\alpha)}{2}\Delta Q_i \Delta Q_j\Delta Q_k\partial_k\bar{g}_{ij}  \nonumber\\
&+\frac{1}{2}\left(\alpha-\frac{1}{2}\right)^2\Delta Q_i \Delta Q_j\Delta Q_k\Delta Q_l
\partial_j\partial_k\bar{g}_{il}\nonumber\\
&+\frac{1}{12}\Delta Q_i \Delta Q_j\Delta Q_k\Delta Q_l\partial_i F_a 
\partial_j\partial_k\partial_lF_a
\big]\bigg\}
\end{align}
The exponential can be expanded in powers of $\Delta Q$ as 
% \begin{align}
% I=\,&\int \frac{d^DQ_i}{(2\pi \Delta T)^{D/2}}\bar{g}^{1/2}e^{-\Delta Q_i \Delta Q_rg_{ir}/(2\Delta T)} \nonumber\\
% &\times\bigg\{1+\frac{1}{4}\big[(1-2\alpha)\Delta Q_k \bar{g}^{ji}\partial_k\bar{g}_{ij}
% \nonumber\\
% &+\frac{1}{2\cdot 4^2}(1-2\alpha)^2\Delta Q_l\Delta Q_k 
% \bar{g}^{rs}\partial_l\bar{g}_{rs}\bar{g}^{ji}\partial_k\bar{g}_{ij}\nonumber\\
% &+ \frac{1-2\alpha+2\alpha^2}{2}\Delta Q_k\Delta Q_l 
% \big(\bar{g}^{ji}\partial_k\partial_l\bar{g}_{ij}
% -\bar{g}^{js}\partial_k\bar{g}_{sm}\bar{g}^{mr}\partial_k\bar{g}_{rj}\big)
% \big]\bigg\}
% \nonumber\\
% &\times\bigg\{1
% -\big[1+\frac{1}{4}\big[(1-2\alpha)\Delta Q_k \bar{g}^{ji}\partial_k\bar{g}_{ij}\big]\nonumber
% \times\frac{(1-2\alpha)}{4\Delta T}\Delta Q_i \Delta Q_j\Delta Q_k\partial_k\bar{g}_{ij}  \nonumber\\
% &-\frac{(1-2\alpha)^2}{2(4\Delta T)^2}\Delta Q_i \Delta Q_j\Delta Q_k
% \Delta Q_r \Delta Q_s\Delta Q_t\partial_r\bar{g}_{st}\partial_k\bar{g}_{ij}  \nonumber\\
% &-\frac{1}{4\Delta T}\left(\alpha-\frac{1}{2}\right)^2\Delta Q_i \Delta Q_j\Delta Q_k\Delta Q_l
% \partial_j\partial_k\bar{g}_{il}\nonumber\\
% &-\frac{1}{24\Delta T}\Delta Q_i \Delta Q_j\Delta Q_k\Delta Q_l\partial_i F_a 
% \partial_j\partial_k\partial_lF_a
% \big]\bigg\}  %Expand exponentials to Order(Delta T), and include cross term.
% \end{align}
% \begin{align}
% I=\,&\int \frac{d^DQ_i}{(2\pi \Delta T)^{D/2}}\bar{g}^{1/2}e^{-\Delta Q_i \Delta Q_rg_{ir}/(2\Delta T)} \nonumber\\
% &\times\bigg\{1+\frac{1}{4}(1-2\alpha)\Delta Q_k \bar{g}^{ji}\partial_k\bar{g}_{ij}
% +\frac{1}{2\cdot 4^2}(1-2\alpha)^2\Delta Q_l\Delta Q_k 
% \bar{g}^{rs}\partial_k\bar{g}_{rs}\bar{g}^{ji}\partial_l\bar{g}_{ij}\nonumber\\
% &+ \frac{1-2\alpha+2\alpha^2}{8}\Delta Q_k\Delta Q_l 
% \big(\bar{g}^{ji}\partial_k\partial_l\bar{g}_{ij}
% -\bar{g}^{js}\partial_k\bar{g}_{sm}\bar{g}^{mr}\partial_k\bar{g}_{rj}\big)
% \nonumber\\
% &-\frac{(1-2\alpha)}{4\Delta T}\Delta Q_i \Delta Q_j\Delta Q_k\partial_k\bar{g}_{ij}
% -\frac{(1-2\alpha)^2}{16\Delta T} \bar{g}^{ji}\partial_k\bar{g}_{ij}
% \partial_r\bar{g}_{st}\Delta Q_k\Delta Q_r \Delta Q_s\Delta Q_t  \nonumber\\
% %
% &-\frac{(1-2\alpha)^2}{2(4\Delta T)^2}\partial_r\bar{g}_{st}\partial_k\bar{g}_{ij}
% \Delta Q_r \Delta Q_s\Delta Q_t\Delta Q_i \Delta Q_j\Delta Q_k  \nonumber\\%6
% &-\frac{1}{4\Delta T}\left(\alpha-\frac{1}{2}\right)^2\partial_j\partial_k\bar{g}_{il}
% \Delta Q_i \Delta Q_j\Delta Q_k\Delta Q_l\nonumber\\ %4
% &-\frac{1}{24\Delta T}\partial_i F_a \partial_j\partial_k\partial_lF_a
% \Delta Q_i \Delta Q_j\Delta Q_k\Delta Q_l %4
% \big]\bigg\}  %Expand (keep odd terms - give velocities?)
\begin{align}
I=\,&\int \frac{d^DQ_i}{(2\pi \Delta T)^{D/2}}\bar{g}^{1/2}e^{-\Delta Q_i \Delta Q_rg_{ir}/(2\Delta T)} \nonumber\\
&\times\bigg\{1+\frac{1}{4}(1-2\alpha)\Delta Q_k \bar{g}^{ji}\partial_k\bar{g}_{ij}
-\frac{(1-2\alpha)}{4\Delta T}\partial_k\bar{g}_{ij}\Delta T
(\bar{g}^{jk}\Delta Q_i+\bar{g}^{ki}\Delta Q_j+\bar{g}^{ij}\Delta Q_k)\nonumber\\
&
-\frac{1}{8}\left(\frac{3}{4}-\alpha+\alpha^2\right)
\bar{g}^{rs}\partial_k\bar{g}_{rs}\bar{g}^{ji}\partial_l\bar{g}_{ij}\Delta T \bar{g}^{kl} \nonumber\\
&+ \frac{1-2\alpha+2\alpha^2}{8}\big(\bar{g}^{ji}\partial_k\partial_l\bar{g}_{ij}
\big)\Delta T \bar{g}^{kl}
\nonumber\\
&
-\frac{(1-2\alpha)^2}{16\Delta T} \bar{g}^{ji}\partial_k\bar{g}_{ij}
\partial_r\bar{g}_{st}\Delta T^2\left[\bar{g}^{kr}\bar{g}^{st} +\bar{g}^{ks}\bar{g}^{rt}+\bar{g}^{kt}\bar{g}^{rs} \right] \nonumber\\
%
&-\frac{(1-2\alpha)^2}{2(4\Delta T)^2}\partial_r\bar{g}_{st}\partial_k\bar{g}_{ij}
\Delta Q_r \Delta Q_s\Delta Q_t\Delta Q_i \Delta Q_j\Delta Q_k  \nonumber\\%6
&-\frac{1}{4\Delta T}\left(\alpha-\frac{1}{2}\right)^2\partial_j\partial_k\bar{g}_{il}
\Delta T^2[ \bar{g}^{ij}\bar{g}^{kl} + \bar{g}^{ik}\bar{g}^{jl}+\bar{g}^{il}\bar{g}^{jk}]\nonumber\\ %4
&-\frac{1}{24\Delta T}\partial_i F_a \partial_j\partial_k\partial_lF_a
\Delta T^2[ \bar{g}^{ij}\bar{g}^{kl} + \bar{g}^{ik}\bar{g}^{jl}+\bar{g}^{il}\bar{g}^{jk}]
\big]\bigg\}  %Replace moments.  and drop odd terms.  
\end{align}

\subsection{Screwing around with symbols}

The metric is defined as
\begin{equation}
g_{ij} =\partial_iF_a\partial_jF_a.
\end{equation}
The Christoffel symbols and the Riemann curvature tensor are defined in terms
of the metric as:
\begin{align}
\Gamma_{ij}^k &= g^{kl}(\partial_ig_{jl}+\partial_jg_{li}-\partial_lg_{ij})\\
&= g^{kl}[\partial_i(\partial_j F_a\partial_lF_a)+\partial_j(\partial_lF_a\partial_iF_a)
-\partial_l(\partial_iF_a\partial_jF_a)]\\
&= g^{kl}[\partial_i\partial_j F_a\partial_lF_a+\partial_lF_a\partial_j\partial_iF_a]\\
%
{R^{i}}_{jkl} &=\partial_k\Gamma_{jl}^i-\partial_l\Gamma_{jk}^i
+\Gamma^i_{km}\Gamma^{m}_{jl}-\Gamma^i_{jm}\Gamma^m_{kl}
\end{align}
Note that the curvature tensor is defined in terms of the connection, and we
will normally choose the Christoffel connection.  

\comment{Gervais and Jevicki have odd definition?} 
They define the Christoffel
symbols via:
\begin{equation}
  \partial_{i}\partial_jF^a = \Gamma^{l}_{ij}\partial_lF^a
\end{equation}
(I think this is consistent with the way Carrol does it.  )
Note this amounts to asserting metric compatibility of the connection,
or $\nabla_\sigma g_{\mu\nu} = 0$.  

Recall that $\nabla_\mu \omega_\nu = \partial_\mu\omega_\nu - \Gamma_{\mu\nu}^\kappa\omega_\kappa$,
and $\nabla_\mu A^\nu = \partial_\mu A^\nu + \Gamma_{\mu\kappa}^\nu A_\kappa$,


\subsection{Joining results}

So we had a path integral
\begin{equation}
Z = g^{1/4}(Q_0)g^{1/4}(Q_N)\int \prod_{k=1}^N\frac{d^DQ(k)}{\sqrt{2\pi\Delta T}} g^{1/4}(k)g^{1/4}(k+1) \exp\left[ - \frac{\left[F_{a}(k+1)-F_a(k)\right]^2}{2\Delta T} - \Delta T V(Q(k))\right].
\end{equation}
We have expanded the $\dot{q}^2 = \Delta F^2$ and $g^{1/4}$ terms out to linear order in $\Delta T$.  This can be exponentiated.  
\begin{align}
Z =& g^{1/4}(Q_0)g^{1/4}(Q_N)\int \prod_{k=1}^N\frac{d^DQ(k)}{\sqrt{2\pi\Delta T}} \sqrt{\bar{g}}\left[ 1+\frac{\Delta Q_i\Delta Q_j}{16}\left(\partial_i g^{ab}\partial_j g_{ba}  + g^{ab}\partial_{ij}^2 g_{ba}\right)  \right]\nonumber\\
&\times \left[1- \frac{1}{24\Delta T}\Delta Q_i\Delta Q_j\Delta Q_k\Delta Q_l\left(\partial_i\partial_j\partial_kF_a\partial_lF_a\right)\right]\nonumber\\
&\times\exp\left[ - \frac{1}{2\Delta T}\Delta Q_i g_{ij}\Delta Q_j - \Delta T V(Q(k))\right].
\end{align}



The result is 
\begin{equation}
Z \approx g^{1/4}(Q_0)g^{1/4}(Q_N)\int \prod_{k=1}^Nd^DQ(k) \bar{g}^{1/2}(k)\frac{1}{\sqrt{2\pi\Delta T}} \exp\left[ -\frac{1}{2\Delta T}\Delta Q_i g_{ij}\Delta Q_j - \Delta T V(Q(k)) - \Delta T V_\text{extra}\right],
\end{equation}
where 
\begin{equation}
V_\text{extra} = -\frac{1}{16}g^{ij}\left(\partial_i g^{ab}\partial_j g_{ba}  + g^{ab}\partial_{ij}^2 g_{ba}\right)+  \frac{1}{24}(g^{ij}g^{kl} + g^{il}g^{jk} + g^{ik}g^{jl})\left(\partial_i\partial_j\partial_kF_a\partial_lF_a\right).
\end{equation}
We can see that all of the terms in the second part are the same by symmetry, so we can write
\begin{equation}
V_\text{extra} = -\frac{1}{16}g^{ij}\left(\partial_i g^{ab}\partial_j g_{ba}  + g^{ab}\partial_{ij}^2 g_{ba}\right)+  \frac{1}{8}g^{ij}g^{kl}\left(\partial_i\partial_j\partial_kF_a\partial_lF_a\right).
\end{equation}
This agrees with Gervais and Jevicki.  They then proceed to phrase this in terms of Christoffel symbols, which makes for more compact form of the potential.  

\section{Stratonovich-Ito conversion}

For the moment, let us assume we have a path integral
\begin{equation}
Z = \int \prod_k \frac{dx_k}{\sqrt{2\pi\Delta T\sigma^2(\bar{x}_k)}} e^{-\frac{(x_{k+1}-x_k)^2}{2\Delta T\sigma^2(\bar{x}_k)}}
\end{equation}
Let us now convert this to an Ito ordering.  This is similar material to covered in Chapter 5 of Langouche\footnote{Langouche, F., Roekaerts, D. and Tirapegui, E. \textit{Functional Integration and Semiclassical Expansions}, (1982)} where they also discuss the relation between different orderings, and then shifting the point of the evaluation.  

We will expand each matrix element to $\order(\Delta T)$.  

A table of derivatives
\begin{gather}
 f= \frac{1}{\sigma^2}\\
f' = -\frac{2\sigma'}{\sigma^3}\\
f'' = -\frac{2\sigma''}{\sigma^3} + 6\frac{(\sigma')^2}{\sigma^4}
\end{gather}

First up we can expand 
\begin{align}
\frac{1}{\sigma^2(\bar{x})} & \approx \frac{1}{\sigma^2} -\frac{\Delta x}{2}\frac{(-2\sigma')}{\sigma^3} + \frac{1}{2!}\frac{\Delta x^2}{4}\left[-\frac{2\sigma''}{\sigma^3} + 6\frac{(\sigma')^2}{\sigma^4}\right]\\
& = \frac{1}{\sigma^2} +\Delta x\frac{\sigma'}{\sigma^3} + \frac{\Delta x^2}{4}\left[-\frac{\sigma''}{\sigma^3} + 3\frac{(\sigma')^2}{\sigma^4}\right]
\end{align}

So the argument of the exponential is 
\begin{equation}
-\frac{\Delta x^2}{2\Delta T\sigma^2(\bar{x}_k)} \approx -\frac{\Delta x^2}{2\Delta T\sigma^2(x)}-\frac{\Delta x^3}{2\Delta T\sigma^2(x)}\frac{\sigma'}{\sigma} - \frac{\Delta x^4}{8\Delta T\sigma^2(x)}\left(-\frac{\sigma''}{\sigma} + 3\frac{(\sigma')^2}{\sigma^2}\right)
\end{equation}
It seems like the done thing here is to then treat the higher order terms as small, and expand this out.  Note that we will have to treat $\Delta x^4/\Delta T$ as $\order(\Delta T)$.  

We will also need to expand the normalization.  
In that case we have 
\begin{equation}
\frac{1}{\sigma(\bar{x})} \approx \frac{1}{\sigma} -\frac{\Delta x}{2}.\frac{-\sigma'}{\sigma^2} + \frac{1}{2!}\frac{\Delta x^2}{2^2}\left(-\frac{\sigma''}{\sigma^2} + 2\frac{(\sigma')^2}{\sigma^3}\right)
\end{equation}
So on expanding both the exponential and the normalization we have 
\begin{align}
Z & = \frac{ e^{-\frac{\Delta x^2}{2\Delta T\sigma^2(\bar{x})}}}{\sqrt{2\pi\Delta T\sigma^2(\bar{x})}}\\
\approx & C \frac{ e^{-\frac{\Delta x^2}{2\Delta T\sigma^2(x)}}}{\sqrt{2\pi\Delta T\sigma^2(x)}}
\end{align}
where 
\begin{align}
C & = \left[1 +\frac{\Delta x}{2}\frac{\sigma'}{\sigma} + \frac{\Delta x^2}{8}\left(-\frac{\sigma''}{\sigma} + 2\frac{(\sigma')^2}{\sigma^2}\right)\right]\left[ 1 - \frac{\Delta x^3}{2\Delta T\sigma^2}\frac{\sigma'}{\sigma} - \frac{\Delta x^4}{8\Delta T\sigma^2}\left(-\frac{\sigma''}{\sigma} + 3\frac{(\sigma')^2}{\sigma^2}\right)\right]\\
\approx & \left[1 +\frac{\Delta x}{2}\frac{\sigma'}{\sigma} + \frac{\Delta x^2}{8}\left(-\frac{\sigma''}{\sigma} + 2\frac{(\sigma')^2}{\sigma^2}\right)-\frac{\Delta x^4}{4\Delta T\sigma^2}\frac{(\sigma')^2}{\sigma^2} - \frac{\Delta x^3}{2\Delta T\sigma^2}\frac{\sigma'}{\sigma} - \frac{\Delta x^4}{8\Delta T\sigma^2}\left(-\frac{\sigma''}{\sigma} + 3\frac{(\sigma')^2}{\sigma^2}\right)\right]\\
= & \left[1 +\frac{\Delta x}{2}\frac{\sigma'}{\sigma} + \frac{\Delta x^2}{8}\left(-\frac{\sigma''}{\sigma} + 2\frac{(\sigma')^2}{\sigma^2}\right) - \frac{\Delta x^3}{2\Delta T\sigma^2}\frac{\sigma'}{\sigma} - \frac{\Delta x^4}{8\Delta T\sigma^2}\left(-\frac{\sigma''}{\sigma} + \frac{5(\sigma')^2}{\sigma^2}\right)\right]
\end{align}


\subsection{Replacing higher order terms with averages}

We start from \footnote{Tirapagui}
I think we now replace the higher order moments by their averages.  In which case 
\begin{gather}
\int \frac{d^Dy}{\sqrt{2\pi\sigma^2}} y^iy^jy^k  e^{-\frac{y^m g_{mn} y^n}{2}} = \int \frac{d^Dy}{\sqrt{2\pi\sigma^2}}\, g^{(ij} y^{k)}  e^{-\frac{y^m g_{mn} y^n}{2}}\\
\int \frac{dy}{\sqrt{2\pi\sigma^2}} y^iy^jy^ky^l e^{-\frac{y^m g_{mn}y^n}{2}} = \int \frac{dy}{\sqrt{2\pi\sigma^2}} g^{(ij}g^{kl)} e^{-\frac{y^2}{2\sigma^2}}
\end{gather}
where $(\cdots)$ denotes adding up all distinct permutations of the indices.  
All these equalities follow by just considering the change of variables in a single integral.  And then using the property that the path integral is a product of these integrals, correct up to $\order(\Delta T)$.  

\begin{align}
C= & 1 +\frac{\Delta x}{2}\frac{\sigma'}{\sigma} + \frac{\sigma^2\Delta T}{8}\left(-\frac{\sigma''}{\sigma} + 2\frac{(\sigma')^2}{\sigma^2}\right) - \frac{3}{2}\Delta x\frac{\sigma'}{\sigma} - \frac{3\sigma^2\Delta T}{8}\left(-\frac{\sigma''}{\sigma} + \frac{5(\sigma')^2}{\sigma^2}\right)\\
& 1 -\Delta x\frac{\sigma'}{\sigma} + \frac{\sigma^2\Delta T}{8}\left[2\frac{\sigma''}{\sigma} -13\frac{(\sigma')^2}{\sigma^2}\right]
\end{align}
We can now exponentiate this as 
\begin{align}
C &= \exp\left[-\Delta x\frac{\sigma'}{\sigma} + \frac{\Delta x^2}{2}\frac{(\sigma')^2}{\sigma^2} + \frac{\sigma^2\Delta T}{8}\left[2\sigma''\sigma -13(\sigma')^2\right] \right]\\
&= \exp\left[-\Delta x\frac{\sigma'}{\sigma} + \frac{\Delta T}{2}(\sigma')^2 + \frac{\sigma^2\Delta T}{8}\left[2\sigma''\sigma -13(\sigma')^2\right] \right].
\end{align}
We can substitute this back in and complete the square in the Gaussian.  
\begin{align}
Z &= \int dx_k \frac{ 1}{\sqrt{2\pi\Delta T\sigma^2(x)}}\exp\left[-\frac{\Delta x^2}{2\Delta T\sigma^2(x)}-\Delta x\frac{\sigma'}{\sigma} - \frac{\Delta T}{2}(\sigma')^2 + \frac{\sigma^2\Delta T}{8}\left[2\sigma''\sigma -13(\sigma')^2\right] \right]\\
&= \int dx_k \frac{1}{\sqrt{2\pi\Delta T\sigma^2(x)}}\exp\left[-\frac{(\Delta x^2+\Delta T\sigma'\sigma)^2}{2\Delta T\sigma^2} + \frac{\sigma^2\Delta T}{8}\left[2\sigma''\sigma -13(\sigma')^2\right] \right]\\
\end{align}
Mmm..
\subsubsection{Fishy kludge}
\comment{If we suppress the term between the normalization and the exponential expansions} we have
\begin{align}
C &= 1 +\frac{\Delta x}{2}\frac{\sigma'}{\sigma} + \frac{\Delta x^2}{8}\left(-\frac{\sigma''}{\sigma} + 2\frac{(\sigma')^2}{\sigma^2}\right) - \frac{\Delta x^3}{2\Delta T\sigma^2}\frac{\sigma'}{\sigma} - \frac{\Delta x^4}{8\Delta T\sigma^2}\left(-\frac{\sigma''}{\sigma} + 3\frac{(\sigma')^2}{\sigma^2}\right)
\end{align}.

Replacing these higher order moments we have
\begin{align}
C &= 1 +\frac{\Delta x}{2}\frac{\sigma'}{\sigma} + \frac{\sigma^2\Delta T}{8}\left(-\frac{\sigma''}{\sigma} + 2\frac{(\sigma')^2}{\sigma^2}\right) - 3\frac{\Delta x}{2}\frac{\sigma'}{\sigma} - \frac{3\sigma^2\Delta T}{8}\left(-\frac{\sigma''}{\sigma} + 3\frac{(\sigma')^2}{\sigma^2}\right)\\
&= 1 -\Delta x\frac{\sigma'}{\sigma}  + \frac{\Delta T}{8}\left(2\sigma'\sigma'' - 7(\sigma')^2\right)
\end{align}.

\section{Operator ordering}

So we must have started from $[\sigma^2p^2]_W$.  Let's operator order this and see what we get.  
\begin{equation}
\frac{1}{2}[\sigma^2p^2]_W = \frac{1}{8}[\sigma^2p^2 + 2p\sigma^2 p + p^2\sigma^2]
\end{equation}
We need to Ito order this.  

First up,
\begin{align}
p\sigma^2 p & = p^2\sigma^2 + p[\sigma^2,p]\\
& = p^2\sigma^2 + 2ip\sigma'\sigma
\end{align}

We will also need 
\begin{align}
\sigma^2 p ^2 &= p\sigma^2p + [\sigma^2,p]p\\
% &= p\sigma^2p + 2i\sigma'\sigma p \\
% &= p^2\sigma^2 + p(2i\sigma'\sigma) + 2ip\sigma'\sigma p -2(\sigma'\sigma)'\\
&= p^2\sigma^2 + 4pi\sigma'\sigma -2\left[\sigma''\sigma+(\sigma')^2\right]
\end{align}

Then 
\begin{equation}
\boxed{\frac{1}{2}[\sigma^2p^2]_W = \frac{1}{2}p^2\sigma^2 + ip\sigma'\sigma -\frac{1}{4}[\sigma''\sigma + (\sigma')^2]}
\end{equation}


\subsubsection{Higher moments}
I've seen claims that 
\begin{equation}
(\Delta x)^3 \dot{=} 3\Delta x \Delta T,
\end{equation}
where $\dot{=}$ means equal so far as the functional integral is concerned.
 I think this just means accurate for one matrix element to order $\Delta T$, when under the integral.  
\begin{equation}
\int \frac{dx_{k+1}}{\sqrt{2\pi\Delta T}}\, \frac{(\Delta x)^3}{\Delta T} e^{-\frac{\Delta x^2}{2\Delta T}} = \int dx_{k+1}\,3\Delta x e^{-\frac{\Delta x^2}{2\Delta T}}
\end{equation}
\comment{The slowest decay in any of this is the Gaussian piece.
 We expect this to be order 1, so $\Delta x\sim(\Delta T)^{1/2}$.
 We then expand everything out treating that.}


\comment{This amounts to Dan's argument that we can replace anything with an equivalent Gaussian.
 We will expand all terms that are effectively linear order in $\Delta T$, and replace them with their means.  }

I think we just integrate by parts often enough until we have something of the form $\Delta x^{n\le 2}$.  

Let's start with 
\begin{equation}
I_3 = \int d^D x\, \frac{1}{(2\pi \Delta T)^{D/2}g^{1/2}} \frac{x^ix^jx^k}{\Delta T} e^{-\frac{x^ig_{ij}x^j}{2\Delta T}}
\end{equation}
Let's make a unitary transformation to diagonalize $g_{ij}$.  I think this amounts to finding the principle axes of $g$.  We have I'm going to suspend the summation convention.  
\begin{gather}
y^i = \sum_jO_{ij}x^j\\
\sum_jg_{ij}y^j = \lambda^j y^i\\
\sum_{kl}O_{ik}O_{jl}g_{kl} = \lambda^i\delta_{ij}\\
\sum_j O_{ij}O_{kj} = \delta_{jk}
\end{gather}

The transformed version of the integral is 
\begin{equation}
I_3 = \int d^D x\, \frac{1}{(2\pi \Delta T)^{D/2}}\frac{1}{\prod_k \lambda_k^{1/2}}\sum_{m,n,p} O_{im}O_{jn}O_{kp}\frac{y^my^ny^p}{\Delta T} e^{-\sum_i\frac{\lambda_i y_i^2}{2\Delta T}}
\end{equation}
Let's look at this term by term.  This is evidently zero if $m\ne n\ne p$.  If we have $m=n$, then 
\begin{align}
I_3 = \int d^D y\, \frac{1}{(2\pi \Delta T)^{D/2}}\frac{1}{\prod_k \lambda_k^{1/2}} \sum_{n,p} O_{kp}y^p O_{in}O_{jn}\frac{y^ny^n}{\Delta T} e^{-\frac{\lambda_i y_i^2}{2\Delta T}}
\end{align}
Now let's integrate by parts using 
\begin{align}
\int dx\, f(x)x^2e^{-\frac{\alpha x^2}{2}}& = -\frac{f(x)}{\alpha}x e^{-\alpha x^2/2}\bigg|_{x=-\infty}^\infty + \int dx\, \frac{1}{\alpha}\frac{d}{dx}(f(x)x)e^{-\alpha x^2/2}\\
& = \frac{1}{\alpha}\int dx\, \left(x\frac{df}{dx} + f\right)e^{-\alpha x^2/2}
\end{align}
So the integral can be written 
\begin{align}
I_3 &= \int d^D y\, \frac{1}{(2\pi \Delta T)^{D/2}}\frac{1}{\prod_k \lambda_k^{1/2}} \sum_{n,p} \frac{1}{\lambda_n}\left[\left(\frac{d}{dy^n}O_{kp}y^p\right)y_nO_{in}O_{jn} + O_{kp}y^pO_{in}O_{jn} \right]e^{-\frac{\lambda_i y_i^2}{2\Delta T}}\\
%&= \int d^D y\, \frac{1}{(2\pi \Delta T)^{D/2}}\frac{1}{\prod_k \lambda_k^{1/2}} \sum_{n,p} \frac{1}{\lambda_n}\left[O_{kp}\delta_{pn}y_nO_{in}O_{jn} + O_{kp}y^pO_{in}O_{jn} \right]e^{-\frac{\lambda_i y_i^2}{2\Delta T}}\\
&= \int d^D y\, \frac{1}{(2\pi \Delta T)^{D/2}}\frac{1}{\prod_k \lambda_k^{1/2}}\left[ \sum_{n} \frac{1}{\lambda_n}O_{kn}y_nO_{in}O_{jn} + \sum_pO_{kp}y^p\sum_n\frac{1}{\lambda_n}O_{in}O_{jn} \right]e^{-\frac{\lambda_i y_i^2}{2\Delta T}}
\end{align}
So we have two terms.  The first is 
\begin{align}
I_{3,a}&= \int d^D y\, \frac{1}{(2\pi \Delta T)^{D/2}}\frac{1}{\prod_k \lambda_k^{1/2}}\left[ \sum_{n} \frac{1}{\lambda_n}O_{kn}y_nO_{in}O_{jn} \right]e^{-\frac{\lambda_i y_i^2}{2\Delta T}}\\
I_{3,b}&= \int d^D y\, \frac{1}{(2\pi \Delta T)^{D/2}}\frac{1}{\prod_k \lambda_k^{1/2}}\left[\sum_pO_{kp}y^p\sum_n\frac{1}{\lambda_n}O_{in}O_{jn} \right]e^{-\frac{\lambda_i y_i^2}{2\Delta T}}\\
&= \int d^D x\, \frac{1}{(2\pi \Delta T)^{D/2}g^{1/2}}x^kg^{ij} e^{-\frac{x^i g_{ij} x^j}{2\Delta T}}
\end{align}
Now of course there are other pairings.  In which case we must sum over all of them.  At least that is the usual logic.  But what of the extra term?  Can we just say this one is zero?

\subsubsection{Gaussian moments}

For one dimension we need 
\begin{gather}
\langle x \rangle = \int dx\,x \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}} = \mu\\
\langle x^2 \rangle = \int dx\,x^2 \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}} = \sigma^2 + \mu^2.
\end{gather}

We then have to also evaluate 
\begin{align}
\langle x^3\rangle & = \int dx\, x^3 \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}} \\
& = \int dx\, (x+\mu)^3 \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{x^2}{2\sigma^2}} \\
& = \int dx\, (x^3 + 3\mu x^2 + 3\mu^2 x + \mu^3 )\frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{x^2}{2\sigma^2}} \\
& = 3\mu\sigma^2 + 4\mu^3
\end{align}

\begin{align}
\langle x^4\rangle & = \int dx\, x^4\frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}} \\
& = \int dx\, (x+\mu)^4 \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{x^2}{2\sigma^2}} \\
& = \int dx\, (x^4 + 4\mu x^3 + 6\mu^2 x^2 + 4\mu x + \mu^4 )\frac{e^{-\frac{x^2}{2\sigma^2}}}{\sqrt{2\pi\sigma^2}} \\
& = 3\sigma^4 + 6\mu^2 \sigma^2  + \mu^4 
\end{align}

Now the idea is to go through and use those moment formulae to rewrite those higher order moments in terms of the lower moments.
  Can we then write a functional equivalence?  


\section{Following DeWitt}

This section is where I will try to reproduce Bryce DeWitt's results\footnote{deWitt, B. S. \textit{Dynamical Theory in Curved Spaces I: A Review of the Classical and Quantum Action Principles}, \\{Rev. Mod. Phys.}, \textbf{29}, 377,(1957)}.  I'll skip the material on transformation theory, etc, and just leap to the curved spaces.  We will need some of those results, but the classical material is a touch irrelevant.  
\subsection{Classical Lagrangian Mechanics}
We have a particle Lagrangian
\begin{equation}
  L= \frac{1}{2}g_{ij}\dot{q}^i\dot{q}^j - V,
\end{equation}
with metric $g_{ij}$ which has inverse $g^{ij}$.  The Lagrangian can be made invariant under point transformations, $q^i=q^i(\bar{q},t)$.  Let's transform the Lagrangian and see what the new constants $a,g,V$ have to look like.  
\begin{align}
\bar{L} &=\frac{1}{2}g_{ij}\left(\frac{\partial q^i}{\partial \bar{q}^m}\dot{\bar{q}}^m+\frac{\partial q^i}{\partial t}\right)\left(\frac{\partial q^j}{\partial \bar{q}^n}\dot{\bar{q}}^n+\frac{\partial q^j}{\partial t}\right)  - V\\
&=\frac{1}{2}\bar{g}_{mn}\dot{\bar{q}}^m\dot{\bar{q}}^n  - \bar{V}
\end{align}
where 
\begin{gather}
\bar{g}_{mn} = \frac{\partial q^i}{\partial\bar{q}^m}\frac{\partial q^j}{\partial\bar{q}^n}g_{ij}\\
\bar{V} = V  - \frac{1}{2}g_{ij}\frac{\partial q^i}{\partial t}\frac{\partial q^j}{\partial t},
\end{gather}
and all functions are evaluated for $\bar{q}$.  

The conjugate momenta are 
\begin{equation}
p_i = \frac{\partial L}{\partial \dot{q}^i} = g_{ij}\dot{q}^j.
\end{equation}

\subsubsection{Equations of motion}

% The equations of motion are then given by 
% \begin{equation}
% \frac{d}{dt}\frac{\partial L}{\partial \dot{q}^k} - \frac{\partial L}{\partial q^k} = 0
% \end{equation}
% Let's introduce the notation, $\partial_i = \frac{\partial}{\partial q^i}$ (note the placement of indices)
% First up we need 
% \begin{align}
% \frac{d}{dt}\frac{\partial L}{\partial \dot{q}^k} &= \frac{d}{dt}\left(g_{kj}\dot{q}^j  + a_k\right)\\
% %&= g_{ij}\ddot{q}^j + \frac{\partial g_{ij}}{\partial q^k}\dot{q}^k\dot{q}^j  + \frac{\partial a_i}{\partial q^j}\dot{q}^j + \frac{\partial g_{ij}}{\partial t}q^j + \frac{\partial a_i}{\partial t}\\
% &= g_{kj}\ddot{q}^j + \partial_i g_{kj}\dot{q}^i\dot{q}^j  + \partial_j a_k\dot{q}^j + \partial_t g_{kj}\dot{q}^j + \partial_t a_k\\
% &= g_{kj}\ddot{q}^j + \frac{1}{2}\left(\partial_i g_{kj}\dot{q}^i\dot{q}^j + \partial_j g_{ki}\dot{q}^i\dot{q}^j\right) + \partial_j a_k\dot{q}^j + \partial_t g_{kj}\dot{q}^j + \partial_t a_k
% \end{align}
% Second we need 
% \begin{align}
% \frac{\partial L}{\partial q^k} &= \frac{\partial }{\partial q^k}\left( \frac{1}{2}g_{ij}\dot{q}^i\dot{q}^j + a_i\dot{q}^i - V\right)\\
% &=  \frac{1}{2}\partial_k g_{ij}\dot{q}^i\dot{q}^j + \partial_k a_i\dot{q}^i - \partial_k V
% \end{align}

% So the equations of motion are 
% \begin{align}
% 0 & = \frac{d}{dt}\frac{\partial L}{\partial \dot{q}^k} - \frac{\partial L}{\partial q^k} \\
% &= g_{kj}\ddot{q}^j + \frac{1}{2}\left(\partial_i g_{kj} + \partial_jg_{ki}\right)\dot{q}^i\dot{q}^j  + \partial_j a_k\dot{q}^j + \partial_t g_{kj}\dot{q}^j + \partial_t a_k - \left(  \frac{1}{2}\partial_k g_{ij}\dot{q}^i\dot{q}^j + \partial_k a_i\dot{q}^i - \partial_k V\right)
% \end{align}


Let's start from the action
\begin{equation}
S = \frac{1}{2}\int dt\, g_{ij}\dot{q}^i\dot{q}^j
\end{equation}
Under a variation this becomes 
\begin{equation}
S+\delta S = \frac{1}{2}\int dt\, (g+\delta q^k\partial_kg_{ij})\dot{q}^i\dot{q}^j+ g_{ij}\frac{d}{dt}(q+\delta q)^iq^j + g_{ij}\frac{d}{dt}(q+\delta q)^jq^i\,
\end{equation}
with 
\begin{equation}
\delta S   = \frac{1}{2}\int dt\, \partial_kg_{ij}\dot{q}^i\dot{q}^j\delta q^k + g_{ij}\frac{d\delta q^i}{dt}q^j + g_{ij}\frac{d}{dt}(\delta q)^j\dot{q}^i\,
\end{equation}
Let's now integrate by parts on the last two terms.  We then have
\begin{align}
\delta S & = \frac{1}{2}\int dt\, \partial_kg_{ij}\dot{q}^i\dot{q}^j\delta q^k - \frac{d}{dt}(g_{ij}\dot{q}^j)\delta q^i - \frac{d}{dt}(g_{ij}\dot{q}^i)\delta q^j\\
% & = \frac{1}{2}\int dt\, \partial_kg_{ij}\dot{q}^i\dot{q}^j\delta q^k - \left( g_{ij}\ddot{q}^j + \partial_k g_{ij}\dot{q}^k\dot{q}^j\right)\delta q^i - \left(g_{ij}\ddot{q}^i + \partial_k g_{ij}\dot{q}^i \dot{q}^k\right)\delta q^j\\
% & = \frac{1}{2}\int dt\, \left[\partial_kg_{ij}\dot{q}^i\dot{q}^j - \left( g_{kj}\ddot{q}^j + \partial_i g_{kj}\dot{q}^i\dot{q}^j\right) - \left(g_{ik}\ddot{q}^i + \partial_j g_{ik}\dot{q}^i \dot{q}^j\right)\right]\delta q^k\\
& = \frac{1}{2}\int dt\, \left[-g_{ik}\ddot{q}^i - [ij,k]\dot{q}^i \dot{q}^j\right]\delta q^k
\end{align}

We then have the equation of motion
\begin{equation}
g_{ki}\ddot{q}^i  + [ij,k]\dot{q}^i\dot{q}^j= 0,\label{eq:eqn_of_motion}
\end{equation}
where 
\begin{equation}
[ij,k] = \frac{1}{2}(\partial_ig_{jk} + \partial_jg_{ik} - \partial_k g_{ij})
\end{equation}

\subsubsection{Short time action}

So deWitt claims that you can find the action function explicitly by solving the equations of motion, and plugging back in, or by solving the Hamiltonian Jacobi equations.  (There seems to be some link between the action and the transformation function in the Hamilton-Jacobi equations.  ) I think the action in this case corresponds to $S_{+-}$ in his parlance, which is a transformation function from $S(q',t'|q,t)$.  

He claims that by solving 
\begin{equation}
\frac{\partial S}{\partial t'}  + \frac{1}{2}  \frac{\partial S}{\partial {q'}^i}g^{ij}(q')  \frac{\partial S}{\partial {q'}^j} + V' = 0
\end{equation}
you can find the action.  
Note that all the stuff on the right is actually the Hamiltonian, with $p'' = \frac{\partial S}{\partial q''}$.  

Now apparently we can expand everything to leading order for $t''-t', q''-q'\ll 1$.    I'm now going to transcribe what he claims.  This will be necessary at some point where we need the van-Vleck-Morette determinant.  
\begin{align}
S(q',t'|q,t) & = \frac{1}{t'-t}\bigg\{ \frac{1}{2}g_{ij}({q'}^i-{q}^i)({q'}^j-{q}^j) 
+ \frac{1}{12}\left(\partial_kg_{ij} + \partial_i g_{jk} + \partial_j g_{ik}\right)
({q'}^i-{q}^i)({q'}^j-{q}^j)({q'}^k-{q}^k) \nonumber \\
&\hspace{2cm}+ \frac{1}{72}\bigg[\partial_{k}\partial_lg_{ij} + \partial_j\partial_l g_{ik} + \partial_j\partial_kg_{il} + \partial_i\partial_j g_{kl} + \partial_i\partial_kg_{jl} + \partial_i\partial_lg_{jk}\nonumber \\
&\hspace{2cm}  - {g}^{mn}\left([ij,m][kl,n]+ [il,m][jk,n] + [ik,m][jl,n]\right)\bigg]({q'}^i-{q}^i)({q'}^j-{q}^j)({q'}^k-{q}^k)({q'}^l-{q}^l)\bigg\}
\end{align}

It seems that you can get also this by expanding $S = \int dt L$ by treating $(q'-q)$ as $\order(\Delta T^{1/2})$.  
\begin{align}
S(q',t'|q,t) = \int_t^{t'} dt \frac{1}{2}g_{ij}\dot{q}^i\dot{q}^j \\
& = \int_t^{t'}ds\frac{1}{2}g_{ij}(q(s))\dot{q}^i(s)\dot{q}^j(s)\\
%& \approx \frac{1}{2}\int_t^{t'}ds\,g_{ij}\dot{q}^i \dot{q}^j\bigg|_{s=t} + (s-t)\frac{d}{dt}g_{ij}\dot{q}^i \dot{q}^j\bigg|_{s=t} + \frac{1}{2}(s-t)^2\frac{d^2}{dt^2}g_{ij}\dot{q}^i \dot{q}^j\bigg|_{s=t}\\
& \approx \frac{1}{2}g_{ij}(t-t')\dot{q}^i \dot{q}^j\bigg|_{s=t} + \frac{1}{4}(t'-t)^2\frac{d}{dt}g_{ij}\dot{q}^i \dot{q}^j\bigg|_{s=t} + \frac{1}{6}(t'-t)^3\frac{d^2}{dt^2}g_{ij}\dot{q}^i \dot{q}^j\bigg|_{s=t}
\end{align}

Let's try evaluating these derivatives, treating $ q\sim \sqrt{\Delta t}$.  If we want this correct to order 
\begin{align}
\frac{d}{dt}g_{ij}\dot{q}^i\dot{q}^j &= \partial_kg_{ij}\dot{q}^i\dot{q}^j\dot{q}^k  + g_{ij}\ddot{q}^i\dot{q}^j +g_{ij}\dot{q}^i\ddot{q}^j\\
% =& \partial_kg_{ij}\dot{q}^i\dot{q}^j\dot{q}^k  - [ki,j]\dot{q}^i\dot{q}^j\dot{q}^k - [kj,i]\dot{q}^i\dot{q}^j\dot{q}^k \\
% =& \partial_kg_{ij}\dot{q}^i\dot{q}^j\dot{q}^k  - \frac{1}{2}(\partial_ig_{jk}+\partial_kg_{ij} - \partial_jg_{ik})\dot{q}^i\dot{q}^j\dot{q}^k  - \frac{1}{2}(\partial_kg_{ji}+\partial_jg_{ik} - \partial_ig_{jk})\dot{q}^i\dot{q}^j\dot{q}^k \\
=&   - \frac{1}{2}(\partial_ig_{jk} - \partial_jg_{ik})\dot{q}^i\dot{q}^j\dot{q}^k  - \frac{1}{2}(+\partial_jg_{ik} - \partial_ig_{jk})\dot{q}^i\dot{q}^j\dot{q}^k  = 0
\end{align}
where we used the equation of motion in Eq.~(\ref{eq:eqn_of_motion})  which is correct for finding the action of the classical path.  The second derivative term is much more complicated.  
\begin{align}
\frac{d^2}{dt^2}g_{ij}\dot{q}^i\dot{q}^j  =& \frac{d}{dt}\left(\partial_kg_{ij}\dot{q}^i\dot{q}^j\dot{q}^k  - 2[kj,i]\dot{q}^i\dot{q}^j\dot{q}^k\right)\\
=& \partial_k\partial_lg_{ij}\dot{q}^i\dot{q}^j\dot{q}^k\dot{q}^l + 2\partial_kg_{ij}\ddot{q}^i\dot{q}^j\dot{q}^k + \partial_kg_{ij}\dot{q}^i\dot{q}^j\ddot{q}^k\\
&-2\partial_l[ij,k]\dot{q}^i\dot{q}^j\dot{q}^k\dot{q}^l - 2[ij,k]\ddot{q}^i\dot{q}^j\dot{q}^k- 2[ij,k]\dot{q}^i\ddot{q}^j\dot{q}^k- 2[ij,k]\dot{q}^i\dot{q}^j\ddot{q}^k
% =& \frac{d}{dt}\left(\partial_kg_{ij}\dot{q}^i\dot{q}^j\dot{q}^k  - g_{ij}\Gamma_{kl}^i\dot{q}^k\dot{q}^l\dot{q}^j - g_{ij}\Gamma^j_{kl}\dot{q}^i\dot{q}^k\dot{q}^l\right)\\
%  =& \partial_l\partial_kg_{ij}\dot{q}^i\dot{q}^j\dot{q}^k\dot{q}^l + \partial_kg_{ij}\left(\ddot{q}^i\dot{q}^j\dot{q}^k + \dot{q}^i\ddot{q}^j\dot{q}^k+\dot{q}^i\dot{q}^j\ddot{q}^k\right) \nonumber \\
% &-\partial_mg_{ij}\Gamma_{kl}^i\dot{q}^m\dot{q}^k\dot{q}^l\dot{q}^j - \partial_mg_{ij}\Gamma^j_{kl}\dot{q}^i\dot{q}^k\dot{q}^l\dot{q}^m \nonumber \\
% &- g_{ij}\partial_m\Gamma^{j}_{kl}\dot{q}^i\dot{q}^k\dot{q}^l\dot{q}^m- g_{ij}\partial_m\Gamma^{i}_{kl}\dot{q}^j\dot{q}^k\dot{q}^l\dot{q}^m\nonumber\\
% &  - g_{ij}\Gamma_{kl}^i\ddot{q}^k\dot{q}^l\dot{q}^j- g_{ij}\Gamma_{kl}^i\dot{q}^k\ddot{q}^l\dot{q}^j - g_{ij}\Gamma_{kl}^i\dot{q}^k\dot{q}^l\ddot{q}^j\nonumber\\
% &  - g_{ij}\Gamma^j_{kl}\ddot{q}^i\dot{q}^k\dot{q}^l   - g_{ij}\Gamma^j_{kl}\dot{q}^i\ddot{q}^k\dot{q}^l  - g_{ij}\Gamma^j_{kl}\dot{q}^i\dot{q}^k\ddot{q}^l
% \end{align}
\end{align}

We will need 
\begin{align}
\partial_m[ij,k] &= \frac{1}{2}(\partial_m\partial_ig_{jk} + \partial_m\partial_jg_{ik} - \partial_m\partial_kg_{ij})\\
\ddot{q}^i &= g^{ij}[kl,j]\dot{q}^k\dot{q}^l
\end{align}

\begin{align}
\frac{d^2}{dt^2}g_{ij}\dot{q}^i\dot{q}^j  =& \partial_k\partial_lg_{ij}\dot{q}^i\dot{q}^j\dot{q}^k\dot{q}^l + 2\partial_kg_{ij}\ddot{q}^i\dot{q}^j\dot{q}^k + \partial_kg_{ij}\dot{q}^i\dot{q}^j\ddot{q}^k\nonumber\\
&-2\partial_l[ij,k]\dot{q}^i\dot{q}^j\dot{q}^k\dot{q}^l - 2[ij,k]\ddot{q}^i\dot{q}^j\dot{q}^k- 2[ij,k]\dot{q}^i\ddot{q}^j\dot{q}^k- 2[ij,k]\dot{q}^i\dot{q}^j\ddot{q}^k\\
% =& \partial_k\partial_lg_{ij}\dot{q}^i\dot{q}^j\dot{q}^k\dot{q}^l + 2\partial_kg_{ij}g^{im}[np,m]\dot{q}^n\dot{q}^p\dot{q}^j\dot{q}^k + 2\partial_kg_{ij}g^{km}[np,m]\dot{q}^n\dot{q}^p\dot{q}^j\dot{q}^i\nonumber\\
% & - (\partial_l\partial_ig_{jk} + \partial_l\partial_jg_{ik} - \partial_l\partial_kg_{ij})\dot{q}^i\dot{q}^j\dot{q}^k\dot{q}^l - 4[ij,k]g^{im}[np,m]\dot{q}^n\dot{q}^p\dot{q}^j\dot{q}^k \nonumber\\
% &- 2[ij,k]g^{km}[np,m]\dot{q}^i\dot{q}^j\dot{q}^n\dot{q}^p\\ 
=&\bigg[ \partial_k\partial_lg_{ij} + 2\partial_kg_{nj}g^{nm}[il,m] + 2\partial_ng_{kj}g^{nm}[il,m]\nonumber\\
 &  - 4[nj,k]g^{nm}[il,m] - 2[ij,n]g^{nm}[kl,m]- 
(\partial_l\partial_ig_{jk} + \partial_l\partial_jg_{ik} - \partial_l\partial_kg_{ij})\bigg]
\dot{q}^i\dot{q}^j\dot{q}^k\dot{q}^l\\
% =&\bigg[ 2\partial_k\partial_lg_{ij} -\partial_l\partial_ig_{jk} 
% - \partial_l\partial_jg_{ik}+ 2\partial_kg_{nj}g^{nm}[il,m] + 2\partial_ng_{kj}g^{nm}[il,m] + 2\partial_\nonumber\\
%  &  - 4g^{nm}[nj,k][il,m] - 2g^{nm}[ij,n][kl,m]\bigg]\dot{q}^i\dot{q}^j\dot{q}^k\dot{q}^l
\end{align}

Get Action.

The Pauli-Van Vleck determinant.  $D$

Then Matrix element. 

Then try to use $H$ to derive path integral.  

\section{1D Example}

Path integrals in curved spaces are a contentious topic.  
Most authors who end up strayin into the field either missed out prior
literature, or made mistakes.  Given the tedious algebra required by calculations
this is understandable.  There are numerous books inveighing against all other
approaches, and declaring their version to be the received truth on how to 
properly write the path integral in curved space.  

We don't need the full glory of those results, so we will focus our attention
on just one dimension, and the TM potential directly.  We will look at a couple
different approaches.    
Let us apply these results to the 1D TM potential example.
The single particle 
\begin{equation}
  \langle x|H_{TM}|\psi\rangle = \frac{1}{2}(-\nabla\frac{1}{\epsilon}\nabla+\omega^2)\psi(x)
\end{equation}

\subsection{Operator view}

In this version, we interpret $\epsilon$ as a metric.  This implies the
form of the momentum operators, and spatial identities are changed.  
The spatial identity is
\begin{equation}
  I_X = \int dx\sqrt{\epsilon}|x\rangle\langle x|
\end{equation}
where the metric is $g=\epsilon$.
The conjugate momentum operator is 
\begin{equation}
  \langle x|\op{p}|\psi\rangle = -i(\partial_x+\frac{1}{2}\partial_x\ln\sqrt{\epsilon})\psi
\end{equation}
The correction is related to the trace of the Christoffel symbols.
In one dimension we will just use $\Gamma_x=\partial_x\ln\sqrt{\epsilon}$.
The differential can then be written in operator form as
\begin{align}
  H &=\frac{1}{2}[-\partial_x\epsilon^{-1}\partial_x]\\
%  &=\frac{1}{2}[(\op{p}-\frac{i}{2}\Gamma_x)\epsilon^{-1}(\op{p}-\frac{i}{2}\Gamma_x)]\\
  &=\op{p}\epsilon^{-1}\op{p}-\frac{i}{2}\op{p}\epsilon^{-1}\Gamma_x
-\frac{i}{2}\Gamma_x\epsilon^{-1}\op{p}-\frac{\Gamma_x^2}{4\epsilon}
  \label{eq:H_op}
\end{align}

In order to evaluate the matrix elements we must operator-order the Hamiltonian.
The three basic orderings are anti-standard, Weyl and standard orderings,
each of which correspond to Ito, Stratonovich and anticipating stochastic
calculus, which further correspond to expanding the path integral about the
pre-point, mid-point and post-point.

We will use the commutation relations $[x,p]=i$.  Prior works were considering
work in a quantum context, where explicit factors of $\hbar$ are required.  
Since we will be working with the 

\subsubsection{Standard ordering}

First, let us put the Hamiltonian (\ref{eq:H_op}) into anti-standard ordering
with all position operators to the left of momentum operators.  

We will have ample opportunity to use: $[f(x),p]=if'$, which implies
$fp = pf +if'$ and $pf = fp-if'$
\begin{align}
  H&=(\op{p}-\frac{i}{2}\Gamma_x)\epsilon^{-1}(\op{p}-\frac{i}{2}\Gamma_x)\\
   % &=(\frac{1}{\epsilon}p+i\frac{\epsilon'}{\epsilon^2})(p-\frac{i}{2}\Gamma_x)
   % -\frac{i}{2\epsilon}\Gamma_x(p-\frac{i}{2}\Gamma_x)\\
   % &=\frac{1}{\epsilon}p^2-\frac{i}{2\epsilon}(\Gamma_xp-i\Gamma_x')+i\frac{\epsilon'}{\epsilon^2}(p-\frac{i}{2}\Gamma_x)
   % -\frac{i\Gamma_x}{2\epsilon}p-\frac{\Gamma_x^2}{4\epsilon}\\
   &=\frac{1}{\epsilon}p^2
   +i\frac{\Gamma_x}{\epsilon}p+\frac{3\Gamma_x^2}{4\epsilon}-\frac{\Gamma_x'}{2\epsilon}
\end{align}
Retrying from different starting point
\begin{align}
H&=p\epsilon^{-1}  p-p\epsilon^{-1}\frac{i}{2}\Gamma_x
-\frac{i}{2}\Gamma_x\epsilon^{-1}p-\frac{\Gamma_x^2}{4\epsilon}\\
% &=(\epsilon^{-1}p +i\frac{\epsilon'}{\epsilon^2})p
% -\frac{i}{2}[\epsilon^{-1}\Gamma_xp -i(\frac{\Gamma_x'}{\epsilon}-\frac{\Gamma\epsilon'}{\epsilon^2})]
% -\frac{i}{2}\Gamma_x\epsilon^{-1}p-\frac{\Gamma_x^2}{4\epsilon}\\
&=(\epsilon^{-1}p +i\frac{\Gamma_x}{\epsilon})p
 -\frac{\Gamma_x'}{2\epsilon}+\frac{3\Gamma_x^2}{\epsilon}
\end{align}


\subsubsection{Anti-Standard ordering}
Now move momentum operators to the left.  $fp = pf+if'$
\begin{align}
  H&=(p-\frac{i}{2}\Gamma_x)\epsilon^{-1}(p-\frac{i}{2}\Gamma_x)\\
% &=p\epsilon^{-1}p-p\epsilon^{-1}\frac{i}{2}\Gamma_x
% -\frac{i}{2}\Gamma_x\epsilon^{-1}p-\frac{\Gamma_x^2}{4\epsilon}\\
% &=p\left(p\epsilon^{-1}-\frac{i\epsilon'}{\epsilon^2}\right)-p\epsilon^{-1}\frac{i}{2}\Gamma_x
% -\frac{i}{2}\left[p\Gamma_x\epsilon^{-1}
%   +i\left(\frac{\Gamma_x'}{\epsilon}-\Gamma_x\frac{\epsilon'}{\epsilon^2}\right) \right]
% -\frac{\Gamma_x^2}{4\epsilon}\\
&=p\left(p\epsilon^{-1}-\frac{3i\Gamma_x}{\epsilon}\right)
+\left(\frac{\Gamma_x'}{2\epsilon}-\frac{5\Gamma_x^2}{4\epsilon}\right)
\end{align}

\subsubsection{Weyl ordering}

$fp-pf = if'\rightarrow fp = pf+if'$
We can then use these pieces to symmetrically order the total as: 
\begin{align}
H_W&=\frac{1}{4}\left[p(p\epsilon^{-1}-i\frac{\epsilon'}{\epsilon^2})+ 2p\epsilon^{-1}p +
  (\epsilon^{-1}p+i\frac{\epsilon'}{\epsilon^2})p\right]
-\frac{i}{2}\left(p\frac{\Gamma_x}{\epsilon}+\frac{\Gamma_x}{\epsilon}p\right)
-\frac{\Gamma_x^2}{4\epsilon}\\
% &=(p^2\epsilon^{-1})_W 
% -i\left(p\frac{\Gamma_x}{\epsilon}\right)_W
% -\frac{\Gamma_x^2}{4\epsilon}+i\left[\frac{\epsilon'}{\epsilon^2},p\right] \\
&=[(p+\frac{i}{2}\Gamma_x)^2\epsilon^{-1}]_W 
+\left(\frac{2(\epsilon')^2}{\epsilon^3}-\frac{\epsilon''}{\epsilon^2}\right)
\end{align}
The potential term can be rewritten as
\begin{align}
  (\partial_x\ln\sqrt{\epsilon}) = \frac{\epsilon'}{2\epsilon}\\
  (\partial_x^2\ln\sqrt{\epsilon}) = \frac{\epsilon''}{2\epsilon}-\frac{\epsilon'^2}{2\epsilon^2}
\end{align}
Accounting for the factor of two we have suppressed, the potential can be written
\begin{align}
 V'&= \left(\frac{(\epsilon')^2}{\epsilon^3}-\frac{\epsilon''}{2\epsilon^2}\right)\\
 &=\frac{1}{\epsilon}\left[2(\partial_x\ln\sqrt{\epsilon})^2-\partial_x^2\ln\sqrt{\epsilon}\right],
\end{align}
which has an additional factor of $\epsilon$, and $\ln\sqrt{\epsilon}$ relative to the
TM potential.  Maybe this will be eaten in the path integral? 

We want to compute the following path integral.  
\begin{equation}
  E = \log Z = -\int \frac{d\cT}{\cT}\tr[\exp(-H\cT)]
\end{equation}
If we assume that the metric term is only on one dimension, then this becomes a path integral,
\begin{align}
  E &= -\int \frac{d\cT}{\cT}\int \prod_k\frac{dx_k dp_k}{2\pi}
\exp\left[-\frac{\Delta T}{2\epsilon}(p_k-i\Gamma_k/2)^2 -V'_k\Delta T+ip_k\Delta x_k\right]\\
% &= -\int \frac{d\cT}{\cT}\int \prod_k\frac{dx_k dp_k}{2\pi}\sqrt{\epsilon} 
% \exp\left[-\frac{\Delta T}{2\epsilon}\left(p_k^2-2i\frac{\Gamma_k}{2}p_k-2i\frac{\epsilon_k}{\Delta T}\Delta x_kp_k\right)
% +\Gamma_k^2\frac{\Delta T}{8\epsilon} -V'_k\Delta T\right]\\
&= -\int \frac{d\cT}{\cT}\int \prod_kdx_k\sqrt{\epsilon} 
\sqrt{\frac{\epsilon_k}{2\pi\Delta T}}
\exp\left[-\frac{\epsilon_k}{2\Delta T}\left(\Delta x_k+\frac{\Gamma_k\Delta T}{2\epsilon_k}\right)^2
+\Gamma_k^2\frac{\Delta T}{8\epsilon} -V'_k\Delta T\right]
\end{align}
where we have used the Weyl correspondence, $[a(\op{x})b(\op{p})]_W\rightarrow a(\bar{x})b(p)$
Note that the overlap between spatial and momentum states also changes. 
\begin{equation}
\langle x|p\rangle = \frac{e^{ipx}}{\epsilon^{1/4}}
\end{equation}

\section{2013-April}

We will follow work\footnote{Girotti, H.O. and Simoes, T.J.M. \textit{A Generalized Treatment of Point Canonical Transformations in the Path Integral}, Il Nuovo Cimento, \textbf{74}, 59, (1983)} extending the point transformation approach for handling arbitrary orderings.  This covers all orderings, but also offers proof for the higher order moments.  

We start from a flat space, with 
\begin{equation}
H = \frac{1}{2}\sum_j p_j^2 + V(q),
\end{equation}
with $[q_i,p_j]=i\hbar\delta_{ij}$.  The propagator is 
\begin{equation}
K(q_f,t_f; q_i,t_i) = \int \prod_k \frac{d^nq_k}{(2\pi i \hbar \Delta T)^{n/2}} \exp\left[ \frac{i}{\hbar}\left(\frac{(q_{i,k+1}-q_{i,k})^2}{2\Delta T} -\Delta T V(q_k)\right)\right]
\end{equation}

 \section{Multiple Dimensions}
 \subsection{Transformation}

Let's now introduce some nonlinear point transformation where 
\begin{equation}
q^j(t) = F^j[x(t)],
\end{equation}
where $x^i$ are the new curvilinear coordinates.  We have metric tensor 
\begin{equation}
g_{ij} = \frac{\partial F^r}{\partial x^i}\frac{\partial F^r}{\partial x^j} = \partial_iF^r \partial_jF^r
\end{equation}
If we take the determinant we get 
\begin{equation}
\det[g_{ij}] = \det[\partial_i F^r\partial_jF^r] = \det[(\partial_i F^r)(\partial_j F_r)^T] = \det[\partial_i F_r]^2
\end{equation}
Now we normally need the Jacobian determinant for the change of variables.  
\begin{equation}
\det\left|\frac{\partial q^i}{\partial x^j}\right| = \det|g_{ij}|^{1/2} = \sqrt{q}
\end{equation}
So the path integral in these new coordinates is
\begin{equation}
K(q_f,t_f; q_i,t_i) = \int \prod_k d^nx_k\frac{\sqrt{g}}{(2\pi i \hbar \Delta T)^{n/2}} \exp\left[ \frac{i}{\hbar}\left(\frac{(F^i_{k+1}-F^i_{k})^2}{2\Delta T} -\Delta T V[F(x_k)]\right)\right]
\end{equation}

\subsection{Ordering and Expanding.}

We will expand these operators around 
\begin{equation}
x_\alpha(k) = \left(\alpha+\frac{1}{2}\right)x(k+1) + \left(\frac{1}{2}-\alpha\right)x(k)
\end{equation}
with $-1/2\le \alpha \le 1/2$.  Then we can expand in Taylor series 
\begin{gather}
\boxed{x(k)-x_\alpha   = -\left(\alpha+\frac{1}{2}\right)\Delta x}\\
\boxed{x(k+1)-x_\alpha = \left(\frac{1}{2}-\alpha\right)\Delta x}
\end{gather}
For notational ease, let's define $\alpha_\pm = \frac{1}{2} \pm \alpha$, with $\alpha_++\alpha_- =1, \alpha_+-\alpha_- = 2\alpha$. So we have 
\begin{gather}
x_\alpha = \alpha_+ x(k+1) + \alpha_-x(k)\\
x(k) -x_\alpha  = -\alpha_+\Delta x \\
x(k+1)-x_\alpha = \alpha_-\Delta x
\end{gather}

\subsubsection{Kinetic term}
We now need to expand out to order $\Delta T$.  We will do this first in the exponential.  
\begin{align}
F^r[x(k+1)] = &F^r(x_\alpha) + \alpha_-\Delta x^i\partial_iF^r +\frac{1}{2}\alpha_-^2\Delta x^i\Delta x^j\partial_i\partial_j F^r(x_\alpha) +\frac{1}{6}\alpha_-^3\Delta x^i\Delta x^j\Delta x^k\partial_i\partial_j\partial_k F^r(x_\alpha) \\
F^r[x(k)] = &F^r(x_\alpha) - \alpha_+\Delta x^i\partial_iF^r +\frac{1}{2}\alpha_+^2\Delta x^i\Delta x^j\partial_i\partial_j F^r(x_\alpha) -\frac{1}{6}\alpha_+^3\Delta x^i\Delta x^j\Delta x^k\partial_i\partial_j\partial_k F^r(x_\alpha)
\end{align}
Now we anticipate that $\Delta x\sim\Delta T$.  We will have to treat terms like $(\Delta x)^2\sim \Delta T,$ $(\Delta x)^3/\Delta T\sim \sqrt{\Delta T},$ $(\Delta x)^4/\Delta T\sim \Delta T,$ and $(\Delta x)^6/\Delta T^2\sim \Delta T$.  
So we have 
\begin{align}
F(k+1)-F(k)&  = (\alpha_-+\alpha_+)\Delta x^i\partial_iF^r +\frac{1}{2}(\alpha_-^2-\alpha_+^2)\Delta x^i\Delta x^j\partial_i\partial_j F^r(x_\alpha) +\frac{1}{6}(\alpha_-^3+\alpha_+^3)\Delta x^i\Delta x^j\Delta x^k\partial_i\partial_j\partial_k F^r(x_\alpha) \\
&  = \Delta x^i\partial_iF^r -\alpha\Delta x^i\Delta x^j\partial_i\partial_j F^r(x_\alpha) +\left(\frac{1}{2}\alpha^2 + \frac{1}{24}\right)\Delta x^i\Delta x^j\Delta x^k\partial_i\partial_j\partial_k F^r(x_\alpha) 
\end{align}
Now square it, and divide by $\Delta T$, and work to order $\Delta T$.  
\begin{align}
\frac{[F^r(k+1)-F^r(k)]^2}{\Delta T} & = \frac{1}{\Delta T}\left[\Delta x^i\partial_iF^r -\alpha\Delta x^i\Delta x^j\partial_i\partial_j F^r +\left(\frac{1}{2}\alpha^2 + \frac{1}{24}\right)\Delta x^i\Delta x^j\Delta x^k\partial_i\partial_j\partial_k F^r\right]\nonumber\\
& \times\left[\Delta x^m\partial_mF^r -\alpha\Delta x^m\Delta x^n\partial_m\partial_n F^r +\left(\frac{1}{2}\alpha^2 + \frac{1}{24}\right)\Delta x^m\Delta x^n\Delta x^p\partial_m\partial_n\partial_p F^r\right]\\
 =& \frac{1}{\Delta T}\bigg[\Delta x^i\Delta x^j\partial_iF^r\partial_jF^r -2\alpha\Delta x^i\Delta x^j\Delta x^k\partial_iF^r \partial_j\partial_k F^r(x_\alpha) \nonumber\\
& + \alpha^2\Delta x^i\Delta x^j\Delta x^k\Delta x^l\partial_i\partial_jF\partial_k\partial_lF +\left(\alpha^2 + \frac{1}{12}\right)\Delta x^i\Delta x^j\Delta x^k\Delta x^l\partial_iF^r\partial_j\partial_k\partial_l F^r(x_\alpha)\bigg]
\end{align}
So our exponential has become 
\begin{align}
e^{i\frac{[F(k+1)-F(k)]^2}{2\hbar\Delta T}}= & \exp\left\{\frac{i}{2\hbar \Delta T}\bigg(g_{ij}\Delta x^i\Delta x^j -2\alpha\Delta x^i\Delta x^j\Delta x^k\partial_iF^r \partial_j\partial_k F^r \right. \nonumber\\
& \left. + \left[\alpha^2\partial_i\partial_jF\partial_k\partial_lF +\left(\alpha^2 + \frac{1}{12}\right)\partial_iF^r\partial_j\partial_k\partial_l F^r\right]\Delta x^i\Delta x^j\Delta x^k\Delta x^l\bigg)\right\}\\
& \approx e^{i\frac{g_{ij}\Delta x^i\Delta x^j}{2\hbar\Delta T}}\bigg\{ 1  -\frac{i}{\hbar}\alpha\partial_iF^r \partial_j\partial_k F^r\frac{\Delta x^i\Delta x^j\Delta x^k}{\Delta T}  \nonumber\\
&  +\frac{i}{\hbar}\left[\alpha^2\partial_i\partial_jF\partial_k\partial_lF +\left(\alpha^2 + \frac{1}{12}\right)\partial_iF^r\partial_j\partial_k\partial_l F^r\right]\frac{\Delta x^i\Delta x^j\Delta x^k\Delta x^l}{\Delta T}\nonumber\\
& -\frac{1}{2\hbar^2} \alpha^2\partial_iF^r \partial_j\partial_k F^r\partial_lF^r \partial_m\partial_n F^r\frac{\Delta x^i\Delta x^j\Delta x^k\Delta x^l\Delta x^m\Delta x^n}{\Delta T^2}\bigg\}
\end{align}
Let us expand this out to linear order in $\Delta T$. 

\subsubsection{Normalization}
In addition, we must also carry out the expansion for the normalization factor.  
Let's expand this out as 
\begin{align}
\sqrt{g[x(k)]} & = \sqrt{g(x_\alpha)} + \frac{1}{2}[x(k)-x_\alpha]^i\partial_i \sqrt{g} + \frac{1}{4}[x(k)-x_\alpha]^i[x(k)-x_\alpha]^j\partial_i\partial_j \sqrt{g}
\end{align}

Now we can use 
\begin{equation}
\det[A]^{1/2} = e^{\frac{1}{2}tr\ln A}
\end{equation}
so we can write 
\begin{equation}
partial_i\det[A]^{1/2} = \partial_i e^{\frac{1}{2}tr\ln A} = \frac{1}{2}\tr[A^{-1}\partial_i A] e^{\frac{1}{2}\tr\ln A}
\end{equation}
So we have 
\begin{equation}
\partial_i\sqrt{g} = \frac{1}{2}g^{jk}\partial_ig_{jk}\sqrt{g}
\end{equation}
and 
\begin{align}
\partial_i\partial_j\sqrt{g} &= \frac{1}{2}\partial_j(g^{kl}\partial_ig_{kl}\sqrt{g})\\
&= \frac{1}{2}\left[ \partial_jg^{kl}\partial_ig_{kl}\sqrt{g} + g^{kl}\partial_i\partial_j g_{kl}\sqrt{g} + \frac{1}{2}g^{kl}\partial_ig_{kl}g^{mn}\partial_jg_{mn}\sqrt{g}\right].
\end{align}
Pulling this expansion together we get 
\begin{align}
  \sqrt{g[x(k)]} & = \sqrt{g(x_\alpha)}\left[ 1 + [x(k)-x_\alpha]^i\frac{1}{2}g^{jk}\partial_ig_{jk} \right. \nonumber\\
& \left. + \frac{1}{4}[x(k)-x_\alpha]^i[x(k)-x_\alpha]^j
\left(\partial_jg^{kl}\partial_ig_{kl} + g^{kl}\partial_i\partial_j g_{kl} + \frac{1}{2}g^{kl}\partial_ig_{kl}g^{mn}\partial_jg_{mn}\right)\right]
\end{align}

\section{Point Transformation in One dimension}

Let's now think a little about one dimension.  We have all this work in higher dimensions.  How do all these 
\begin{equation}
g = \partial_x q(x)\partial_xq(x)
\end{equation}
Now $g^{-1} = 1/g$.  

We usually define the Christoffel connection as  
\begin{equation}
\Gamma^{i}_{kl}  = \frac{1}{2}g^{ij}(\partial_kg_{jl} +\partial_l g_{jk} - \partial_jg_{kl})
\end{equation}
In one dimension this becomes 
\begin{equation}
\Gamma = \frac{1}{2} g^{-1}\partial_x g = \frac{1}{2}\partial_x \ln g
\end{equation}

The Riemann Curvature tensor is 
\begin{equation}
  R^\rho_{\sigma\mu\nu} = \partial_\mu\Gamma^{\rho}_{\nu\sigma} - \partial_\nu\Gamma^\rho_{\mu\sigma} + \Gamma^{\rho}_{\mu\lambda}\Gamma^\lambda_{\nu\sigma} - \Gamma^\rho_{\nu\lambda}\Gamma^\lambda_{\mu\sigma}
\end{equation}
Due to the anti-symmetry, it is clear that this vanishes in 1D.  This is evident because you can't have any non-trivial parallalel transport.  

The Ricci tensor is 
\begin{equation}
R_{\mu\nu} = R^\lambda_{\mu\lambda\nu}
\end{equation}

\begin{equation}
  R_{\mu\nu} = \partial_\mu\Gamma^{\rho}_{\nu\rho} - \partial_\nu\Gamma^\rho_{\mu\rho} + \Gamma^{\rho}_{\mu\lambda}\Gamma^\lambda_{\nu\rho} - \Gamma^\rho_{\nu\lambda}\Gamma^\lambda_{\mu\rho}=0
\end{equation}

The Ricci scalar is 
\begin{equation}
R = {R^{\lambda\mu}} g_{\lambda\mu} =0
\end{equation}

\section{Three dimensions, diagonal metric}

Let's assume we have a metric like 
\begin{equation}
g_{ij} = g(\vect{x})\delta_{ij}
\end{equation}
Then the Christoffel symbols are 
We usually define the Christoffel connection as  
\begin{align}
\Gamma^{i}_{kl}  =& \frac{1}{2g}\delta^{ij}(\partial_kg\delta_{jl} +\partial_l g\delta_{jk} - \partial_jg\delta _{kl})
\end{align}

Let's assume that $\delta^{m}_n = \delta_{mn}?$ 
\subsubsection{Riemann Curvature Tensor}
The Riemann curvature tensor is 
\begin{align}
  R^r_{smn} =& R^{(1)} + R^{(2)}
\end{align}
where 
\begin{align}
R^{(1),r}_{smn}=&\partial_m\left(\Gamma^{r}_{ns}  \right) - \partial_n\left(\Gamma^r_{ms}\right) \\
=& \partial_m\left(\frac{1}{2g}\delta^{rt}(\partial_ng\delta_{st} +\partial_s g\delta_{nt} - \partial_tg\delta _{ns})  \right) - \partial_n\left(\frac{1}{2g}\delta^{rt}(\partial_mg\delta_{st} + \partial_sg\delta_{mt} - \partial_t g \delta_{ms})^r_{ms}\right) \\
=& \partial_m\left(\frac{1}{2g}(\partial_ng\delta^{r}_{s} +\partial_s g\delta^{r}_n - \partial_tg\delta^{rt}\delta _{ns})  \right) - \partial_n\left(\frac{1}{2g}(\partial_mg\delta^{r}_{s} + \partial_sg\delta^{r}_{m} - \delta^{rt}\partial_t g \delta_{ms})\right) \\
% =& -\frac{\partial_m g}{2g^2}(\partial_ng\delta^{r}_{s} +\partial_s g\delta^{r}_n - \partial_tg\delta^{rt}\delta _{ns}) + \frac{1}{2g}(\partial_m\partial_ng\delta^{r}_{s} +\partial_m\partial_s g\delta^{r}_n - \partial_m\partial_tg\delta^{rt}\delta _{ns})\nonumber\\
% & + \frac{\partial_n g}{2g^2}(\partial_mg\delta^{r}_{s} + \partial_sg\delta^{r}_{m} - \delta^{rt}\partial_t g \delta_{ms}) -\frac{1}{2g}(\partial_n\partial_mg\delta^{r}_{s} + \partial_n\partial_sg\delta^{r}_{m} - \delta^{rt}\partial_n\partial_t g \delta_{ms})\\
% =& -\frac{\partial_m g}{2g^2}(\partial_s g\delta^{r}_n - \partial_tg\delta^{rt}\delta _{ns}) + \frac{1}{2g}(\partial_m\partial_s g\delta^{r}_n - \partial_m\partial_tg\delta^{rt}\delta _{ns})\nonumber\\
% & + \frac{\partial_n g}{2g^2}( \partial_sg\delta^{r}_{m} - \delta^{rt}\partial_t g \delta_{ms}) -\frac{1}{2g}( \partial_n\partial_sg\delta^{r}_{m} - \delta^{rt}\partial_n\partial_t g \delta_{ms})\\
% =& -\frac{\partial_m g}{2g^2}(\partial_s g\delta_{rn} - \partial_rg\delta _{ns}) + \frac{1}{2g}(\partial_m\partial_s g\delta_{rn} - \partial_m\partial_rg\delta _{ns})\nonumber\\
% & + \frac{\partial_n g}{2g^2}( \partial_sg\delta_{rm} - \partial_r g \delta_{ms}) -\frac{1}{2g}( \partial_n\partial_sg\delta_{rm} - \partial_n\partial_r g \delta_{ms})\\
=&\frac{1}{2g}(\partial_m\partial_s g\delta_{rn} - \partial_m\partial_rg\delta _{ns})  -\frac{1}{2g}( \partial_n\partial_sg\delta_{rm} - \partial_n\partial_r g \delta_{ms}) \nonumber\\
&+ \frac{1}{2g^2}\partial_s g (\partial_ng\delta_{rm}-\partial_mg \delta_{rn}) - \frac{1}{2g^2}\partial_rg(\partial_ng\delta_{ms} -\partial_mg\delta _{ns}),
\end{align}
and 
\begin{align}
R^{(2),r}_{smn}=&\Gamma^{r}_{ml}\Gamma^l_{ns} - \Gamma^r_{nl}\Gamma^l_{ms}\\
=&\frac{1}{4g^2}\delta^{rt}(\partial_m g\delta_{tl} + \partial_l g\delta_{mt} - \partial_t g\delta_{lm})\delta^{lt}(\partial_ng\delta_{st} + \partial_sg\delta_{nt} - \partial_tg_{ns}) \nonumber\\
&-\frac{1}{4g^2}\delta^{rt}(\partial_n g\delta_{tl} + \partial_l g\delta_{nt} - \partial_t g\delta_{ln})\delta^{lt}(\partial_mg\delta_{st} + \partial_sg\delta_{mt} - \partial_tg_{ms})\\
% =&\frac{1}{4g^2}\bigg(\partial_m g\delta^{r}_{l} + \partial_l g\delta^{r}_{m} - \partial_t g\delta^{rt}\delta_{lm})(\partial_ng\delta^{l}_{s} + \partial_sg\delta^{l}_{n} - \partial_tg\delta^{lt}\delta_{ns}) \nonumber\\
% &-(\partial_n g\delta^{r}_{l} + \partial_l g\delta^{r}_{n} - \partial_t g\delta^{rt}\delta_{ln})(\partial_mg\delta^{l}_{s} + \partial_sg\delta^{l}_{m} - \partial_tg\delta^{lt}\delta_{ms})\bigg)\\
%
% =&\partial_m g(\partial_sg\delta_{rn} - \partial_rg\delta_{ns}) \nonumber\\
% &-\partial_n g( \partial_sg\delta_{rm} - \partial_rg\delta_{ms}) \nonumber\\
% &+ (\partial_s g\delta_{rm}\partial_ng + \partial_n g\delta_{rm}\partial_sg - \partial_l g\partial_lg\delta_{ns}\delta_{rm}) \nonumber\\
% &- \partial_s g\delta_{rn}\partial_mg - \partial_m g\delta_{rn}\partial_sg + \partial_l g\delta_{rn}\partial_lg\delta_{ms}
%  \nonumber\\
% &- 2\partial_r g(\partial_ng\delta_{ms} - \partial_mg\delta_{ns}) \\
% =&\partial_s g (\partial_mg\delta_{rn} - \partial_n g\delta_{rm}) +\partial_r g (\partial_n \delta_{ms}-\partial_m g\delta_{ns}) \nonumber\\
% &+ 2\partial_s g(\delta_{rm}\partial_ng -\delta_{rn}\partial_mg) - 2\partial_r g(\partial_ng\delta_{ms} - \partial_mg\delta_{ns}) \nonumber\\
% & + \partial_l g\partial_lg(\delta_{rn}\delta_{ms}- \delta_{ns}\delta_{rm})\\
= &\frac{1}{4g^2}\partial_s g(\delta_{rm}\partial_ng -\delta_{rn}\partial_mg) - \frac{1}{4g^2}\partial_r g(\partial_ng\delta_{ms} - \partial_mg\delta_{ns}) \nonumber\\
& + \frac{1}{4g^2}\partial_l g\partial_lg(\delta_{rn}\delta_{ms}- \delta_{ns}\delta_{rm})
\end{align}
Now pull $R^{(1)}$ and $R^{(2)}$ together.  
\begin{align}
R^r_{smn}=&\frac{1}{2g}(\partial_m\partial_s g\delta_{rn} - \partial_m\partial_rg\delta _{ns})  -\frac{1}{2g}( \partial_n\partial_sg\delta_{rm} - \partial_n\partial_r g \delta_{ms}) \nonumber\\
&+ \frac{1}{2g^2}\partial_s g (\partial_ng\delta_{rm}-\partial_mg \delta_{rn}) - \frac{1}{2g^2}\partial_rg(\partial_ng\delta_{ms} -\partial_mg\delta _{ns})\nonumber\\
& +\frac{1}{4g^2}\partial_s g(\delta_{rm}\partial_ng -\delta_{rn}\partial_mg) - \frac{1}{4g^2}\partial_r g(\partial_ng\delta_{ms} - \partial_mg\delta_{ns}) \nonumber\\
& + \frac{1}{4g^2}\partial_l g\partial_lg(\delta_{rn}\delta_{ms}- \delta_{ns}\delta_{rm})\\
=&\frac{1}{2g}(\partial_m\partial_s g\delta_{rn} - \partial_m\partial_rg\delta _{ns})  -\frac{1}{2g}( \partial_n\partial_sg\delta_{rm} - \partial_n\partial_r g \delta_{ms}) \nonumber\\
&+ \frac{3}{4g^2}\partial_s g (\partial_ng\delta_{rm}-\partial_mg \delta_{rn}) - \frac{3}{4g^2}\partial_rg(\partial_ng\delta_{ms} -\partial_mg\delta _{ns})\nonumber\\
& + \frac{1}{4g^2}\partial_l g\partial_lg(\delta_{rn}\delta_{ms}- \delta_{ns}\delta_{rm})
\end{align}

\subsubsection{Ricci tensor}

The Ricci tensor is 
\begin{equation}
R_{sn} = R^r_{srn}
\end{equation}
So we have
\begin{align}
R_{sn}=&\frac{1}{2g}(\partial_r\partial_s g\delta_{rn} - \partial_r\partial_rg\delta _{ns})  -\frac{1}{2g}( \partial_n\partial_sg\delta_{rr} - \partial_n\partial_r g \delta_{rs}) \nonumber\\
&+ \frac{3}{4g^2}\partial_s g (\partial_ng\delta_{rr}-\partial_rg \delta_{rn}) - \frac{3}{4g^2}\partial_rg(\partial_ng\delta_{rs} -\partial_rg\delta _{ns})\nonumber\\
& + \frac{1}{4g^2}\partial_l g\partial_lg(\delta_{rn}\delta_{rs}- \delta_{ns}\delta_{rr})\\
% =&\frac{1}{2g}(\partial_n\partial_s g - \partial_r\partial_rg\delta _{ns})  -\frac{1}{2g}\partial_n\partial_sg ( d -1 ) \nonumber\\
% &+ \frac{3}{4g^2}\partial_n g \partial_s g ( d-1 ) - \frac{3}{4g^2}(\partial_sg\partial_ng -\partial_rg\partial_rg\delta _{ns})\nonumber\\
% & - \frac{1}{4g^2}\partial_r g\partial_rg\delta_{ns}(d-1)\\
=&-\frac{1}{2g}\partial_n\partial_s g(d-2) - \frac{1}{2g}\partial_r\partial_rg\delta _{ns}  + \frac{3}{4g^2}\partial_n g \partial_s g ( d-2 )  - \frac{1}{4g^2}\partial_r g\partial_rg\delta_{ns}(d-4)
\end{align}
\subsubsection{Ricci scalar}
Then we finally have
\begin{align}
R&=g^{ns}R_{ns}\\
&=\frac{1}{g}\delta^{ns}\left(-\frac{1}{2g}\partial_n\partial_s g(d-2) - \frac{1}{2g}\partial_r\partial_rg\delta _{ns}  + \frac{3}{4g^2}\partial_n g \partial_s g ( d-2 )  - \frac{1}{4g^2}\partial_r g\partial_rg\delta_{ns}(d-4)\right)\\
% &=-\frac{1}{2g^2}\partial_n\partial_n g(d-2) - \frac{1}{2g^2}\partial_r\partial_rg d  + \frac{3}{4g^3}\partial_n g \partial_n g ( d-2 )  - \frac{1}{4g^3}\partial_n g\partial_ng d(d-4)\\
% &=-\frac{1}{g^2}\partial_n\partial_n g(d-1)   - \frac{1}{4g^3}\partial_n g \partial_n g \left(  d^2 -3d +6 \right) \\
&=-\frac{1}{g^2}\partial_n\partial_n g(d-1)   - \frac{1}{4g^3}\partial_n g \partial_n g (d-2)(d-1)
\end{align}


\section{Transforming a One-Dimensional path integral}
\subsection{Transformation}

Let's now introduce some nonlinear point transformation where 
\begin{equation}
q(t) = F[x(t)],
\end{equation}
where $x$ are the new ``curvilinear'' coordinates.  We have metric tensor 
\begin{equation}
g = \frac{\partial F}{\partial x}\frac{\partial F}{\partial x} = (\partial_xF)^2
\end{equation}
Now we normally need the Jacobian determinant for the change of variables.  
\begin{equation}
J = \sqrt{g}
\end{equation}
We have a flat space propagator which satisfies 
\begin{align}
\psi(q_n,t_n) &= \int dq_0 K(q_n,t_n; q_0,t_0)\psi(q_0,t_0)\\
&= \int dx \sqrt{g(x_0)}K(x_n,t_n; x_0,t_0)\psi(x_0,t_0)
\end{align}
So the path integral in these new coordinates is
\begin{equation}
K(x_n,t_n; x_0,t_0) = \frac{1}{\sqrt{g(x_0)}}\int \prod_{k=1}^{n-1} dx_k\frac{\sqrt{g_k}}{\sqrt{2\pi i \hbar \Delta T}} \exp\left[ \frac{i}{\hbar}\left(\frac{(F_{k+1}-F_{k})^2}{2\Delta T} -\Delta T V[F(x_k)]\right)\right],
\end{equation}
where we had to multiply and divide by $\sqrt{g(x_0)}$. 
\subsection{Ordering and Expanding.}

We will expand these operators around 
\begin{equation}
x_\alpha(k) = \left(\alpha+\frac{1}{2}\right)x(k+1) + \left(\frac{1}{2}-\alpha\right)x(k)
\end{equation}
with $-1/2\le \alpha \le 1/2$.  Then we can expand in Taylor series 
\begin{gather}
\boxed{x(k)-x_\alpha   = -\left(\alpha+\frac{1}{2}\right)\Delta x}\\
\boxed{x(k+1)-x_\alpha = \left(\frac{1}{2}-\alpha\right)\Delta x}
\end{gather}

For notational ease, let's define $\alpha_\pm = \frac{1}{2} \pm \alpha$, with $\alpha_++\alpha_- =1, \alpha_+-\alpha_- = 2\alpha$. So we have 
\begin{gather}
x_\alpha = \alpha_+ x(k+1) + \alpha_-x(k)\\
x(k)   = x_\alpha-\alpha_+\Delta x \\
x(k+1) = x_\alpha+\alpha_-\Delta x
\end{gather}

\subsubsection{Kinetic term}
We now need to expand out to order $\Delta T$.  We will do this first in the exponential.  
\begin{align}
F[x(k+1)] = &F(x_\alpha) + \alpha_-\Delta x\partial_xF +\frac{1}{2}\alpha_-^2\Delta x^2\partial_x^2F(x_\alpha) +\frac{1}{6}\alpha_-^3\Delta x^3\partial_x^3F(x_\alpha) \\
F[x(k)] = &F(x_\alpha) - \alpha_+\Delta x\partial_xF +\frac{1}{2}\alpha_+^2\Delta x^2\partial_x^2 F(x_\alpha) -\frac{1}{6}\alpha_+^3\Delta x^3\partial_x^3 F(x_\alpha)
\end{align}
Now we anticipate that $\Delta x\sim\Delta T$.  We will have to treat terms like $(\Delta x)^2\sim \Delta T,$ $(\Delta x)^3/\Delta T\sim \sqrt{\Delta T},$ $(\Delta x)^4/\Delta T\sim \Delta T,$ and $(\Delta x)^6/\Delta T^2\sim \Delta T$.  
So we have 
\begin{align}
F(k+1)-F(k)&  = (\alpha_-+\alpha_+)\Delta x F' +\frac{1}{2}(\alpha_-^2-\alpha_+^2)\Delta x^2 F'' +\frac{1}{6}(\alpha_-^3+\alpha_+^3)\Delta x^3 F''' \\
&  = \Delta xF' -\alpha\Delta x^2F''(x_\alpha) +\left(\frac{1}{2}\alpha^2 + \frac{1}{24}\right)\Delta x^3  F'''(x_\alpha) 
\end{align}
Now square it, and divide by $\Delta T$, and work to order $\Delta T$.  Let us now use $F' = \sqrt{g}$.  
\begin{align}
\frac{[F^r(k+1)-F^r(k)]^2}{\Delta T} & = \frac{1}{\Delta T}\left[\Delta xF' -\alpha\Delta x^2F''(x_\alpha) +\left(\frac{1}{2}\alpha^2 + \frac{1}{24}\right)\Delta x^3  F'''(x_\alpha) \right]^2\\
 % =& \frac{1}{\Delta T}\bigg[\Delta x^2(F')^2 -2\alpha\Delta x^3F' F'' + \alpha^2\Delta x^4F''F'' +\left(\alpha^2 + \frac{1}{12}\right)\Delta x^4F' F'''\bigg]\\
 % =& \frac{1}{\Delta T}\bigg[\Delta x^2 g -2\alpha\Delta x^3\sqrt{g}\sqrt{g}' + \alpha^2\Delta x^4(\sqrt{g}')^2 +\left(\alpha^2 + \frac{1}{12}\right)\Delta x^4\sqrt{g}\sqrt{g}''\bigg]\\
 =& \frac{1}{\Delta T}\bigg[\Delta x^2 g -\alpha\Delta x^3g' + \alpha^2\Delta x^4\frac{(g')^2}{4g} +\left(\alpha^2 + \frac{1}{12}\right)\Delta x^4\left(\frac{g''}{2}  - \frac{(g')^2}{4g}\right)\bigg]
\end{align}


\subsubsection{Normalization}
In addition, we must also carry out the expansion for the normalization factor.  Let's expand this out as 
\begin{align}
\sqrt{g[x(k)]} & = \sqrt{g(x_\alpha)} + (x(k)-x_\alpha)\frac{g'}{2\sqrt{g}} + \frac{1}{2}(x(k)-x_\alpha)^2\left(\frac{g''}{2\sqrt{g}} - \frac{(g')^2}{4 g^{3/2}}\right)\\
& = \sqrt{g(x_\alpha)}\left[1 -\alpha_+\Delta x\frac{g'}{2g} + \frac{1}{2}\alpha_+^2\Delta x^2\left(\frac{g''}{2g} - \frac{(g')^2}{4 g^{2}}\right)\right]
\end{align}

\subsubsection{Expanding the exponential and normalization}

So the exponential expansion is 
\begin{align}
K & = \frac{1}{\sqrt{g(x_0)}}\int \prod_{k=1}^{n-1} dx_k\frac{\sqrt{g_k}}{\sqrt{2\pi i \hbar \Delta T}} \exp\left[ \frac{i}{\hbar}\left(\frac{(F_{k+1}-F_{k})^2}{2\Delta T} -\Delta T V[F(x_k)]\right)\right]\\
& = \int \prod_{j=1}^{n-1} dx_j \sqrt{\frac{g(x_\alpha)}{2\pi i \hbar\Delta T}}   e^{i\frac{g(x_\alpha)\Delta x^2}{2\hbar\Delta T} -iV(x_\alpha)\Delta T}\left[1 -\alpha_+\Delta x\frac{g'}{2g} + \frac{1}{2}\alpha_+^2\Delta x^2\left(\frac{g''}{2g} - \frac{(g')^2}{4 g^{2}}\right)\right]\nonumber\\
&\times \exp\bigg\{ -\frac{i\alpha}{2\hbar}g'\frac{\Delta x^3}{\Delta T} + \frac{i\alpha^2}{8\hbar}\frac{(g')^2}{g}\frac{\Delta x^4}{\Delta T} +\frac{i}{2\hbar}\left(\alpha^2 + \frac{1}{12}\right)\frac{\Delta x^4}{\Delta T}\left(\frac{g''}{2}  - \frac{(g')^2}{4g}\right)\bigg]\bigg\}
\end{align}
Let's now expand that exponential 
\begin{align}% 
K& = \frac{1}{\sqrt{g(x_0)}}\int \prod_{j=1}^{n-1} dx_j \sqrt{\frac{g(x_\alpha)}{2\pi i \hbar\Delta T}}   e^{i\frac{g(x_\alpha)\Delta x^2}{2\hbar\Delta T} -iV(x_\alpha)\Delta T}\left[1 -\alpha_+\Delta x\frac{g'}{2g} + \frac{1}{2}\alpha_+^2\Delta x^2\left(\frac{g''}{2g} - \frac{(g')^2}{4 g^{2}}\right)\right]\nonumber\\
&\times \bigg\{1 -\frac{i\alpha}{2\hbar}g'\frac{\Delta x^3}{\Delta T}  + \frac{i\alpha^2}{8\hbar}\frac{(g')^2}{g}\frac{\Delta x^4}{\Delta T}+\frac{i}{2\hbar}\left(\alpha^2 + \frac{1}{12}\right)\frac{\Delta x^4}{\Delta T}\left(\frac{g''}{2}  - \frac{(g')^2}{4g}\right) - \frac{\alpha^2}{8\hbar^2}(g')^2\frac{\Delta x^6}{(\Delta T)^2}\bigg]\bigg\}\\
& = \int \prod_{j=1}^{n-1} dx_j \sqrt{\frac{g(x_\alpha)}{2\pi i \hbar\Delta T}}   e^{i\frac{g(x_\alpha)\Delta x^2}{2\hbar\Delta T} -iV(x_\alpha)\Delta T} C,
\end{align}
where the prefactor is 
\begin{align}
C =&1 -\alpha_+\Delta x\frac{g'}{2g} + \frac{1}{2}\alpha_+^2\Delta x^2\left(\frac{g''}{2g} - \frac{(g')^2}{4 g^{2}}\right)-\frac{i\alpha}{2\hbar}g'\frac{\Delta x^3}{\Delta T}\nonumber\\
&   + \left[\frac{i\alpha^2}{8\hbar}\frac{(g')^2}{g}+\frac{i}{2\hbar}\left(\alpha^2 + \frac{1}{12}\right)\left(\frac{g''}{2}  - \frac{(g')^2}{4g}\right) +\frac{i\alpha_+\alpha}{4\hbar}\frac{(g')^2}{g}\right]\frac{\Delta x^4}{\Delta T} \nonumber\\
&- \frac{\alpha^2}{8\hbar^2}(g')^2\frac{\Delta x^6}{(\Delta T)^2}.
\end{align}


\subsection{Replacing higher moments with their averages}

Using the above moment theorems We can then make the following replacements which are correct to $\order(\Delta T)$.  

\begin{align}
\Delta x^2 \dot{=} & i\hbar\frac{1}{g}\Delta T\\
\frac{\Delta x^3}{\Delta T} \dot{=}& 3i\hbar \frac{1}{g} \Delta x\\
\frac{\Delta x^4}{\Delta T} \dot{=}& 3(i\hbar)^2\frac{1}{g^2}\Delta T\\
\frac{\Delta x^6}{\Delta T^2} \dot{=}& 15(i\hbar)^3\frac{1}{g^3}\Delta T
\end{align}

The new averaged prefactor is 
\begin{align}
C =&1 -\alpha_+\Delta x\frac{g'}{2g} + \frac{1}{2}\alpha_+^2\left(\frac{g''}{2g} - \frac{(g')^2}{4 g^{2}}\right)\left(i\hbar\frac{\Delta T}{g}\right)-\frac{i\alpha}{2\hbar}g'\left(3i\hbar \frac{\Delta x}{g}\right)\nonumber\\
&   + \left[\frac{i\alpha^2}{8\hbar}\frac{(g')^2}{g}+\frac{i}{2\hbar}\left(\alpha^2 + \frac{1}{12}\right)\left(\frac{g''}{2}  - \frac{(g')^2}{4g}\right) +\frac{i\alpha_+\alpha}{4\hbar}\frac{(g')^2}{g}\right]\left(3(i\hbar)^2\frac{1}{g^2}\Delta T\right) \nonumber\\
&- \frac{\alpha^2}{8\hbar^2}(g')^2\left(15(i\hbar)^3\frac{1}{g^3}\Delta T\right)\\
% =&1 +\alpha\Delta x\frac{g'}{g}-\frac{g'}{4g}\Delta x + \frac{i\hbar}{2}\left(\alpha +\frac{1}{2}\right)^2\left(\frac{g''}{2g^2} - \frac{(g')^2}{4 g^{3}}\right)\Delta T\nonumber\\
% & -  3i\hbar\Delta T \left[\frac{3\alpha^2}{8}\frac{(g')^2}{g^3}+\frac{1}{2}\left(\alpha^2 + \frac{1}{12}\right)\left(\frac{g''}{2 g^2}  - \frac{(g')^2}{4g^3}\right) +\frac{\alpha}{8}\frac{(g')^2}{g^3}\right]+15i\hbar\frac{(g')^2}{g^3} \frac{\alpha^2}{8}\Delta T\\
% =&1 +\left(\alpha-\frac{1}{4}\right)\Delta x\frac{g'}{g} + \frac{i\hbar}{2}\left[ \left(\alpha +\frac{1}{2}\right)^2 -3\left(\alpha^2 + \frac{1}{12}\right)\right]\left(\frac{g''}{2g^2} - \frac{(g')^2}{4 g^{3}}\right)\Delta T\nonumber\\
% & +  \frac{3i}{4}\hbar\Delta T \left(\alpha^2-\frac{\alpha}{2}\right)\frac{(g')^2}{g^3}\\
=&1 +\left(\alpha-\frac{1}{4}\right)\Delta x\frac{g'}{g} + i\hbar\left(\alpha^2 -\frac{\alpha}{2}\right)\left( \frac{(g')^2}{ g^{3}}-\frac{g''}{2g^2}\right)\Delta T 
\end{align}


\subsection{Moment theorems}
This follows (and fixed a typo in) Dan's work.  
Let us now consider evaluating Gaussian moments of the form,
\begin{equation}
E_{\sigma(x)}[x^n] = \int dx\, x^n \frac{e^{-\frac{x^2}{2\sigma^2(x)\Delta T}}}{\sqrt{2\pi\sigma^2(x)\Delta T}}
\end{equation}
We will treat $x$ as $\order(\sqrt{\Delta T})$
Now expand about the origin
\begin{gather}
\sigma(x) \approx \sigma(\mu) + (x-\mu)\sigma'(\mu)\\
\frac{1}{\sigma(x)} \approx \frac{1}{\sigma(\mu)} -\frac{\sigma'(\mu)}{\sigma^2(\mu)}(x-\mu)\\
\frac{1}{\sigma^2(x)} \approx \frac{1}{\sigma^2(\mu)} -\frac{2\sigma'(\mu)}{\sigma^3(\mu)}(x-\mu)
\end{gather}
We have to deal with moments like $\Delta x^{2n}/\Delta T^{2(n-1)}$ and $\Delta x^{2n+1}/\Delta x^{2n-1}$.  
Now note that our correction is already $\Delta T$ for even moments, or $\order(\sqrt{\Delta T})$ for the odd moments.  So for even moments, we can drop the corrections, whereas for odd moments we will have to keep the first order correction.  

\subsubsection{Normal Gaussian Moment theorem}

Let's now think about the recursion relations for the Gaussian moment theorem.  
\begin{align}
E[x^n] =& \int dx\,x^n \frac{e^{-\frac{x^2}{2\sigma^2}}}{\sqrt{2\pi\sigma^2}}\\
 =&  -\sigma^2x^{n-1}e^{-\frac{x^2}{2\sigma^2}}\bigg|_{x=-\infty}^{\infty} + \int dx\,(n-1)\sigma^2x^{n-2} \frac{e^{-\frac{x^2}{2\sigma^2}}}{\sqrt{2\pi\sigma^2}}\\
 =&  (n-1)\sigma^2E[x^{n-2}]
\end{align}

Now for $\mu = 0$, only $m=n$ contributes, and 
\begin{align}
E[x^n] = (n-1)\sigma^2E[x^{n-2}]
\end{align}

So for even moments you get $n = 2k$
\begin{equation}
E[x^{2k}] = (2k-1)!!\sigma^{2k},\quad k =1,2,\ldots
\end{equation}
where $n!! = n(n-2)(n-4)(n-6)\ldots 1$.  (The recursion truncates at $2k-2n = 0$, or $n = k$).  For odd moments we get $n=2k-1$
\begin{equation}
E[x^{2k-1}] = (2k-2)\sigma^2E[x^{2k-3}] = (2k-2)!!\sigma^{2k-2}E[x]
\end{equation}
Repeat for $m$ steps until $2k-1-2m = 1$, or $m=k-1$.  

\subsubsection{Odd moments}

Note that we want to simplify $x^3/\Delta T$, which is order $\Delta T^{1/2}$.  
\begin{align}
  E_{\sigma(x)}\left[\frac{x^{2n+1}}{\Delta T^{n}}\right] =& \int dx\, \frac{x^{2n+1}}{\Delta T^{n}} \frac{e^{-\frac{x^2}{2\sigma^2(x)\Delta T}}}{\sqrt{2\pi\sigma^2(x)\Delta T}}\\
% \approx&  \int dx\, \frac{x^{2n+1}}{\Delta T^{n}}\frac{e^{-\frac{x^2}{2\sigma^2\Delta T}}}{\sqrt{2\pi\sigma^2\Delta T}} \left[1 - x\frac{\sigma'}{\sigma}  \right]\left[1 + \frac{2\sigma'}{\sigma}\frac{x^3}{2\sigma^2\Delta T}\right]\\
 \approx&  \int dx\, \frac{e^{-\frac{x^2}{2\sigma^2\Delta T}}}{\sqrt{2\pi\sigma^2\Delta T}} \left[\frac{x^{2n+1}}{\Delta T^{n}} - \frac{x^{2n+2}}{\Delta T^{n}}\frac{\sigma'}{\sigma}  + \frac{x^{2n+4}}{\Delta T^{n+1}}\frac{\sigma'}{\sigma^3}\right]
\end{align}
Where we expanded everything to $\order(\Delta T^{1/2})$, since the coefficient is already $\order\Delta T^{1/2}$.  Now we integrate by parts 
\begin{align}
 E_{\sigma(x)}\left[\frac{x^{2n+1}}{\Delta T^{n}}\right]=&-\sigma^2\Delta T\frac{e^{-\frac{x^2}{2\sigma^2\Delta T}}}{\sqrt{2\pi\sigma^2\Delta T}} \left[\frac{x^{2n}}{\Delta T^{n}} - \frac{x^{2n+1}}{\Delta T^{n}}\frac{\sigma'}{\sigma}  + \frac{x^{2n+3}}{\Delta T^{n+1}}\frac{\sigma'}{\sigma^3}\right]_{x=-\infty}^{\infty}\nonumber\\
&+\sigma^2\int dx\, \frac{e^{-\frac{x^2}{2\sigma^2\Delta T}}}{\sqrt{2\pi\sigma^2\Delta T}} \left[2n\frac{x^{2n-1}}{\Delta T^{n-1}} - \frac{(2n+1)x^{2n}}{\Delta T^{n-1}}\frac{\sigma'}{\sigma}  + \frac{(2n+3)x^{2n+2}}{\Delta T^{n}}\frac{\sigma'}{\sigma^3}\right]\\
=&\sigma^2\int dx\, \frac{x^{2n-1}}{\Delta T^{n-1}}\frac{e^{-\frac{x^2}{2\sigma^2\Delta T}}}{\sqrt{2\pi\sigma^2\Delta T}} \left[2n - (2n+1)x\frac{\sigma'}{\sigma}  + \frac{(2n+3)x^{3}}{\Delta T}\frac{\sigma'}{\sigma^3}\right]
\end{align}

Now isolate the coefficient of the lower moment we want.  Integrate by parts once more on the extra term.  
\begin{align}
 E_{\sigma(x)}\left[\frac{x^{2n+1}}{\Delta T^{n}}\right]=&(2n+1)\sigma^2\int dx\, \frac{x^{2n-1}}{\Delta T^{n-1}}\frac{e^{-\frac{x^2}{2\sigma^2\Delta T}}}{\sqrt{2\pi\sigma^2\Delta T}} \left[1 - x\frac{\sigma'}{\sigma}  + \frac{x^{3}}{\Delta T}\frac{\sigma'}{\sigma^3}\right] \nonumber \\
&+\int dx\, \frac{x^{2n-1}}{\Delta T^{n-1}}\frac{e^{-\frac{x^2}{2\sigma^2\Delta T}}}{\sqrt{2\pi\sigma^2\Delta T}} \left[-\sigma^2+ \frac{2x^{3}}{\Delta T}\frac{\sigma'}{\sigma}\right] \\
% =&(2n+1)\sigma^2E_{\sigma(x)}\left[\frac{x^{2n-1}}{\Delta T^{n-1}}\right]+2\sigma'\sigma \int dx\, \frac{e^{-\frac{x^2}{2\sigma^2\Delta T}}}{\sqrt{2\pi\sigma^2\Delta T}} \frac{x^{2n+1}}{\Delta T^{n}}\\
% =&(2n+1)\int dx \frac{e^{-\frac{x^2}{2\sigma^2(x)\Delta T}}}{\sqrt{2\pi\sigma^2(x)\Delta T}}\frac{x^{2n-1}}{\Delta T^{n-1}}\left[\sigma^2 + 2\sigma'\sigma\right]\\
 \approx&(2n+1)\int dx \frac{e^{-\frac{x^2}{2\sigma^2(x)\Delta T}}}{\sqrt{2\pi\sigma^2(x)\Delta T}}\frac{x^{2n-1}}{\Delta T^{n-1}}\sigma^2(x)\\
%=&(2n+1)E_{\sigma(x)}\left[\sigma^2(x)\frac{x^{2n-1}}{\Delta T^{n-1}}\right]\\
=&(2n+1)!!E_{\sigma(x)}\left[\sigma^{2n}(x)x\right]
\end{align}
In the last line we used the recursion relation $n$ times.  



 \subsection{Dan's log trick}

We have terms, which we can exponentiate as 
\begin{equation}
1 + \left(\alpha-\frac{1}{4}\right)\frac{g'}{g}\Delta x = \exp\left[\left(\alpha - \frac{1}{4}\right)\frac{g'}{g}\Delta x-\frac{1}{2}\left(\alpha-\frac{1}{4}\right)^2\frac{g'^2}{g^2}\Delta x^2\right]
\end{equation}
We will rewrite this as the variation of a logarithm.  We will then be able to relate these linear terms to a normalization factor.  We can expand the log out to second order as 
\begin{equation}
\log(y +dy) = \log(y) +\frac{dy}{y} - \frac{1}{2}\frac{dy^2}{y^2}.
\end{equation}
We will expand functions of $x_{k+1}$ and $x_k$ around  $x_\alpha$.  
\begin{align}
\log\left[\frac{g(x_{k+1})}{g(x_k)}\right] =& \log[g(x_\alpha+\alpha_-\Delta x)] - \log[ g(x_\alpha -\alpha_+\Delta x)]\\
% =& \log\left[g(x_{\alpha})+\alpha_-\Delta x g' + \alpha_-^2\frac{\Delta x^2}{2} g''\right] - \log\left[g(x_{\alpha})-\alpha_+\Delta x g' + \alpha_+^2\frac{\Delta x^2}{2} g''\right]\\
% =& \left(\log[g(x_\alpha)] + \alpha_-\Delta x \frac{g'}{g} + \frac{\alpha^2_-\Delta x^2}{2}\frac{g''}{g} - \alpha_-^2\frac{\Delta x^2}{2}\frac{(g')^2}{g^2}\right) \nonumber\\
% &- \left(\log[g(x_\alpha)] - \alpha_+\Delta x \frac{g'}{g} + \frac{\alpha^2_+\Delta x^2}{2}\frac{g''}{g} - \alpha_+^2\frac{\Delta x^2}{2}\frac{(g')^2}{g^2}\right)\\
% =& (\alpha_+ +\alpha_-)\frac{g'}{g}\Delta x -(\alpha^2_+-\alpha^2_-)\frac{g''}{2g}\Delta x^2 + (\alpha_+^2-\alpha_-^2)\frac{(g')^2}{2g^2}\\  
=&   \Delta x \frac{g'}{g} -\alpha\Delta x^2\frac{g''}{g} + \alpha\Delta x^2\frac{(g')^2}{g^2}
\end{align}
So we can write 
\begin{align}
\frac{g'}{g}\Delta x = \log\left[\frac{g(x_{k+1})}{g(x_k)}\right]  +\alpha\Delta x^2\left(\frac{g''}{g} -\frac{(g')^2}{g^2}\right)\label{eq:velocity_log}
\end{align}
Plugging in this expansion for the exponent we have
\begin{align}
1 + \left(\alpha-\frac{1}{4}\right)\frac{g'}{g}\Delta x  =& \exp\left[\left(\alpha - \frac{1}{4}\right)\frac{g'}{g}\Delta x-\frac{1}{2}\left(\alpha-\frac{1}{4}\right)^2\frac{g'^2}{g^2}\Delta x^2\right]\\
%  =& \exp\left[\left(\alpha - \frac{1}{4}\right)\left[\log\left(\frac{g(x_{k+1})}{g(x_k)}\right)  +\alpha\Delta x^2\left(\frac{g''}{g} - \frac{(g')^2}{g^2}\right)\right]-\frac{1}{2}\left(\alpha-\frac{1}{4}\right)^2\frac{g'^2}{g^2}\Delta x^2\right]\\
%  =& \exp\left[\left(\alpha - \frac{1}{4}\right)\log\left(\frac{g(x_{k+1})}{g(x_k)}\right)  +\alpha\left(\alpha - \frac{1}{4}\right)\Delta x^2\frac{g''}{g}\right]\nonumber\\
% &\times\exp\left\{-\Delta x^2\frac{(g')^2}{g^2}\left[\frac{1}{2}\left(\alpha-\frac{1}{4}\right)^2+\alpha\left(\alpha - \frac{1}{4}\right)\right]\right\}\\
 =& \exp\left[\left(\alpha - \frac{1}{4}\right)\log\left(\frac{g(x_{k+1})}{g(x_k)}\right)  +\alpha\left(\alpha - \frac{1}{4}\right)\Delta x^2\frac{g''}{g}\right]\nonumber\\
&\times\exp\left[-\Delta x^2\frac{(g')^2}{g^2}\left(\frac{3\alpha^2}{2} -\frac{\alpha}{2}+\frac{1}{32}\right)\right]
%=& \exp\left[\left(\alpha - \frac{1}{4}\right)\log\left(\frac{g(x_{k+1})}{g(x_k)}\right) +i\hbar\Delta T\left(\alpha^2 - \frac{\alpha}{4}\right)\frac{g''}{g^2} - i\hbar\Delta T\left[\alpha ^3+\frac{\alpha^2}{4}  - \frac{1}{32}\right]\frac{g'^2}{g^3}\right],
\end{align}
where in the third line we expanded the exponential to order $\Delta T$, used the moment theorem, and re-exponentiated the result.  So this is a bit unwieldy. 

\subsection{Restoring the rest: The effective potential}

Now we are in a position to restore the rest of this mess.  
We can now exponentiate the remaining $\Delta T$ terms, which will give a potential, (recalling $e^{\frac{i}{\hbar}S}=e^{\frac{i\Delta T}{\hbar}(K-V)}$)
\begin{align}
  \frac{-V_{\text{tot}}+V_{\text{ext}}}{\hbar} &= \left(\alpha^2 - \frac{\alpha}{4}\right)\frac{g''}{g^2} -\left(\frac{3}{2}\alpha ^2-\frac{\alpha}{2}  + \frac{1}{32}\right)\frac{g'^2}{g^3}+\left(\alpha^2 -\frac{\alpha}{2}\right)\left( \frac{(g')^2}{ g^{3}}-\frac{g''}{2g^2}\right)\\
&= \left(\alpha^2 - \frac{\alpha}{4} - \frac{\alpha^2}{2} +\frac{\alpha}{4}\right)\frac{g''}{g^2} +\left(\alpha^2 -\frac{\alpha}{2}-\frac{3}{2}\alpha ^2+\frac{\alpha}{2}- \frac{1}{32}\right)\frac{g'^2}{g^3}\\
&=  \frac{\alpha^2}{2}\left(\frac{g''}{g^2}-\frac{g'^2}{g^3}\right) - \frac{1}{32}\frac{g'^2}{g^3}
\end{align}
So we have the following effective potential:
\begin{equation}
\boxed{V_{\text{eff}} = \frac{\hbar}{32}\frac{g'^2}{g^3} -\hbar\frac{\alpha^2}{2}\left(\frac{g''}{g^2}-\frac{g'^2}{g^3}\right) }
\end{equation}
\comment{Agrees with Dan's cases}

\subsection{Propagator}

So pulling all of this together we have 
\begin{align}
K(q_n,t_n; q_0,t_0) = \frac{1}{\sqrt{g(x_0)}}\int \prod_{k=1}^{n-1} dx_k\frac{\sqrt{g_k}}{\sqrt{2\pi i \hbar \Delta T}} \exp\left[ \frac{i}{2\Delta T\hbar}g_{ij}\Delta x^i\Delta x^j +\left(\alpha - \frac{1}{4}\right)\log\left(\frac{g(x_{k+1})}{g(x_k)}\right)-\frac{i}{\hbar}\Delta T [V+V_{\text{eff}}]\right]
\end{align}
Now we can use deal with the log by taking (recall we used this trick for all $\Delta x_k = x_{k+1}-x_k, k=0,1,....n-1$)
\begin{align}
\prod_{k=0}^{n-1}\exp\left[\left(\alpha - \frac{1}{4}\right)\log\left(\frac{g(x_{k+1})}{g(x_k)}\right)\right] & = \exp\left[\left(\alpha - \frac{1}{4}\right)\sum_{k=0}^{n-1}\left(\log[g(x_k)]-\log[g(x_{k+1})]\right)\right]\\
& = \exp\left[\left(\frac{1}{4}-\alpha\right)\log\left(\frac{g(x_{n})}{g(x_0)}\right)\right]\\
& = \left[\frac{g(x_{n})}{g(x_0)}\right]^{ \frac{1}{4}-\alpha}
\end{align}
so we have
\begin{align}
K(q_n,t_n; q_0,t_0) = \left[\frac{g(x_n)}{g(x_0)}\right]^{\frac{1}{4}-\alpha}\frac{1}{\sqrt{g(x_0)}}\int \prod_{k=1}^{n-1} dx_k\frac{\sqrt{g(x_{k,\alpha})}}{\sqrt{2\pi i \hbar \Delta T}} \exp\left[ \frac{i\Delta x^i\Delta x^j}{2\hbar\Delta T}g_{ij}(x_{k,\alpha}) -\frac{i}{\hbar}\Delta T [V+V_{\text{eff}}]\right]
\end{align}
\comment{Agrees with Dan}

\subsection{Operator Orderings DeWitt's results}
DeWitt claims that when setting up the path integral in curved coordinates, you find the relevant differential operator in the schrodinger equation is 
\begin{equation}
H = -g^{-1/2}\partial_i g^{1/2}g^{ij}\partial_j,
\end{equation}
where that is the Laplace-Beltrami operator

Now using 
\begin{equation}
\langle x| p_i |\psi\rangle = -i\hbar g^{-1/4}\partial_i g^{1/4}
\end{equation}
Then we can write 
\begin{align}
H &= g^{-1/2}g^{1/4}(i\hbar g^{-1/4}\partial_i g^{1/4}) g^{-1/4} g^{1/2}g^{ij} g^{1/4}(i\hbar g^{-1/4} \partial_j g^{1/4} g^{-1/4}
&= g^{-1/4}p_i  g^{1/2}g^{ij}p_j g^{-1/4}
\end{align}

Now if we assume 
\begin{equation}
[f(x),p] = i\hbar f'
\end{equation}
we can set about ordering this.  

\subsection{Ito Ordering}

For Ito order we want all $x$ operators to the left of their counterparts.  
\begin{equation}
H = p_ip_j g^{ij}
\end{equation}

So let's start commuting things.  
\begin{align}
H &= g^{-1/4}p_i  g^{1/2}g^{ij}p_j g^{-1/4}\\
% & = \left[ p_i g^{-1/4} + i\hbar\partial_i(g^{-1/4})\right] g^{1/2}g^{ij}p_j g^{-1/4}\\
% & = \left[ p_i g^{-1/4}  -i\frac{\hbar}{4}\frac{\partial_ig}{g^{5/4}}\right]g^{1/2}g^{ij}p_j g^{-1/4}\\
% & =  p_i g^{1/4}g^{ij}p_j g^{-1/4}  -i\frac{\hbar}{4} \frac{\partial_ig}{g^{3/4}}g^{ij}p_j g^{-1/4}\\
% & =  p_i [p_j g^{ij}g^{1/4} + i\hbar\partial_j(g^{1/4}g^{ij})]g^{-1/4}  -ip_j\frac{\hbar}{4} \frac{\partial_ig}{g^{3/4}}g^{ij} g^{-1/4} - \frac{\hbar^2}{4}\partial_j\left( \frac{\partial_ig}{g^{3/4}}g^{ij} \right)g^{-1/4}\\
% & =  p_i p_j g^{ij} + i\hbar p_i\left( \frac{1}{4}\frac{\partial_jg}{g^{3/4}}g^{ij} + g^{1/4}\partial_j g^{ij}\right)g^{-1/4} -ip_j\frac{\hbar}{4} \frac{\partial_ig}{g^{3/4}}g^{ij} g^{-1/4} - \frac{\hbar^2}{4}\partial_j\left( \frac{\partial_ig}{g^{3/4}}g^{ij} \right)g^{-1/4}\\
% & =  p_i p_j g^{ij} + i\hbar p_i \partial_j g^{ij} - \frac{\hbar^2}{4}\left(\frac{g^{ij}}{g^{3/4}}\partial_j\partial_i g - \frac{3}{4}g^{ij}\partial_ig \frac{\partial_jg}{g^{7/4}} + \frac{\partial_i g}{g^{3/4}}\partial_jg^{ij} \right)g^{-1/4}\\
& =  p_i p_j g^{ij} + i\hbar p_i \partial_j g^{ij} - \frac{\hbar^2}{4}\left(g^{ij}\frac{\partial_j\partial_i g}{g} - \frac{3}{4}g^{ij}\frac{\partial_ig \partial_jg}{g^{2}} + \frac{\partial_i g}{g}\partial_jg^{ij} \right)
\end{align}
Let's now consider 1D, where $g^{ij} = 1/g, \det{g^{ij}} = g, g_{ij} = g$.  We then have 
\begin{align}
H & =  p^2g - i\hbar p \frac{g'}{g^2} - \frac{\hbar^2}{4}\left(\frac{g''}{g^2} - \frac{3}{4}\frac{(g')^2}{g^{3}} - \frac{(g')^2}{g^3} \right)
\end{align}

\subsubsection{One Dimension}

So let's start commuting things.  
\begin{align}
H &= g^{-1/4}p  g^{-1/2}p g^{-1/4}\\
% & = \left[ p g^{-1/4} + i\hbar(g^{-1/4})'\right] g^{-1/2}p_j g^{-1/4}\\
% & = \left[ p g^{-1/4}  -i\frac{\hbar}{4}\frac{g'}{g^{5/4}}\right]g^{-1/2}p g^{-1/4}\\
% & =  p g^{-3/4}p g^{-1/4}  -i\frac{\hbar}{4} \frac{g'}{g^{7/4}}p g^{-1/4}\\
% & =  p(p g^{-1} - i\hbar \frac{3}{4}\frac{g'}{g^{2}})  -i\frac{\hbar}{4}p \frac{g'}{g^{2}} +\frac{\hbar^2}{4}\left(\frac{g''}{g^{7/4}}- \frac{7(g')^2}{4g^{11/4}}\right)'g^{-1/4}\\
% & =  p\left(p g^{-1} - i\hbar \frac{3}{4}\frac{g'}{g^{2}}\right)  -i\frac{\hbar}{4}p \frac{g'}{g^{2}} +\frac{\hbar^2}{4}\left(\frac{g''}{g^{2}}- \frac{7(g')^2}{4g^{3}}\right)\\
& =  p^2 g^{-1} - i\hbar p\frac{g'}{g^{2}}  +\frac{\hbar^2}{4}\left(\frac{g''}{g^{2}}- \frac{7(g')^2}{4g^{3}}\right)
\end{align}

On constructing the path integral we then have to evaluate 
\begin{align}
\langle x_f| e^{-i\frac{H}{\hbar}t} |x_i\rangle =& g^{-1/4}(x_f)g^{-1/4}(x_i)\int\prod_k \frac{dx_k dp_k}{2\pi\hbar}\, e^{\frac{i}{\hbar}p_k(x_{k+1}-x_k)}\nonumber\\
&\times\exp\left[ -\frac{i}{2\hbar}\Delta t\left(  p^2g^{-1} - i\hbar p g^{-1}\partial_x \ln g  +\frac{\hbar^2}{4}\left(\frac{g''}{g^{2}}- \frac{7(g')^2}{4g^{3}}\right)\right)\right]
\end{align}

Complete the square in the momentum
\begin{equation}
-\frac{i\Delta T}{2\hbar}\left(\frac{p^2}{g} - i\hbar p\frac{g'}{g^2}  -2p_k\frac{(x_{k+1}-x_k)}{\Delta T} \right) = -\frac{i\Delta T}{2\hbar g}\left(p - g\frac{x_{k+1}-x_k}{\Delta T} - i\hbar \frac{g'}{2g}\right) +\frac{i\Delta T}{2\hbar g}\left(g\frac{x_{k+1}-x_k}{\Delta T} + i\hbar\frac{g'}{2g}\right)^2
\end{equation}
Let's now expand out that quadratic term, and use dan's log trick.  
\begin{align}
\langle x_f| e^{-i\frac{H}{\hbar}t} |x_i\rangle =& g_f^{-1/4}g_i^{-1/4}\int\prod_k dx_k\sqrt{\frac{g}{2\pi i\hbar\Delta T}}
\exp\left[\frac{i\Delta T g }{2\hbar }\left(\frac{x_{k+1}-x_k}{\Delta T} + i\hbar\frac{g'}{2g^2}\right)^2 -\frac{i\hbar\Delta T}{8} \left(\frac{g''}{g^{2}}- \frac{7(g')^2}{4g^{3}}\right)\right]\\
% =& g_f^{-1/4}g_i^{-1/4}\int\prod_k dx_k\sqrt{\frac{g}{2\pi i\hbar\Delta T}}
% \exp\left[\frac{ig (x_{k+1}-x_k)^2}{2\hbar\Delta T } -\frac{i g}{2}(x_{k+1}-x_k)\frac{g'}{g^2}\right]\nonumber\\
% &\times\exp\left[ -\frac{i\hbar\Delta T g}{8}\frac{(g')^2}{g^4} -\frac{i\hbar\Delta T}{8} \left(\frac{g''}{g^{2}}- \frac{7(g')^2}{4g^{3}}\right)\right]\\
=& g_f^{-1/4}g_i^{-1/4}\int\prod_k dx_k\sqrt{\frac{g}{2\pi i\hbar\Delta T}}
\exp\left[\frac{ig (x_{k+1}-x_k)^2}{2\hbar\Delta T } -(x_{k+1}-x_k)\frac{g'}{2g}\right]\nonumber\\
&\times\exp\left[ -\frac{i\hbar\Delta T}{8} \left(\frac{g''}{g^{2}}- \frac{3(g')^2}{4g^{3}}\right)\right]
\end{align}

Now we can use 
\begin{equation}
\frac{g'}{g}\Delta x = \log\left[\frac{g(x_{k+1})}{g(x_k)}\right]  -\frac{1}{2}\Delta x^2\left(\frac{g''}{g} -\frac{(g')^2}{g^2}\right) = \log\left[\frac{g(x_{k+1})}{g(x_k)}\right]  -\frac{i\hbar\Delta T}{2}\left(\frac{g''}{g^2} -\frac{(g')^2}{g^3}\right)
\end{equation}
The propagator is 
\begin{align}
\langle x_f| e^{-i\frac{H}{\hbar}t} |x_i\rangle =& g_f^{-1/4}g_i^{-1/4}\int\prod_k dx_k\sqrt{\frac{g}{2\pi i\hbar\Delta T}}
\exp\left[\frac{ig (x_{k+1}-x_k)^2}{2\hbar\Delta T } -\frac{1}{2}\log\left[\frac{g(x_{k+1})}{g(x_k)}\right] \right]\nonumber\\
&\times\exp\left[ \frac{i\hbar\Delta T}{4}\left(\frac{g''}{g^2} -\frac{(g')^2}{g^3}\right) -\frac{i\hbar\Delta T}{8} \left(\frac{g''}{g^{2}}- \frac{3(g')^2}{4g^{3}}\right)\right]\\
=& g_f^{-3/4}g_i^{1/4}\int\prod_k dx_k\sqrt{\frac{g}{2\pi i\hbar\Delta T}}
\exp\left[\frac{ig (x_{k+1}-x_k)^2}{2\hbar\Delta T }+ \frac{i\hbar\Delta T}{8}\left(\frac{g''}{g^2} -\frac{(g')^2}{g^3}\right) -\frac{i\hbar\Delta T}{32}\frac{(g')^2}{g^3}\right],
\end{align}
which agrees with the transformed path integral picture.  


\section{Dielectric as  a Metric}


How about we force that differential operator into Laplace-Beltrami form
\begin{align}
H(x) &= -\frac{1}{\sqrt{\epsilon}}\nabla^2\frac{1}{\sqrt{\epsilon}} \\
&= -\frac{1}{\sqrt{\epsilon}}\partial_x\left[\frac{1}{\sqrt{\epsilon}}\partial_x  + \left(\partial_x\frac{1 }{\sqrt{\epsilon} }\right)\right] 
\end{align}
Let's now try to put this in operator form, using $p = -ig^{-1/4}\partial_x g^{1/4}$.   Let us also choose $g = \epsilon$.
\begin{align}
H(x)&= -\frac{1}{\sqrt{g}}ig^{1/4}pg^{-1/4}\left[\frac{1}{\sqrt{g}}ig^{1/4}p g^{-1/4}  -i\left[\frac{1}{\sqrt{g}},p\right]\right]\\
%&= g^{-1/4}pg^{-1/2}p g^{-1/4}  -g^{-1/4}pg^{-1/4}\left[\frac{1}{\sqrt{g}},p\right]\\
&= g^{-1/4}p^2g^{-3/4}
\end{align}

Intriguingly, the coordinate transform viewpoint says:
\begin{align}
\Delta_{LB} =& \frac{1}{\sqrt{g}}\partial_x \frac{1}{\sqrt{g}}\partial_x\\
=& \frac{\partial x}{\partial q}\partial_x \frac{\partial x}{\partial q}\partial_x\\
=& \partial_q^2
\end{align}
where $\sqrt{g} = \frac{\partial q}{\partial x}$, if $q$ are the initial flat coordinates.  In which case, Dan's claim that the Laplace-Beltrami operator is ``trivial'' stands quite readily.  
So if we take $\sqrt{g} = \sqrt{\epsilon}$ this says that lengths are increased by $\sqrt{\epsilon(x)} = n(x)$ in this space.   The coordinate transformation would have to be $q(x) = \int_{x_0}^x dx' \sqrt{\epsilon(x')}$.(\comment{where $q$ are the initial flat coordinates})


Let's now try to develop this as a path integral.  
\subsection{Ito ordering}
If we Ito order we have
\begin{align}
H =& p^2 g^{-1} + [g^{-1/4},p^2]g^{-3/4}\\
% =& p^2 g^{-1} -i\frac{1}{4}(g^{-5/4}g'p + p g^{-5/4}g')g^{-3/4}\\
% =& p^2 g^{-1} -\frac{i}{4}pg^{-2}g' -\frac{i}{4}[g^{-5/4}g',p]g^{-3/4}-\frac{i}{4} p g^{-2}g'\\
=& p^2 g^{-1} -\frac{i}{2}pg^{-2}g' +\frac{1}{4}\left(-\frac{5}{4}g^{-3}g'^2 + g^{-2}g''\right)
\end{align}

We then have a path integral
\begin{align}
\Tr[e^{-HT}] =& \int \prod_{k=1}^N\frac{dx_k dp_k}{2\pi}\, \exp\left\{ -\left[\frac{p_k^2}{g} -\frac{i}{2}p\frac{g'}{g^2}+\frac{1}{4}\left(-\frac{5g'^2}{4g^{3}}+ \frac{g''}{g^2}\right)\right]\Delta T+ip_k(x_{k+1}-x_k)  \right\}\\
% =& \int \prod_{k=1}^N\frac{dx_k dp_k}{2\pi}\, \exp\left[ -\frac{\Delta T}{g}p_k^2 +ip_k\left(x_{k+1}-x_k\frac{g'}{2g^2}\Delta T\right) - \frac{\Delta T}{4}\left(-\frac{5g'^2}{4g^{3}}+ \frac{g''}{g^2}\right) \right]\\
% =& \int \prod_{k=1}^Ndx_k \sqrt{\frac{g_k}{4\pi \Delta T}}\, \exp\left[ -\frac{g}{4\Delta T}\left(x_{k+1}-x_k\frac{g'}{2g^2}\Delta T\right)^2 + \frac{\Delta T}{4}\left(\frac{5g'^2}{4g^{3}}- \frac{g''}{g^2}\right) \right]\\
% =&  \int\prod_{k=1}^Ndx_k \sqrt{\frac{g_k}{4\pi \Delta T}}\, \exp\left[ -\frac{g(x_{k+1}-x_k)^2}{4\Delta T} + (x_{k+1}-x_k)\frac{g'}{4g} - \frac{g'^2}{4g^3}\Delta T+ \frac{\Delta T}{4}\left(\frac{5g'^2}{4g^{3}}- \frac{g''}{g^2}\right) \right]\\
=&  \int\prod_{k=1}^Ndx_k \sqrt{\frac{g_k}{4\pi \Delta T}}\, \exp\left[ -\frac{g(x_{k+1}-x_k)^2}{4\Delta T} + (x_{k+1}-x_k)\frac{g'}{4g} + \frac{\Delta T}{4}\left(\frac{g'^2}{4g^{3}}- \frac{g''}{g^2}\right) \right]
\end{align}

Now we write the linear velocity term as a logarithm using
\begin{equation}
\frac{g'}{g}\Delta x = \log\left[\frac{g(x_{k+1})}{g(x_k)}\right]  -\frac{1}{2}\Delta x^2\left(\frac{g''}{g} -\frac{(g')^2}{g^2}\right) = \log\left[\frac{g(x_{k+1})}{g(x_k)}\right]  +\frac{\Delta T}{g}\left(\frac{g''}{g^2} -\frac{(g')^2}{g^3}\right),
\end{equation}
where we used $\langle\langle \Delta x^2\rangle\rangle = 2\Delta T g^{-1}$.  

The path integral is now
\begin{align}
\tr[e^{-HT}]=&  \int\prod_{k=1}^Ndx_k \sqrt{\frac{g_k}{4\pi \Delta T}}\, \exp\left\{ -\frac{g(x_{k+1}-x_k)^2}{4\Delta T} + \frac{1}{4}\log\left[\frac{g(x_{k+1})}{g(x_k)}\right] \right\} \nonumber\\
&\times \exp\left[\frac{\Delta T}{4g}\left(\frac{g''}{g^2} -\frac{(g')^2}{g^3}\right) + \frac{\Delta T}{4}\left(\frac{g'^2}{4g^{3}}- \frac{g''}{g^2}\right) \right]\\
=&  \int\prod_{k=1}^Ndx_k \sqrt{\frac{g_k}{4\pi \Delta T}}\, \exp\left\{ -\frac{g(x_{k+1}-x_k)^2}{4\Delta T} + \frac{1}{4}\log\left[\frac{g(x_{k+1})}{g(x_k)}\right]-\frac{3\Delta T}{4g}\frac{(g')^2}{g^3} \right\}
\end{align}
Now since we have a loop integral, the log does yields 
\begin{equation}
\prod_{k=0}^{N-1} \log\left[ \frac{g(x_{k+1})}{g(x_k)}\right] = \log\left[ \frac{g(x_{N})}{g(x_0)}\right] = 0
\end{equation}

So we get the Ito ordered path integral
\begin{equation}
\boxed{\tr[e^{-g^{-1/4}p^2g^{-3/4}T}]=  \int\prod_{k=1}^Ndx_k \sqrt{\frac{g_k}{4\pi \Delta T}}\, \exp\left[ -\frac{g(x_{k+1}-x_k)^2}{4\Delta T}-\frac{3\Delta T}{4g}\frac{(g')^2}{g^3} \right]}\label{eq:Ito_PI_metric}
\end{equation}

\subsection{Weyl Ordered Path Integral}

Let's set about Weyl ordering that Hamiltonian.  
\subsubsection{Various permutations of operators}

We will need the anti-standard order expression
\begin{equation}
H = p^2 g^{-1} -\frac{i}{2}pg^{-2}g' +\frac{1}{4}\left(-\frac{5}{4}g^{-3}g'^2 + g^{-2}g''\right).
\end{equation}

In addition we need the corresponding expression in standard order
\begin{align}
H =& g^{-1/4}p^2g^{-3/4}\\
% =& g^{-1}p^2 + g^{-1/4}[p^2,g^{-3/4}]\\
% =& g^{-1}p^2 +\frac{3i}{4}g^{-1/4}\left(pg'g^{-7/4} + g'g^{-7/4}p\right)\\
% =& g^{-1}p^2 +\frac{3i}{2} \frac{g'}{g^2}p  + \frac{3i}{4}g^{-1/4}[p,g'g^{-7/4}]\\
=& g^{-1}p^2 +\frac{3i}{2} \frac{g'}{g^2}p  + \frac{3}{4}\left( \frac{g''}{g^2} -\frac{7g'^2}{4g^3}\right)
\end{align}

And finally, $g$ in the middle.  
\begin{align}
H =& g^{-1/4}p^2g^{-3/4}\\
% =& \left(pg^{-1/4}+ [g^{-1/4},p]\right)\left( g^{-3/4}p  + [p,g^{-3/4}]\right)\\
% =& \left(pg^{-1/4}-\frac{i}{4}g'g^{-5/4}\right)\left( g^{-3/4}p  +i\frac{3}{4}g'g^{-7/4}\right)\\
=& pg^{-1}p -\frac{i}{4}g'g^{-2}p  +i\frac{3}{4}pg'g^{-2} + \frac{3}{16}\frac{g'^2}{g^3}
\end{align}


So we have 
\begin{align}
H =& [pg^{-1}p]_W + \frac{1}{4}\left[ -\frac{i}{2}p\frac{g'}{g^{2}} +\frac{1}{4}\left(\frac{g''}{g^2}-\frac{5g'^2}{4g^3}\right) +\frac{3i}{2} \frac{g'}{g^2}p  + \frac{3}{4}\left( \frac{g''}{g^2} -\frac{7g'^2}{4g^3}\right) -\frac{i}{2}g'g^{-2}p  +i\frac{3}{2}pg'g^{-2} + \frac{3}{8}\frac{g'^2}{g^3}\right]\\
%=& [pg^{-1}p]_W + \frac{1}{4}\left[ ip\frac{g'}{g^2} +i\frac{g'}{g^2}p +\frac{g''}{g^2}-\frac{5g'^2}{4g^3}\right]\\
=& [pg^{-1}p]_W + \frac{i}{2}\left[p\frac{g'}{g^2}\right]_W +\frac{1}{4}\left(\frac{g''}{g^2}-\frac{5g'^2}{4g^3}\right)
\end{align}
So we get a velocity in this case, due to the asymmetry of the operators.  

Using the midpoint rule for  Weyl ordered operators, we then can form the path integral as 
\begin{align}
\tr[e^{-HT}_W] =& \int \prod_k \frac{dx_kdp_k}{2\pi}\exp\left[-\left(p^2\bar{g}^{-1} + \frac{i}{2}\left[p\frac{\bar{g}'}{\bar{g}^2}\right]_W +\frac{1}{4}\left(\frac{g''}{g^2}-\frac{5g'^2}{4g^3}\right)\right)\Delta T + ip_k(x_{k+1}-x_k)\right]\\
% =& \int \prod_k \frac{dx_kdp_k}{2\pi}\exp\left[-p^2\bar{g}^{-1}\Delta T - ip_k\left(x_{k+1}-x_k-\frac{\bar{g}'}{2\bar{g}^2}\Delta T\right) -\frac{\Delta T}{4}\left(\frac{g''}{g^2}-\frac{5g'^2}{4g^3}\right) \right]\\
% =& \int \prod_k dx_k\sqrt{\frac{\bar{g}}{4\pi\Delta T}}\exp\left[-\frac{\bar{g}}{4\Delta T}\left(x_{k+1}-x_k-\frac{\bar{g}'}{2\bar{g}^2}\Delta T\right)^2 -\frac{\Delta T}{4}\left(\frac{g''}{g^2}-\frac{5g'^2}{4g^3}\right) \right]\\
% =& \int \prod_k dx_k\sqrt{\frac{\bar{g}}{4\pi\Delta T}}\exp\left[-\frac{\bar{g}(x_{k+1}-x_k)^2}{4\Delta T} +(x_{k+1}-x_k)\frac{\bar{g}'}{4\bar{g}} -\frac{\bar{g}'^2}{16 g^3}\Delta T  -\frac{\Delta T}{4}\left(\frac{g''}{g^2}-\frac{5g'^2}{4g^3}\right) \right]\\
=& \int \prod_k dx_k\sqrt{\frac{\bar{g}}{4\pi\Delta T}}\exp\left[-\frac{\bar{g}(x_{k+1}-x_k)^2}{4\Delta T} +(x_{k+1}-x_k)\frac{\bar{g}'}{4\bar{g}}  -\frac{\Delta T}{4}\left(\frac{g''}{g^2}-\frac{g'^2}{g^3}\right) \right]
\end{align}

So now we need to carry out the log expansion for $\alpha=0$.  Fortunately, to order $\Delta T$ we have 
\begin{equation}
\log\left[\frac{g(x_{k+1})}{g(x_k)}\right] = \frac{\bar{g}'}{\bar{g}}(x_{k+1}-x_k)
\end{equation}
So we have no corrections to the potential from eliminating the velocity, since the log drops out for a trace.  
\begin{equation}
\boxed{\tr[e^{-HT}]_W= \int \prod_k dx_k\sqrt{\frac{\bar{g}}{4\pi\Delta T}}\exp\left[-\frac{\bar{g}(x_{k+1}-x_k)^2}{4\Delta T}   -\frac{\Delta T}{4}\left(\frac{g''}{g^2}-\frac{g'^2}{g^3}\right) \right]}
\end{equation}


\section{Dielectric as in flat space}
\subsection{Ito ordering}


Let's consider trying to find
\begin{equation}
E = \int \frac{dT}{T\sqrt{4\pi T}}  \tr e^{-\sigma p^2\sigma T}
\end{equation}

We will choose to adopt anti-standard order(this gives an Ito calculus).
\begin{align}
\sigma p^2\sigma   %= (p\sigma + i\sigma')p\sigma \\
& = p\sigma p\sigma + i\sigma' p \sigma\\
%& = p(p\sigma + i\sigma')\sigma + i(p\sigma' + i \sigma'') \sigma\\
& = p^2\sigma^2 + 2ip\sigma'\sigma- \sigma''\sigma
\end{align}


\subsection{Configuration Space}

We can carry out the momentum integrals, which gives us 
\begin{align}
\tr e^{-\sigma p^2\sigma T} &= \int dx_k dp_k \delta(x_N-x_0)e^{-\frac{\Delta T}{2} p_k^2\sigma^2_{k} - ip(\sigma'\sigma \Delta T) + \frac{\Delta T}{2}\sigma''\sigma+ i p_k(x_{k+1}-x_{k})}\\
&= \int dx_k \delta(x_N-x_0)\frac{1}{\sqrt{4\pi \Delta T\sigma^2_{k}}} e^{-\frac{[x_{k+1}-x_{k}-(\sigma'\sigma)_{k}\Delta T]^2}{2\Delta T\sigma^2_{k}}  + \frac{1}{2}\Delta T(\sigma''\sigma)_{k}}\\
&= \int dx_k \delta(x_N-x_0)\frac{1}{\sqrt{4\pi \Delta T\sigma^2_{k}}} e^{-\frac{(x_{k+1}-x_{k})^2}{2\sigma^2_{k}\Delta T}  +(x_{k+1}-x_k)\frac{\sigma'}{\sigma}   + \frac{1}{2}\Delta T(\sigma''\sigma - \sigma'^2)_{k}}.
\end{align}

We will now explicitly deal with the linear velocity term.  This will produce a normalization constant.   
We can then expand a logarithm as 
\begin{align}
\log\left[\frac{\sigma(x_{k+1})}{\sigma(x_k)}\right] =& \log\left[  1 + \Delta x \frac{\sigma'}{\sigma}  + \frac{1}{2}\Delta x^2\frac{\sigma''}{\sigma}\right]= \Delta x\frac{\sigma'}{\sigma} + \frac{1}{2}\Delta x^2\left(\frac{\sigma''}{\sigma} - \frac{\sigma'^2}{\sigma^2}\right)
\end{align}
If we use this log substitution immediately inside the exponential, we get
\begin{equation}
\exp\left[\Delta x\frac{\sigma'}{\sigma}\right] = \exp\left[\log\left[\frac{\sigma(x_{k+1})}{\sigma(x_k)}\right] - \frac{1}{2}\sigma^2\Delta T\left(\frac{\sigma''}{\sigma} - \frac{\sigma'^2}{\sigma^2}\right)\right],
\end{equation}
which would cancel out the potential.  

We will also need
\begin{equation}
\prod_{k=0}^{N-1} \exp\left[\log\left(\frac{\sigma(x_{k+1})}{\sigma(x_k)}\right)\right] =  \exp\left[\prod_{k=0}^{N-1}\log\left(\frac{\sigma(x_{k+1})}{\sigma(x_k)}\right)\right] = \frac{\sigma(x_N)}{\sigma(x_0)} = 1,
\end{equation}
where we employed $x_N = x_0$.  

Then we just have 
\begin{equation}
Z= \int dx_k \delta(x_N-x_0)\frac{1}{\sqrt{4\pi \Delta T\sigma^2(x_{k})}} e^{-\frac{(x_{k+1}-x_{k})^2}{2\sigma^2(x_k)\Delta T}}.
\end{equation}


\section{Putting into Numerical form-Ito$g$} 

So let's put a bit of thought into how to handle 
\begin{equation}
Z = \int \prod_{k=1}^{N-1}dx_k \frac{\sqrt{g_k}}{\sqrt{2\pi\Delta T}} \exp\left[- \frac{g(x_k)(x_{k+1}-x_k)^2}{2\Delta T}\right]
\end{equation}

\subsection{Transforming to a Gaussian}
We can transform variable from positions $x_k$ to increments
\begin{equation}
u_k = x_{k+1} - x_k, k = 0,N-1,
\end{equation}
with
\begin{equation}
x_{k} = \sum_{j=0}^{k-1} u_j.
\end{equation}
This transformation has unit Jacobian.  
\begin{equation}
Z= \int du_k \delta\left(\sum u_k \right)\sqrt{\frac{g[x_k(u)]}{2\pi \Delta T}} e^{-\frac{g[x(u)]u_k^2}{2\Delta T}}.
\end{equation}

Let's now try to decouple the random variables.  Let us introduce 
\begin{equation}
dW_k = \sqrt{g_k}u_k
\end{equation}

We will need to calculate a Jacobian, and a euclidean norm of gradients.  In both cases we will need $\frac{\partial u_k}{\partial dW_j}$.  
So we can iteratively define the increments from the Gaussians as 
\begin{equation}
u_k = \frac{1}{\sqrt{g_k[x_k(u_{j<k})]}}dW_k.
\end{equation}

We then have 
\begin{align}
\frac{\partial u_j}{\partial dW_k} &= \frac{\partial}{\partial dW_k}\frac{1}{\sqrt{g_j[(u_{i<j})]}}dW_j\\
&= \frac{1}{\sqrt{g_j}}\delta_{jk} -\frac{g_j'}{2g^{3/2}_j}dW_j\sum_{i<j}\frac{d u_i}{dW_k}.
\end{align}
So we start at $j,k=0$.  We can solve this laboriously, or quite quickly by starting the recursion at zero.  
We have 
\begin{gather}
\frac{\partial u_0}{\partial dW_0} = \frac{1}{\sqrt{g_0}}, \quad \frac{\partial u_0}{\partial dW_{j>0}} = 0
\end{gather}
Similarly the second increment is 
\begin{align}
\frac{\partial u_1}{\partial dW_0}& = -\frac{1}{\sqrt{g_0}}\frac{g'_1}{2g_1^{3/2}}dW_1, \quad \frac{\partial u_1}{\partial dW_1} = \frac{1}{\sqrt{g_1}} ,\quad \frac{\partial u_1}{\partial dW_{j>1}} = 0.
\end{align}
The third increment is 
\begin{align}
\frac{\partial u_2}{\partial dW_0}& = -\frac{g'_2}{2g_2^{3/2}}dW_2\left(1-\frac{g'_1}{2g_1^{3/2}}dW_1\right)\frac{1}{\sqrt{g_0}}\, \quad \frac{\partial u_2}{\partial dW_1} = -\frac{1}{\sqrt{g_1}}\frac{g'_2}{2g_2^{3/2}}dW_2, \quad \frac{\partial u_2}{\partial dW_2} = \frac{1}{\sqrt{g_2}}, \quad \frac{\partial u_2}{\partial dW_{j>2}} = 0.
\end{align}

For the diagonal, we just get $g_k^{-1/2}$. 
So if we're off the diagonal we multiply by $g_j' dW_j$ for the current row $j$, and sum up all of the preceding entries in this column.   

This is enough to infer the pattern
\begin{align}
&\frac{\partial u_j}{\partial dW_k} \nonumber\\
=& \left( 
\begin{array}{lllllll}
\frac{1}{\sqrt{g_0}}      & 0     &   \\
-\frac{1}{\sqrt{g_0}}dW_1\frac{g'_{1}}{2g^{3/2}_1}    & \frac{1}{\sqrt{g_1}}     & 0 \\
-\frac{1}{\sqrt{g_0}}\left(1-\frac{g'_{1}}{2g^{3/2}_1}dW_1\right)\frac{g'_{2}}{2g^{3/2}_2}dW_2 & -\frac{1}{\sqrt{g_1}}\frac{g'_{2}}{2g^{3/2}_2}dW_2    & \frac{1}{\sqrt{g_2}}   & 0 & 0 \\
-\frac{1}{\sqrt{g_0}}\left(1-\frac{g'_{1}}{2g^{3/2}_1}dW_1\right)\left(1-\frac{g'_{2}}{2g^{3/2}_2}dW_2\right)\frac{g'_{3}}{2g^{3/2}_3}dW_3 &  -\frac{1}{\sqrt{g_1}}(1-\frac{g'_{2}}{2g^{3/2}_2}dW_2)\frac{g'_{3}}{2g^{3/2}_3}dW_3     &  -\frac{1}{\sqrt{g_2}}\frac{g'_{3}}{2g^{3/2}_3}dW_3 &\frac{1}{\sqrt{g_3}} & 0 \\
\vdots & & & \ddots
\end{array}
\right)
\end{align}
Evidently a generic term off the diagonal will have components (row is $u_j$, column is $dW_k$ increment)
\begin{equation}
\boxed{\frac{\partial u_j}{\partial dW_k} =
 \frac{1}{\sqrt{g_k}}\delta_{jk} - \frac{1}{\sqrt{g_k}}\frac{g'_j}{2g^{3/2}_j}dW_j\delta_{j,k+1}
 - \frac{1}{\sqrt{g_k}}\frac{g'_j}{2g^{3/2}_j}dW_j\prod_{m=k+1}^{j-1} \left(1- \frac{g'_m}{2g^{3/2}_m}dW_m\right)\Theta(j\ge k+2),}
\end{equation}
with $j,k=0,1,\ldots N-1$. If we further define $dW_k = \sqrt{\Delta T}z_k$, then we should multiply this by $\sqrt{\Delta T}$.  

\subsection{Jacobian}

The first place we need this result is in calculating the jacobian:
\begin{equation}
\left|\frac{\partial u_j}{\partial dz_k}\right| = \prod_{k=0}^{N-1}\frac{\sqrt{\Delta T}}{\sqrt{g_k}},
\end{equation}
which follows because the matrix is in lower-triangular form.
  The Jacobian from changing from positions to increments is also lower-triangular, and just gives unit determinant.
  This factor will eat all of the prefactor normalizations.  

\subsection{Euclidean norm of gradient}

Next up we need to calculate the change in the normalization when constrained to loops that close.
  The loop must close, or the increments sum to zero.
   Our constraint is 
\begin{align}
  h(d\vect{W}) = x_n-x_0 = \sum_{j=0}^{N-1} u_j = \sum_{j=0}^{N-1}u_j\left[\sum_{k<j} u_k[dW] \right]=0
\end{align}
The Euclidean norm of the gradient is defined as 
\begin{align}
\|\nabla_{\vect{z}}h(\vect{z})\|^2 = &  \Delta T \|\nabla_{d\vect{W}}h(d\vect{W})\|^2\\
 = & \Delta T \sum_{k=0}^{N-1} \left(\sum_{j=0}^{N-1} \frac{\partial u_j}{\partial dW_k} \right)^2\\
 = & \Delta T \sum_{k=0}^{N-1} \left(\sum_{j=0}^{N-1}\frac{1}{\sqrt{g_k}}\delta_{jk} - \frac{1}{\sqrt{g_k}}\frac{g'_j}{2g^{3/2}_j}dW_j\delta_{j,k+1} \right. \nonumber\\
&\left.\qquad - \frac{1}{\sqrt{g_k}}\frac{g'_j}{2g^{3/2}_j}dW_j\prod_{m=k+1}^{j-1} \left(1- \frac{g'_m}{2g^{3/2}_m}dW_m\right)\Theta(j\ge k+2)\right)^2\\
 = & \Delta T  \sum_{k=0}^{N-1}\left[\frac{1}{\sqrt{g_k}} - \frac{1}{\sqrt{g_k}}\frac{g'_{k+1}}{2g^{3/2}_{k+1}}dW_{k+1} - \sum_{j=k+2}^{N-1}\frac{1}{\sqrt{g_k}}\frac{g'_j}{2g^{3/2}_j}dW_j\prod_{m=k+1}^{j-1} \left(1- \frac{g'_m}{2g^{3/2}_m}dW_m\right)\right]^2\\
 = & \Delta T  \sum_{k=0}^{N-1}\frac{1}{g_k}\left[1 - \frac{g'_{k+1}}{2g^{3/2}_{k+1}}dW_{k+1} - \sum_{j=k+2}^{N-1}\frac{g'_j}{2g^{3/2}_j}dW_j\prod_{m=k+1}^{j-1} \left(1- \frac{g'_m}{2g^{3/2}_m}dW_m\right)\right]^2
\end{align}
where we carried out the sum over $j$.    Now we have to start guessing a bit - using some inspiration to approximate this thing.  
It turns out that we can simplify the bracketered term.  We have a sum like: 
\begin{align}
1- f_{k+1}  - \sum_{j={k+2}}^{N-1} f_j\prod_{m=k+1}^{j-1}(1-f_m) =& 1 - f_{k+1}  - f_{k+2}(1-f_{k+1}) - f_{k+3}(1-f_{k+2})(1-f_{k+1}) + \ldots\\
=& (1-f_{k+2})(1-f_{k+1}) - f_{k+3}(1-f_{k+2})(1-f_{k+1}) + \ldots \\
=& \prod_{j=k+1}^{N-1}(1-f_j)
\end{align}
So our complicated factor is just an exponential.  
So we get 
\begin{equation}
{\|\nabla_{\vect{z}}h(\vect{z})\|^2 = 
  \Delta T \sum_{k=0}^{N-1}\frac{1}{g_k}\exp\left[
    -\sum_{j=k+1}^{N-1}\frac{g_j'}{2g_j^{3/2}}dW_j - \Delta T\frac{g_j'^2}{8g_j^3}\right]^2}
\end{equation}
Now we can use the logarithmic expansion to rewrite the Wiener increment term
\begin{align}
d\log\left[g\right]=& \frac{g'}{g}dx +\frac{1}{2}\left(\frac{g''}{g} -\frac{g'^2}{g^2}\right)dx^2   \\ 
=& \frac{g'}{g^{3/2}} dW +\frac{1}{2}\left(\frac{g''}{g^2} -\frac{g'^2}{g^3}\right)dT,
\end{align}
to write 
 \begin{align}
 \|\nabla_{\vect{z}}h(\vect{z})\|^2 = & \Delta T  \sum_{k=0}^{N-1}\frac{1}{g_k}
 \exp\left[\sum_{j=k+1}^{N-1}-\frac{1}{2}\log\frac{g_{j+1}}{g_j}+\frac{\Delta T}{4}\left(\frac{g''}{g^2}
  -\frac{g'^2}{g^3}\right) - \Delta T\frac{g_j'^2}{8g_j^3}\right]^2\\
  = & \Delta T  \sum_{k=0}^{N-1}\frac{1}{g_k}\exp\left[\log\frac{g_{k+1}}{g_{N}}
  +\frac{\Delta T}{2}\sum_{j=k+1}^{N-1}\left(\frac{g''}{g^2}-\frac{3g'^2}{2g^3}\right)\right]
\\
= & \Delta T  \sum_{k=0}^{N-1}\frac{g_{k+1}}{g_k}\frac{1}{g_N}\exp\left[
\frac{\Delta T}{2}\sum_{j=k+1}^{N-1}\left(\frac{g''}{g^2} -\frac{3g'^2}{2g^3}\right)\right]
 \end{align}
Now we can use the fact that the trace is invariant under cyclic permutations to write, $g_N$ as a loop average.
  This follows since we cyclically permute all labels.
  However, I think the integration over partial times will remain.  
Can we drop the ``small'' terms?

In continuum language we have
\begin{equation}
\|\nabla_{\vect{z}}h(\vect{z})\|^2 =\int_0^T dt\, \frac{g(t+dt)}{g(t)}\frac{1}{g(T)} \exp\left[\int_t^Tds\left(\frac{g''}{2g^2} -\frac{3g'^2}{4g^3}\right)\right]
\end{equation}
I think we can then argue that $g(t+dt)/g(t)\sim 1 + \order(N^{-1/2})$, and we can drop the correction at this point.  We can also write $g(T)$ as a sum over all permutations, since this is just a label.  

So at the end of the day we get:
\begin{equation}
Z = \frac{1}{\sqrt{2\pi T}} \bigg<\bigg< e^{-\int dt V}[\langle g^{-1}\rangle_{\text{loop}}]^{-1/2}\left[\frac{1}{T}\int dt \exp\left(\frac{g''}{2g^2} -\frac{3g'^2}{4g^3}\right)\right]^{-1/2}\bigg>\bigg>
\end{equation}

If we use the cyclic permutation argument we can rewrite that extra exponential.  We can also pull in the other potential to write this as:
\begin{equation}
Z = \frac{1}{\sqrt{2\pi T}}\bigg<\bigg< [\langle \sigma^2\rangle_{\text{loop}}]^{-1/2}\left[\frac{1}{T}\int_0^T dt \exp\left(-\int_{0}^tds \sigma''(s) \sigma(s) + \int_0^T dt\, 2V(t)\right)\right]^{-1/2}\bigg>\bigg>
\end{equation}

From our work above: if we use the metric form of the partition function in Eq.~(\ref{eq:Ito_PI_metric}), we have 
\begin{equation}
V = \frac{3}{8}\frac{g'^2}{g^3},
\end{equation}
where we took $g\rightarrow 2g$ to get from the earlier work creating the path integral to the current convention.  
So the partition function is 
\begin{align}
Z =& \frac{1}{\sqrt{2\pi T}}\bigg<\bigg< [\langle g^{-1}\rangle_{\text{loop}}]^{-1/2}\left[\frac{1}{T}\int_0^T dt \exp\left(\int_{0}^tds \frac{g''}{2g^2}-\frac{3g'^2}{4g^3} + \int_0^T dt\, \frac{3 g'^2}{4g^3}\right)\right]^{-1/2}\bigg>\bigg>\\
=& \frac{1}{\sqrt{2\pi T}}\bigg<\bigg< [\langle g^{-1}\rangle_{\text{loop}}]^{-1/2}\left[\frac{1}{T}\int_0^T dt \exp\left(\int_{0}^tds \frac{g''}{g^2}+ \int_t^T dt\, \frac{3 g'^2}{2g^3}\right)\right]^{-1/2}\bigg>\bigg>
\end{align}
If however, we operator order in flat space there is no potential, since it cancels with the change in variables from the mean velocity.  


\section{Putting into Numerical form-Weyl} 

So let's put a bit of thought into how to handle 
\begin{equation}
Z = \int \prod_{k=1}^{N-1}dx_k \frac{\sqrt{\bar{g}_k}}{\sqrt{2\pi\Delta T}} \exp\left[- \frac{g(\bar{x}_k)(x_{k+1}-x_k)^2}{2\Delta T}\right],
\end{equation}
where we will use $\bar{x}_k = (x_{k+1}+x_k)/2$, and $\bar{g} = g(\bar{x})$.  
\subsection{Transforming to a Gaussian}
We can transform variable from positions $x_k$ to increments
\begin{equation}
u_k = x_{k+1} - x_k, k = 0,N-1,
\end{equation}
with
\begin{equation}
x_{k} = \sum_{j=0}^{k-1} u_j.
\end{equation}
This transformation has unit Jacobian.  
\begin{equation}
Z= \int du_k \delta\left(\sum u_k \right)\sqrt{\frac{\bar{g}_k}{2\pi \Delta T}} e^{-\frac{\bar{g}_ku_k^2}{2\Delta T}}.
\end{equation}
now where 
\begin{equation}
\bar{g}_k = g\left(\bar{x}_k\right) =  g\left(\frac{u_k}{2}+\sum_{j<k} u_j\right) 
\end{equation}

Let's now try to decouple the random variables.  Let us introduce 
\begin{equation}
dW_k = \sqrt{\bar{g}_k}u_k
\end{equation}
\comment{I amy miss some bars - all functions are understood to be functions of $\bar{x}_j$.  }
We will need to calculate a Jacobian, and a euclidean norm of gradients.  In both cases we will need $\frac{\partial u_k}{\partial dW_j}$.  
So we can iteratively define the increments from the Gaussians as 
\begin{equation}
u_k = \frac{1}{\sqrt{\bar{g}_k}}dW_k.
\end{equation}

\subsection{Partial derivatives of increments}
We then have 
\begin{align}
\frac{\partial u_j}{\partial dW_k} &= \frac{\partial}{\partial dW_k}\frac{1}{\sqrt{g\left(\frac{u_j}{2} +\sum_{i<j}u_i\right)}}dW_j\\
&= \frac{1}{\sqrt{\bar{g}_j}}\delta_{jk} -\frac{\bar{g}_j'}{2\bar{g}^{3/2}_j}dW_j\left(\frac{1}{2}\frac{du_j}{dW_k} + \sum_{i<j}\frac{d u_i}{dW_k}\right)\\
\left(1 + \frac{\bar{g}_j'}{4\bar{g}^{3/2}_j}dW_j\right)\frac{du_j}{dW_k} &= \frac{1}{\sqrt{\bar{g}_j}}\delta_{jk} -\frac{\bar{g}_j'}{2\bar{g}^{3/2}_j}dW_j\sum_{i<j}\frac{d u_i}{dW_k}\\
\frac{du_j}{dW_k} &= \left(1 + \frac{\bar{g}_j'}{4\bar{g}^{3/2}_j}dW_j\right)^{-1}\left(\frac{1}{\sqrt{\bar{g}_j}}\delta_{jk} -\frac{\bar{g}_j'}{2\bar{g}^{3/2}_j}dW_j\sum_{i<j}\frac{d u_i}{dW_k}\right).
\end{align}
Now approximate that leading coeffient to order $\Delta T$.  
\begin{align}
\left(1 + \frac{\bar{g}_j'}{4\bar{g}^{3/2}_j}dW_j\right)^{-1} \approx& 1 - \frac{\bar{g}_j'}{4\bar{g}_j^{3/2} }dW_j + \frac{\bar{g}_j'^2}{16 \bar{g}_j^3}\Delta T\\
\approx& \exp\left(-\frac{\bar{g}_j'}{4\bar{g}_j^{3/2} }dW_j+ \frac{\bar{g}_j'^2}{32 \bar{g}_j^3}\Delta T\right) \\
=& e^{U_j}\label{eq:defn_exp_U}
\end{align}
where 
\begin{equation}
U_j = -\frac{\bar{g}_j'}{4\bar{g}_j^{3/2} }dW_j+ \frac{\bar{g}_j'^2}{32 \bar{g}_j^3}\Delta T
\end{equation}
\subsubsection{Logarithm}
Now we can expand the increment in $\log g$ to order $\Delta T$.
\begin{align}
\log[g(x_{j+1})] -\log[g(x_{j})] =& \log[g\left(\bar{x}_j+ \frac{dx_j}{2}\right)] -\log[g\left(\bar{x}_j- \frac{dx_j}{2}\right)]\\
=& \log\left[\bar{g}_j+ \frac{dx_j}{2}\bar{g}_j' + \frac{dx_j^2}{4}\bar{g}''_j\right]-\log\left[\bar{g}_j- \frac{dx_j}{2}\bar{g}_j' + \frac{dx_j^2}{4}\bar{g}''_j\right]\\
=& \log\left[\bar{g}_j\right] + \frac{dx_j}{2}\frac{\bar{g}_j'}{g_j} + \frac{dx_j^2}{4}\frac{\bar{g}''_j}{g_j} - \frac{1}{2}\frac{dx_j^2}{4}\frac{\bar{g}_j'^2}{g^2}\nonumber\\
&-\left(\log\left[\bar{g}_j\right] - \frac{dx_j}{2}\frac{\bar{g}_j'}{g_j} + \frac{dx_j^2}{4}\frac{\bar{g}''_j}{g_j} - \frac{1}{2}\frac{dx_j^2}{4}\frac{\bar{g}_j'^2}{g^2}\right)\\
=& dx_j\frac{\bar{g}'_j}{\bar{g}_j}.\label{eq:log_strat}
\end{align}
So we can write 
\begin{equation}
\boxed{U_k=-\frac{1}{4}\log\left(\frac{\bar{g}_{j+1}}{\bar{g}_j}\right)+ \frac{\bar{g}_j'^2}{32 \bar{g}_j^3}\Delta T}
\end{equation}

\subsubsection{Putting derivative matrix into closed form}

Let us now return to finding the derivative of u w.r.t w:
\begin{equation}
\boxed{\frac{du_j}{dW_k} = \frac{e^{U_j}}{\sqrt{\bar{g}_j}}\delta_{jk} -e^{U_j}\frac{\bar{g}_j'}{2\bar{g}^{3/2}_j}dW_j\sum_{i<j}\frac{d u_i}{dW_k}.}
\end{equation}
We can solve this by starting the recursion at $j,k=0$.  We have 
\begin{gather}
\frac{\partial u_0}{\partial dW_0} = \frac{e^{U_0}}{\sqrt{\bar{g}_0}}, \quad \frac{\partial u_0}{\partial dW_{j>0}} = 0
\end{gather}
Similarly the second increment is 
\begin{align}
\frac{\partial u_1}{\partial dW_0}& = -\frac{e^{U_0}}{\sqrt{\bar{g}_0}}\frac{e^{U_1}\bar{g}'_1}{2\bar{g}_1^{3/2}}dW_1, \quad \frac{\partial u_1}{\partial dW_1} = \frac{e^{U_1}}{\sqrt{\bar{g}_1}} ,\quad \frac{\partial u_1}{\partial dW_{j>1}} = 0.
\end{align}
The third increment is 
\begin{align}
\frac{\partial u_2}{\partial dW_0}& = -\frac{e^{U_2}\bar{g}'_2}{2\bar{g}_2^{3/2}}dW_2\left(1-\frac{e^{U_1}\bar{g}'_1}{2\bar{g}_1^{3/2}}dW_1\right)\frac{e^{U_0}}{\sqrt{\bar{g}_0}}\, \quad \frac{\partial u_2}{\partial dW_1} = -\frac{e^{U_1}}{\sqrt{\bar{g}_1}}\frac{e^{U_2}\bar{g}'_2}{2\bar{g}_2^{3/2}}dW_2, \quad \frac{\partial u_2}{\partial dW_2} = \frac{e^{U_2}}{\sqrt{\bar{g}_2}}, \quad \frac{\partial u_2}{\partial dW_{j>2}} = 0.
\end{align}

For the diagonal, we just get $\bar{g}_k^{-1/2}$. 
So if we're off the diagonal we multiply by $\bar{g}_j' dW_j$ for the current row $j$, and sum up all of the preceding entries in this column.   
Evidently a generic term off the diagonal will have components (row is $u_j$, column is $dW_k$ increment)
\begin{equation}
\boxed{\frac{\partial u_j}{\partial dW_k} = \frac{e^{U_k}}{\sqrt{\bar{g}_k}}\delta_{jk} - \frac{e^{U_k}}{\sqrt{\bar{g}_k}}\frac{e^{U_j}\bar{g}'_j}{2\bar{g}^{3/2}_j}dW_j\delta_{j,k+1} - \frac{e^{U_k}}{\sqrt{\bar{g}_k}}\frac{e^{U_j}\bar{g}'_j}{2\bar{g}^{3/2}_j}dW_j\prod_{m=k+1}^{j-1} \left(1- \frac{e^{U_m}\bar{g}'_m}{2\bar{g}^{3/2}_m}dW_m\right)\Theta(j\ge k+2),}
\end{equation}
with $j,k=0,1,\ldots N-1$. If we further define $dW_k = \sqrt{\Delta T}z_k$, then we should multiply this by $\sqrt{\Delta T}$.  

\subsection{Jacobian}

The first place we need this result is in calculating the jacobian:
\begin{equation}
\left|\frac{\partial u_j}{\partial dz_k}\right| = \prod_{k=0}^{N-1}\frac{e^{U_k}\sqrt{\Delta T}}{\sqrt{\bar{g}_k}}
\end{equation}
which follows because the matrix is in lower-triangular form.  The Jacobian from changing from positions to increments is also lower-triangular, and just gives unit determinant.  This factor will eat all of the prefactor normalizations, and slightly shift the potential.  

After cancelling out the normalization prefactors we then have to deal with 
\begin{equation}
\exp\left[\sum_k U_k\right] = \prod_{j=0}^{N-1}\left( \frac{\bar{g}_j}{\bar{g}_{j+1}}\right)^{1/4}\exp\left( \sum_j\frac{\bar{g}_j'^2}{32 \bar{g}_j^3}\Delta T\right) = \exp\left( \sum_j\frac{\bar{g}_j'^2}{32 \bar{g}_j^3}\Delta T\right),
\end{equation}
since we have closed loops, so that prefactor just gives us unity.  


\subsection{Euclidean norm of gradient}

Next up we need to calculate the change in the normalization when constrained to loops that close.  The loop must close, or the increments sum to zero.   Our constraint is 
\begin{align}
  h(d\vect{W}) = x_n-x_0 = \sum_{j=0}^{N-1} u_j = \sum_{j=0}^{N-1}u_j\left[\sum_{k<j} u_k[dW] \right]=0
\end{align}
We will use the $z_k$, to ensure we carry out all of the transformations we need.  
The Euclidean norm of the gradient is defined as 
\begin{align}
\|\nabla_{\vect{z}}h(\vect{z})\|^2 = &  \Delta T \|\nabla_{d\vect{W}}h(d\vect{W})\|^2\\
 = & \Delta T \sum_{k=0}^{N-1} \left(\sum_{j=0}^{N-1} \frac{\partial u_j}{\partial dW_k} \right)^2
\end{align}
We will plug in our form for $\frac{\partial u_j}{\partial dW_k} $, and simplify the sums.  
\begin{align}
\|\nabla_{\vect{z}}h(\vect{z})\|^2 = & \Delta T \sum_{k=0}^{N-1} \left(\sum_{j=0}^{N-1}\frac{e^{U_k}}{\sqrt{\bar{g}_k}}\delta_{jk} - \frac{e^{U_k}}{\sqrt{\bar{g}_k}}\frac{e^{U_j}\bar{g}'_j}{2\bar{g}^{3/2}_j}dW_j\delta_{j,k+1} \right. \nonumber\\
&\left.\qquad - \frac{e^{U_k}}{\sqrt{\bar{g}_k}}\frac{\bar{g}'_j}{2\bar{g}^{3/2}_j}dW_j\prod_{m=k+1}^{j-1} \left(1- \frac{e^{U_m}\bar{g}'_m}{2\bar{g}^{3/2}_m}dW_m\right)\Theta(j\ge k+2)\right)^2\\
 = & \Delta T  \sum_{k=0}^{N-1}\frac{e^{2U_k}}{\bar{g}_k}\left[1 - \frac{e^{U_{k+1}}\bar{g}'_{k+1}}{2\bar{g}^{3/2}_{k+1}}dW_{k+1} - \sum_{j=k+2}^{N-1}\frac{e^{U_j}\bar{g}'_j}{2\bar{g}^{3/2}_j}dW_j\prod_{m=k+1}^{j-1} \left(1- \frac{e^{U_m}\bar{g}'_m}{2\bar{g}^{3/2}_m}dW_m\right)\right]^2
\end{align}
where we carried out the sum over $j$.    Now we have to start guessing a bit - using some inspiration to approximate this thing.  It turns out that we can simplify the bracketed term.  We will just start writing out the sum starting at $k+2$, and then factoring terms.  It will be clear that wecan then proceed to just factor all of the terms up.  
\begin{align}
1- f_{k+1}  - \sum_{j={k+2}}^{N-1} f_j\prod_{m=k+1}^{j-1}(1-f_m) =& 1 - f_{k+1}  - f_{k+2}(1-f_{k+1}) - f_{k+3}(1-f_{k+2})(1-f_{k+1}) + \ldots\\
=& (1-f_{k+2})(1-f_{k+1}) - f_{k+3}(1-f_{k+2})(1-f_{k+1}) + \ldots \\
=& \prod_{j=k+1}^{N-1}(1-f_j)
\end{align}
Now that is in a form that begs to be exponentiated.  We can plug in $e^{U_m}$ using the definition in Eq.~(\ref{eq:defn_exp_U}), and simplify this a bit.  
So we get 
\begin{align}
\|\nabla_{\vect{z}}h(\vect{z})\|^2 =& \Delta T  \sum_{k=0}^{N-1}\frac{e^{2U_k}}{\bar{g}_k}\left[\prod_{m=k+1}^{N-1}\left(1 -\frac{e^{U_m}\bar{g}'_m}{2\bar{g}^{3/2}_m}dW_m\right)\right]^2\\
=& \Delta T  \sum_{k=0}^{N-1}\frac{e^{U_k}}{\bar{g}_k}\prod_{m=k+1}^{N-1}\left[1 -\left(1 - \frac{\bar{g}_j'}{4\bar{g}_j^{3/2} }dW_j + \frac{\bar{g}_j'^2}{16 \bar{g}_j^3}\Delta T\right)\frac{\bar{g}'_m}{2\bar{g}^{3/2}_m}dW_m\right]^2\\
\approx& \Delta T  \sum_{k=0}^{N-1}\frac{e^{U_k}}{\bar{g}_k}\prod_{m=k+1}^{N-1}\left(1 -\frac{\bar{g}'_m}{2\bar{g}^{3/2}_m}dW_m + \frac{\bar{g}_j'^2}{8\bar{g}_j^{3} }\Delta T\right)\\
\approx& \Delta T  \sum_{k=0}^{N-1}\frac{e^{2U_k}}{\bar{g}_k}\prod_{m=k+1}^{N-1}\exp\left( -\frac{\bar{g}'_m}{\bar{g}^{3/2}_m}dW_m \right)\\
\approx& \Delta T  \sum_{k=0}^{N-1}\frac{1}{\bar{g}_k}\exp\left(-\frac{\bar{g}_k'}{2\bar{g}_k^{3/2} }dW_k+ \frac{\bar{g}_k'^2}{16 \bar{g}_k^3}\Delta T\right)\prod_{m=k+1}^{N-1}\exp\left( -\frac{\bar{g}'_m}{\bar{g}^{3/2}_m}dW_m \right)
\end{align}
Now we can use the logarithmic expansion in Eq.(~\ref{eq:log_strat}) to rewrite the Wiener increment term
\begin{align}
-\frac{g'_m}{g_m^{3/2}} dW_m = -\frac{g'_m}{g_m'} dx = \ln\frac{g_m}{g_{m+1}}
\end{align}
We have a sum of these: 
\begin{equation}
\prod_{m=k+1}^{N-1}\exp\left( -\frac{\bar{g}'_m}{\bar{g}^{3/2}_m}dW_m \right) = \prod_{m=k+1}^{N-1} \frac{g_m}{g_{m+1}} = \frac{g_{k+1}}{g_N}.
\end{equation}
If this came out with a different sign we could be dancing?  
So our normalization factor is 
\begin{equation}
\boxed{\|\nabla_{\vect{z}}h(\vect{z})\|^2 = \Delta T \sum_{k=0}^{N-1}\frac{1}{\bar{g}_k}\frac{\bar{g}_{k+1}}{\bar{g}_{N}} \approx \frac{ T}{g_N} + \order(N^{-1/2})}
\end{equation}

Fuck.  So that potential has to do something.   Or this is really just wrong -> check logic for extracting a mean energy.  
Maybe we forgot an extra term?  

So if we pull together the Jacobian and Euclidean norm factors we get 
\begin{align}
\boxed{Z= \left<\left< \sqrt{\frac{g_N}{2\pi T}}  e^{\Delta T\sum_{m}\frac{\bar{g}'^2}{32g^3}-V}\right>\right>_{g}},
\end{align}
where the loops are to be taken with respect to the $g$ loops.  There may be an additional potentital arising rom operator ordering.  
\comment{replacing constants with their loop average? what order should this be done in?  average of functions, or function of averages?  }



%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "thesis_master"
%%% End: 
